# Analytical MMD A2B Feature58 å·¥ä½œæµç¨‹æ–‡æ¡£

## æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†åŸºäºMMDï¼ˆMaximum Mean Discrepancyï¼‰çš„åŸŸé€‚åº”æ–¹æ³•ï¼Œç”¨äºåŒ»ç–—æ•°æ®çš„è·¨åŸŸé¢„æµ‹ã€‚æ”¯æŒå¤šç§æ•°æ®åˆ’åˆ†ç­–ç•¥ã€ç›®æ ‡åŸŸé€‰æ‹©å’Œè´å¶æ–¯ä¼˜åŒ–åŠŸèƒ½ã€‚

## æ ¸å¿ƒç‰¹æ€§

### 1. ç›®æ ‡åŸŸé€‰æ‹©

é¡¹ç›®ç°åœ¨æ”¯æŒçµæ´»çš„ç›®æ ‡åŸŸé€‰æ‹©ï¼š

#### ç›®æ ‡åŸŸBï¼ˆæ²³å—ç™Œç—‡åŒ»é™¢ï¼‰
- **é»˜è®¤é€‰é¡¹**ï¼šä¸åŸæœ‰A2Bå®éªŒä¿æŒä¸€è‡´
- **æ•°æ®ç‰¹ç‚¹**ï¼šæ²³å—ç™Œç—‡åŒ»é™¢çš„åŒ»ç–—æ•°æ®
- **ä½¿ç”¨åœºæ™¯**ï¼šæ ‡å‡†çš„Aâ†’BåŸŸé€‚åº”å®éªŒ

#### ç›®æ ‡åŸŸCï¼ˆå¹¿å·åŒ»ç§‘å¤§å­¦ï¼‰
- **æ–°å¢é€‰é¡¹**ï¼šæ”¯æŒAâ†’CåŸŸé€‚åº”å®éªŒ
- **æ•°æ®ç‰¹ç‚¹**ï¼šå¹¿å·åŒ»ç§‘å¤§å­¦çš„åŒ»ç–—æ•°æ®
- **ä½¿ç”¨åœºæ™¯**ï¼šæ¢ç´¢ä¸åŒåŒ»é™¢é—´çš„åŸŸé€‚åº”æ•ˆæœ

### 2. æ•°æ®åˆ’åˆ†ç­–ç•¥

é¡¹ç›®æ”¯æŒä¸¤ç§æ•°æ®åˆ’åˆ†ç­–ç•¥ï¼š

#### äºŒåˆ†æ³• (Two-way Split)
- **AåŸŸæ•°æ®**ï¼šå®Œæ•´ç”¨ä½œè®­ç»ƒé›†
- **BåŸŸæ•°æ®**ï¼šå®Œæ•´ç”¨ä½œæµ‹è¯•é›†
- **é€‚ç”¨åœºæ™¯**ï¼šæ ‡å‡†çš„åŸŸé€‚åº”è¯„ä¼°ï¼Œä¸åŸå§‹MMDæ–¹æ³•ä¿æŒä¸€è‡´

#### ä¸‰åˆ†æ³• (Three-way Split)
- **AåŸŸæ•°æ®**ï¼šå®Œæ•´ç”¨ä½œè®­ç»ƒé›†
- **BåŸŸæ•°æ®**ï¼šåˆ’åˆ†ä¸ºéªŒè¯é›†(é»˜è®¤80%)å’Œä¿ç•™æµ‹è¯•é›†(20%)
- **éªŒè¯é›†**ï¼šç”¨äºæ¨¡å‹é€‰æ‹©å’Œè¶…å‚æ•°ä¼˜åŒ–
- **ä¿ç•™æµ‹è¯•é›†**ï¼šç”¨äºæœ€ç»ˆæ³›åŒ–èƒ½åŠ›è¯„ä¼°
- **é€‚ç”¨åœºæ™¯**ï¼šéœ€è¦è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–æˆ–æ¨¡å‹é€‰æ‹©çš„åœºæ™¯

### 3. è´å¶æ–¯ä¼˜åŒ–é›†æˆ

é¡¹ç›®ç°åœ¨æ”¯æŒä¸¤ç§è´å¶æ–¯ä¼˜åŒ–æ¨¡å¼ï¼š

#### æ ‡å‡†è´å¶æ–¯ä¼˜åŒ–
- **åŠŸèƒ½**ï¼šä»…ä¼˜åŒ–æ¨¡å‹è¶…å‚æ•°
- **é€‚ç”¨åœºæ™¯**ï¼šå¿«é€Ÿæ¨¡å‹è°ƒä¼˜ï¼Œä¸æ¶‰åŠåŸŸé€‚åº”å‚æ•°
- **è„šæœ¬**ï¼š`run_bayesian_optimization.py`

#### è´å¶æ–¯MMDä¼˜åŒ–ï¼ˆæ¨èï¼‰
- **åŠŸèƒ½**ï¼šåŒæ—¶ä¼˜åŒ–æ¨¡å‹è¶…å‚æ•°å’ŒMMDåŸŸé€‚åº”å‚æ•°
- **ä¼˜åŠ¿**ï¼šç«¯åˆ°ç«¯ä¼˜åŒ–ï¼Œè·å¾—æœ€ä½³çš„åŸŸé€‚åº”æ•ˆæœ
- **è„šæœ¬**ï¼š`run_bayesian_mmd_optimization.py`
- **æœç´¢ç©ºé—´**ï¼š
  - æ¨¡å‹å‚æ•°ï¼šmax_time, preset, ges_scoring, max_modelsç­‰
  - MMDå‚æ•°ï¼šlr, n_epochs, gamma, lambda_regç­‰ï¼ˆæ ¹æ®MMDæ–¹æ³•è€Œå®šï¼‰

### 4. æ•°æ®åˆ’åˆ†ç­–ç•¥

### ğŸš€ ä¸»å‡½æ•°æ‰§è¡Œæµç¨‹

### 1. ç¨‹åºå…¥å£ - main()

```python
def main():
    """ä¸»å‡½æ•° - ç¨‹åºæ‰§è¡Œçš„èµ·ç‚¹"""
```

**æ‰§è¡Œæ­¥éª¤:**

#### 1.1 å‚æ•°è§£æ
```python
args = parse_arguments()
```
- è§£æå‘½ä»¤è¡Œå‚æ•°
- æ”¯æŒçš„ä¸»è¦å‚æ•°ï¼š
  - `--model-type`: æ¨¡å‹ç±»å‹ (auto/tuned/base/rf)
  - `--method`: MMDæ–¹æ³• (linear/kpca/mean_std)
  - `--feature-type`: ç‰¹å¾ç±»å‹ (all/best7)
  - `--use-class-conditional`: æ˜¯å¦ä½¿ç”¨ç±»æ¡ä»¶MMD
  - `--use-threshold-optimizer`: æ˜¯å¦ä½¿ç”¨é˜ˆå€¼ä¼˜åŒ–
  - `--skip-cv-on-a`: æ˜¯å¦è·³è¿‡æ•°æ®é›†Açš„äº¤å‰éªŒè¯
  - `--evaluation-mode`: è¯„ä¼°æ¨¡å¼ (cv/proper_cv/single)
  - `--data-split-strategy`: æ•°æ®åˆ’åˆ†ç­–ç•¥ (`two-way` | `three-way`)
  - `--validation-split`: ä¸‰åˆ†æ³•æ—¶éªŒè¯é›†æ¯”ä¾‹ (é»˜è®¤: 0.7)
  - `--target-domain`: ç›®æ ‡åŸŸé€‰æ‹© (`B` | `C`) (é»˜è®¤: B)

#### 1.2 æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–
```python
logger = setup_experiment_logging(args.log_file)
```
- åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„æ—¥å¿—æ–‡ä»¶
- è®¾ç½®æ§åˆ¶å°å’Œæ–‡ä»¶åŒé‡è¾“å‡º
- æ—¥å¿—æ ¼å¼ï¼š`æ—¶é—´æˆ³ - æ¨¡å—å - çº§åˆ« - æ¶ˆæ¯`

#### 1.3 å®éªŒé…ç½®æ‰“å°
```python
logger.info("å®éªŒé…ç½®:")
logger.info(f"  æ¨¡å‹ç±»å‹: {args.model_type}")
# ... å…¶ä»–é…ç½®ä¿¡æ¯
```

#### 1.4 æ¨¡å‹å¯ç”¨æ€§æ£€æŸ¥
```python
available_models = get_available_models()
if args.model_type not in available_models:
    logger.error(f"æ¨¡å‹ç±»å‹ {args.model_type} ä¸å¯ç”¨")
    return
```

#### 1.5 å®éªŒæ¨¡å¼åˆ†å‘
```python
if args.compare_all:
    run_comparison_experiment(args, logger)
else:
    # ç›´æ¥è¿è¡Œè·¨åŸŸå®éªŒ
    run_cross_domain_experiment_mode(args, logger)
```

## ğŸ”„ å®éªŒæ¨¡å¼è¯¦ç»†æµç¨‹

### ä¸»è¦æ¨¡å¼: è·¨åŸŸå®éªŒ

#### å‡½æ•°: `run_cross_domain_experiment_mode()`

**æ­¥éª¤1: æ•°æ®éªŒè¯**
```python
if not validate_data_paths():
    logger.error("æ•°æ®æ–‡ä»¶éªŒè¯å¤±è´¥")
    return
```
- æ£€æŸ¥ AI4Healthã€æ²³å—ç™Œç—‡åŒ»é™¢ã€å¹¿å·åŒ»ç§‘å¤§å­¦æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
- éªŒè¯æ•°æ®è·¯å¾„çš„å®Œæ•´æ€§

**æ­¥éª¤2: å‚æ•°å‡†å¤‡**
```python
model_kwargs = prepare_model_kwargs(args)
mmd_kwargs = prepare_mmd_kwargs(args, args.method)
```

**prepare_model_kwargs() è¯¦ç»†æµç¨‹:**
```python
# è·å–åŸºç¡€é…ç½®
if args.model_preset:
    base_config = get_model_config(args.model_type, args.model_preset)
else:
    base_config = get_model_config(args.model_type)

# è¦†ç›–ç‰¹å®šå‚æ•°
if args.max_time is not None:
    model_kwargs['max_time'] = args.max_time
# ... å…¶ä»–å‚æ•°è¦†ç›–

# éªŒè¯å‚æ•°
model_kwargs = validate_model_params(args.model_type, model_kwargs)
```

**prepare_mmd_kwargs() è¯¦ç»†æµç¨‹:**
```python
# è·å–MMDæ–¹æ³•åŸºç¡€é…ç½®
mmd_kwargs = MMD_METHODS.get(method, {}).copy()

# Linearæ–¹æ³•ç‰¹å®šå‚æ•°
if method == 'linear':
    if args.lr is not None:
        mmd_kwargs['lr'] = args.lr
    # ... å…¶ä»–linearå‚æ•°
    
    # é¢„è®¾é…ç½®å¤„ç†
    if args.use_preset == 'conservative':
        mmd_kwargs.update({
            'lr': 1e-4,
            'lambda_reg': 1e-2,
            'staged_training': True,
            # ...
        })
```

**æ­¥éª¤3: ä¿å­˜è·¯å¾„ç”Ÿæˆ**
```python
if args.output_dir:
    save_path = args.output_dir
else:
    suffix = generate_experiment_suffix(args)
    save_path = f"./results_cross_domain_{args.model_type}_{args.method}_{args.feature_type}{suffix}"
```

**æ­¥éª¤4: æ ¸å¿ƒå®éªŒæ‰§è¡Œ**
```python
results = run_cross_domain_experiment(
    model_type=args.model_type,
    feature_type=args.feature_type,
    mmd_method=args.method,
    use_class_conditional=args.use_class_conditional,
    use_threshold_optimizer=args.use_threshold_optimizer,
    save_path=save_path,
    skip_cv_on_a=args.skip_cv_on_a,
    evaluation_mode=args.evaluation_mode,
    save_visualizations=not args.no_visualizations,
    **{**model_kwargs, **mmd_kwargs}
)
```

**æ­¥éª¤5: ç»“æœè¾“å‡º**
```python
# æ‰“å°æ•°æ®é›†Aäº¤å‰éªŒè¯ç»“æœ
if 'cross_validation_A' in results:
    cv_results = results['cross_validation_A']
    logger.info(f"æ•°æ®é›†Aäº¤å‰éªŒè¯ - å‡†ç¡®ç‡: {cv_results['accuracy']}")
    logger.info(f"æ•°æ®é›†Aäº¤å‰éªŒè¯ - AUC: {cv_results['auc']}")

# æ‰“å°æ•°æ®é›†Bå¤–éƒ¨éªŒè¯ç»“æœ
if 'external_validation_B' in results:
    # æ— åŸŸé€‚åº”ç»“æœ
    # æœ‰åŸŸé€‚åº”ç»“æœ
    
# æ‰“å°æ•°æ®é›†Cå¤–éƒ¨éªŒè¯ç»“æœ
if 'external_validation_C' in results:
    # æ— åŸŸé€‚åº”ç»“æœ
    # æœ‰åŸŸé€‚åº”ç»“æœ
```

### æ¨¡å¼2: æ–¹æ³•æ¯”è¾ƒæ¨¡å¼ (compare-all)

#### å‡½æ•°: `run_comparison_experiment()`

**æ‰§è¡Œæµç¨‹:**
```python
methods = ['linear', 'kpca', 'mean_std']
all_results = {}

for method in methods:
    logger.info(f"è¿è¡Œ{method}æ–¹æ³•...")
    
    # æ›´æ–°å‚æ•°
    args.method = method
    
    try:
        # ç›´æ¥è¿è¡Œè·¨åŸŸå®éªŒ
        run_cross_domain_experiment_mode(args, logger)
        
        logger.info(f"{method}æ–¹æ³•å®Œæˆ")
        
    except Exception as e:
        logger.error(f"{method}æ–¹æ³•å¤±è´¥: {e}")
        continue

logger.info("æ‰€æœ‰æ–¹æ³•æ¯”è¾ƒå®Œæˆ!")
```

## ğŸ”§ æ ¸å¿ƒè·¨åŸŸå®éªŒæµç¨‹è¯¦è§£

### run_cross_domain_experiment() å‡½æ•°æµç¨‹

è¿™æ˜¯æ•´ä¸ªç³»ç»Ÿçš„æ ¸å¿ƒå‡½æ•°ï¼Œä½äº `modeling/cross_domain_runner.py` ä¸­ï¼š

#### é˜¶æ®µ1: æ•°æ®å‡†å¤‡
1. **æ•°æ®åŠ è½½**
   ```python
   datasets = load_all_datasets()
   # åŠ è½½ AI4Health (A), æ²³å—ç™Œç—‡åŒ»é™¢ (B), å¹¿å·åŒ»ç§‘å¤§å­¦ (C)
   ```

2. **ç‰¹å¾é€‰æ‹©**
   ```python
   features = get_features_by_type(feature_type)
   categorical_indices = get_categorical_indices(feature_type)
   ```

3. **æ•°æ®é¢„å¤„ç†**
   ```python
   # æ•°æ®æ ‡å‡†åŒ–
   X_A_scaled, scaler = fit_apply_scaler(X_A, categorical_indices)
   X_B_scaled = apply_scaler(X_B, scaler, categorical_indices)
   X_C_scaled = apply_scaler(X_C, scaler, categorical_indices)
   ```

#### é˜¶æ®µ2: åŸºçº¿è¯„ä¼° (å¯é€‰)
```python
if not skip_cv_on_a:
    # æ•°æ®é›†Aä¸Šçš„10æŠ˜äº¤å‰éªŒè¯
    cv_results = evaluate_model_on_external_cv(model, X_A_scaled, y_A, n_folds=10)
```

#### é˜¶æ®µ3: æ— åŸŸé€‚åº”è¯„ä¼°
```python
# åœ¨æ•°æ®é›†Aä¸Šè®­ç»ƒï¼Œåœ¨Bå’ŒCä¸Šæµ‹è¯•
model.fit(X_A_scaled, y_A)

# æ•°æ®é›†Bè¯„ä¼°
y_B_pred = model.predict(X_B_scaled)
y_B_proba = model.predict_proba(X_B_scaled)[:, 1]
b_results_no_da = evaluate_metrics(y_B, y_B_pred, y_B_proba)

# æ•°æ®é›†Cè¯„ä¼°
y_C_pred = model.predict(X_C_scaled)
y_C_proba = model.predict_proba(X_C_scaled)[:, 1]
c_results_no_da = evaluate_metrics(y_C, y_C_pred, y_C_proba)
```

#### é˜¶æ®µ4: MMDåŸŸé€‚åº”
```python
if use_class_conditional:
    # ç±»æ¡ä»¶MMDå˜æ¢
    X_B_adapted = class_conditional_mmd_transform(
        X_A_scaled, y_A, X_B_scaled, method=mmd_method, **mmd_kwargs
    )
    X_C_adapted = class_conditional_mmd_transform(
        X_A_scaled, y_A, X_C_scaled, method=mmd_method, **mmd_kwargs
    )
else:
    # æ ‡å‡†MMDå˜æ¢
    X_B_adapted = mmd_transform(
        X_A_scaled, X_B_scaled, method=mmd_method, **mmd_kwargs
    )
    X_C_adapted = mmd_transform(
        X_A_scaled, X_C_scaled, method=mmd_method, **mmd_kwargs
    )
```

#### é˜¶æ®µ5: åŸŸé€‚åº”åè¯„ä¼°
```python
# é‡æ–°è®­ç»ƒæ¨¡å‹
model.fit(X_A_scaled, y_A)

# åœ¨é€‚åº”åçš„æ•°æ®ä¸Šè¯„ä¼°
y_B_pred_adapted = model.predict(X_B_adapted)
y_B_proba_adapted = model.predict_proba(X_B_adapted)[:, 1]
b_results_with_da = evaluate_metrics(y_B, y_B_pred_adapted, y_B_proba_adapted)

y_C_pred_adapted = model.predict(X_C_adapted)
y_C_proba_adapted = model.predict_proba(X_C_adapted)[:, 1]
c_results_with_da = evaluate_metrics(y_C, y_C_pred_adapted, y_C_proba_adapted)
```

#### é˜¶æ®µ6: é˜ˆå€¼ä¼˜åŒ– (å¯é€‰)
```python
if use_threshold_optimizer:
    # åœ¨æ•°æ®é›†Bä¸Šä¼˜åŒ–é˜ˆå€¼
    optimal_threshold_B, optimized_metrics_B = optimize_threshold(y_B, y_B_proba_adapted)
    
    # åœ¨æ•°æ®é›†Cä¸Šä¼˜åŒ–é˜ˆå€¼
    optimal_threshold_C, optimized_metrics_C = optimize_threshold(y_C, y_C_proba_adapted)
```

#### é˜¶æ®µ7: å¯è§†åŒ–ç”Ÿæˆ
```python
if save_visualizations:
    # t-SNEå¯¹æ¯”å¯è§†åŒ–
    compare_before_after_adaptation(
        X_A_scaled, X_B_scaled, X_B_adapted,
        y_A, y_B, y_B,
        save_path=os.path.join(save_path, 'visualizations')
    )
    
    # ROCæ›²çº¿
    plot_roc_curve(y_B, y_B_proba_adapted, 
                   save_path=os.path.join(save_path, 'roc_curve_B.png'))
```

#### é˜¶æ®µ8: ç»“æœä¿å­˜
```python
# ä¿å­˜è¯¦ç»†ç»“æœ
results = {
    'cross_validation_A': cv_results,
    'external_validation_B': {
        'without_domain_adaptation': b_results_no_da,
        'with_domain_adaptation': b_results_with_da
    },
    'external_validation_C': {
        'without_domain_adaptation': c_results_no_da,
        'with_domain_adaptation': c_results_with_da
    },
    'experiment_config': {
        'model_type': model_type,
        'feature_type': feature_type,
        'mmd_method': mmd_method,
        'use_class_conditional': use_class_conditional,
        'use_threshold_optimizer': use_threshold_optimizer
    }
}

# ä¿å­˜åˆ°JSONæ–‡ä»¶
with open(os.path.join(save_path, 'results.json'), 'w') as f:
    json.dump(results, f, indent=2)
```

## ğŸ“Š MMDæ–¹æ³•å…·ä½“å®ç°æµç¨‹

### Linear MMD å˜æ¢æµç¨‹

#### 1. åˆå§‹åŒ–
```python
transformer = MMDLinearTransform(
    gamma=gamma,
    lr=lr,
    n_epochs=n_epochs,
    batch_size=batch_size,
    lambda_reg=lambda_reg,
    staged_training=True,
    dynamic_gamma=True
)
```

#### 2. åˆ†é˜¶æ®µè®­ç»ƒ
```python
if staged_training:
    # é˜¶æ®µ1: ä½å­¦ä¹ ç‡é¢„è®­ç»ƒ
    transformer.fit(X_source, X_target, lr=lr*0.1, n_epochs=n_epochs//3)
    
    # é˜¶æ®µ2: æ­£å¸¸å­¦ä¹ ç‡è®­ç»ƒ
    transformer.fit(X_source, X_target, lr=lr, n_epochs=n_epochs//3)
    
    # é˜¶æ®µ3: ä½å­¦ä¹ ç‡ç²¾è°ƒ
    transformer.fit(X_source, X_target, lr=lr*0.1, n_epochs=n_epochs//3)
```

#### 3. åŠ¨æ€Gammaæœç´¢
```python
if dynamic_gamma:
    best_gamma = None
    best_mmd = float('inf')
    
    for gamma_candidate in gamma_search_values:
        transformer.gamma = gamma_candidate
        X_target_transformed = transformer.transform(X_target)
        mmd_dist = compute_mmd_kernel(X_source, X_target_transformed, gamma_candidate)
        
        if mmd_dist < best_mmd:
            best_mmd = mmd_dist
            best_gamma = gamma_candidate
    
    transformer.gamma = best_gamma
```

#### 4. å˜æ¢åº”ç”¨
```python
X_target_transformed = transformer.transform(X_target)
```

### Kernel PCA MMD å˜æ¢æµç¨‹

#### 1. æ ¸PCAæ‹Ÿåˆ
```python
# åˆå¹¶æºåŸŸå’Œç›®æ ‡åŸŸæ•°æ®
X_combined = np.vstack([X_source, X_target])

# æ‹Ÿåˆæ ¸PCA
kpca = KernelPCA(n_components=n_components, kernel='rbf', gamma=gamma)
X_combined_transformed = kpca.fit_transform(X_combined)
```

#### 2. åŸŸåˆ†ç¦»
```python
n_source = X_source.shape[0]
X_source_kpca = X_combined_transformed[:n_source]
X_target_kpca = X_combined_transformed[n_source:]
```

#### 3. å‡å€¼å¯¹é½
```python
source_mean = np.mean(X_source_kpca, axis=0)
target_mean = np.mean(X_target_kpca, axis=0)
X_target_aligned = X_target_kpca + (source_mean - target_mean)
```

### Mean-Std å¯¹é½æµç¨‹

#### 1. ç»Ÿè®¡é‡è®¡ç®—
```python
source_mean = np.mean(X_source, axis=0)
source_std = np.std(X_source, axis=0)
target_mean = np.mean(X_target, axis=0)
target_std = np.std(X_target, axis=0)
```

#### 2. æ ‡å‡†åŒ–å’Œé‡æ–°ç¼©æ”¾
```python
# æ ‡å‡†åŒ–ç›®æ ‡åŸŸ
X_target_normalized = (X_target - target_mean) / (target_std + 1e-8)

# é‡æ–°ç¼©æ”¾åˆ°æºåŸŸåˆ†å¸ƒ
X_target_aligned = X_target_normalized * source_std + source_mean
```

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹å’Œå…¸å‹å‘½ä»¤

### åŸºæœ¬ç”¨æ³•
```bash
# äºŒåˆ†æ³•ï¼ˆé»˜è®¤ç›®æ ‡åŸŸBï¼‰
python scripts/run_analytical_mmd.py --model-type auto --method linear

# äºŒåˆ†æ³•ï¼ˆç›®æ ‡åŸŸCï¼‰
python scripts/run_analytical_mmd.py --model-type auto --method linear --target-domain C

# ä¸‰åˆ†æ³•ï¼ˆé»˜è®¤ç›®æ ‡åŸŸBï¼‰
python scripts/run_analytical_mmd.py --model-type auto --method linear --data-split-strategy three-way

# ä¸‰åˆ†æ³•ï¼ˆç›®æ ‡åŸŸCï¼‰
python scripts/run_analytical_mmd.py --model-type auto --method linear --data-split-strategy three-way --target-domain C

# ä¸‰åˆ†æ³• + è´å¶æ–¯ä¼˜åŒ–ï¼ˆç›®æ ‡åŸŸBï¼‰
python scripts/run_analytical_mmd.py --model-type auto --method linear --data-split-strategy three-way --use-bayesian-optimization

# ä¸‰åˆ†æ³• + è´å¶æ–¯ä¼˜åŒ–ï¼ˆç›®æ ‡åŸŸCï¼‰
python scripts/run_analytical_mmd.py --model-type auto --method linear --data-split-strategy three-way --use-bayesian-optimization --target-domain C
```

### é«˜çº§é…ç½®
```bash
# è‡ªå®šä¹‰éªŒè¯é›†æ¯”ä¾‹ï¼ˆç›®æ ‡åŸŸBï¼‰
python scripts/run_analytical_mmd.py \
    --model-type auto \
    --method linear \
    --data-split-strategy three-way \
    --validation-split 0.7

# è‡ªå®šä¹‰éªŒè¯é›†æ¯”ä¾‹ï¼ˆç›®æ ‡åŸŸCï¼‰
python scripts/run_analytical_mmd.py \
    --model-type auto \
    --method linear \
    --data-split-strategy three-way \
    --validation-split 0.7 \
    --target-domain C

# è´å¶æ–¯ä¼˜åŒ–å‚æ•°è°ƒæ•´ï¼ˆç›®æ ‡åŸŸBï¼‰
python scripts/run_analytical_mmd.py \
    --model-type auto \
    --method linear \
    --data-split-strategy three-way \
    --use-bayesian-optimization \
    --bo-n-calls 100 \
    --bo-random-state 42

# è´å¶æ–¯ä¼˜åŒ–å‚æ•°è°ƒæ•´ï¼ˆç›®æ ‡åŸŸCï¼‰
python scripts/run_analytical_mmd.py \
    --model-type auto \
    --method linear \
    --data-split-strategy three-way \
    --use-bayesian-optimization \
    --bo-n-calls 100 \
    --bo-random-state 42 \
    --target-domain C

# å®Œæ•´é…ç½®ç¤ºä¾‹ï¼ˆç›®æ ‡åŸŸBï¼‰
python scripts/run_analytical_mmd.py \
    --model-type auto \
    --feature-type best7 \
    --method linear \
    --data-split-strategy three-way \
    --validation-split 0.7 \
    --use-bayesian-optimization \
    --bo-n-calls 50 \
    --use-class-conditional \
    --skip-cv-on-a

# å®Œæ•´é…ç½®ç¤ºä¾‹ï¼ˆç›®æ ‡åŸŸCï¼‰
python scripts/run_analytical_mmd.py \
    --model-type auto \
    --feature-type best7 \
    --method linear \
    --data-split-strategy three-way \
    --validation-split 0.7 \
    --use-bayesian-optimization \
    --bo-n-calls 50 \
    --use-class-conditional \
    --skip-cv-on-a \
    --target-domain C
```

### å‚æ•°è°ƒä¼˜
```bash
# Linearæ–¹æ³•å‚æ•°è°ƒä¼˜
python scripts/run_analytical_mmd.py \
    --model-type auto \
    --method linear \
    --lr 0.001 \
    --n-epochs 500 \
    --lambda-reg 1e-4 \
    --use-gradient-clipping

# ä½¿ç”¨ä¿å®ˆé¢„è®¾
python scripts/run_analytical_mmd.py \
    --model-type auto \
    --method linear \
    --use-preset conservative
```

### è´å¶æ–¯MMDä¼˜åŒ–ç”¨æ³•
```bash
# åŸºæœ¬è´å¶æ–¯MMDä¼˜åŒ–ï¼ˆç›®æ ‡åŸŸBï¼‰
python scripts/run_bayesian_mmd_optimization.py --model-type auto --mmd-method linear

# è´å¶æ–¯MMDä¼˜åŒ–ï¼ˆç›®æ ‡åŸŸCï¼‰
python scripts/run_bayesian_mmd_optimization.py --model-type auto --mmd-method linear --target-domain C

# ä½¿ç”¨ç±»æ¡ä»¶MMD + æœ€ä½³7ç‰¹å¾
python scripts/run_bayesian_mmd_optimization.py --model-type auto --feature-type best7 --mmd-method linear --use-class-conditional

# æ ¸PCA MMDä¼˜åŒ–
python scripts/run_bayesian_mmd_optimization.py --model-type auto --mmd-method kpca --target-domain B

# è‡ªå®šä¹‰ä¼˜åŒ–å‚æ•°
python scripts/run_bayesian_mmd_optimization.py \
    --model-type auto \
    --feature-type best7 \
    --mmd-method linear \
    --use-class-conditional \
    --target-domain C \
    --validation-split 0.7 \
    --n-calls 100 \
    --auto-run-mmd-after-bo

# Random Forest + Mean-Std MMD
python scripts/run_bayesian_mmd_optimization.py --model-type rf --mmd-method mean_std --n-calls 30
```

### é›†æˆåˆ°ä¸»è„šæœ¬çš„ç”¨æ³•
```bash
# åœ¨ä¸»è„šæœ¬ä¸­ä½¿ç”¨è´å¶æ–¯MMDä¼˜åŒ–
python scripts/run_analytical_mmd.py \
    --model-type auto \
    --method linear \
    --feature-type best7 \
    --data-split-strategy three-way \
    --use-bayesian-mmd-optimization \
    --bo-n-calls 50 \
    --target-domain B

# ä¼˜åŒ–åè‡ªåŠ¨è¿è¡Œå®Œæ•´å®éªŒ
python scripts/run_analytical_mmd.py \
    --model-type auto \
    --method linear \
    --feature-type best7 \
    --data-split-strategy three-way \
    --use-bayesian-mmd-optimization \
    --auto-run-mmd-after-bo \
    --target-domain C
```

## ğŸ“ è¾“å‡ºç»“æœç»“æ„

### ç›®å½•ç»“æ„
```
# é»˜è®¤ç›®æ ‡åŸŸBçš„ç»“æœ
results_cross_domain_auto_linear_all/
â”œâ”€â”€ results.json                    # ä¸»è¦ç»“æœæ–‡ä»¶
â”œâ”€â”€ experiment_log.txt              # å®éªŒæ—¥å¿—
â”œâ”€â”€ visualizations/                 # å¯è§†åŒ–ç»“æœ
â”‚   â”œâ”€â”€ tsne_comparison_A_to_B.png  # t-SNEå¯¹æ¯”å›¾
â”‚   â”œâ”€â”€ roc_curve_B.png             # ROCæ›²çº¿
â”‚   â””â”€â”€ ...
â”œâ”€â”€ metrics/                        # è¯¦ç»†æŒ‡æ ‡
â””â”€â”€ models/                         # ä¿å­˜çš„æ¨¡å‹

# ç›®æ ‡åŸŸCçš„ç»“æœ
results_cross_domain_auto_linear_all_target_C/
â”œâ”€â”€ results.json                    # ä¸»è¦ç»“æœæ–‡ä»¶
â”œâ”€â”€ experiment_log.txt              # å®éªŒæ—¥å¿—
â”œâ”€â”€ visualizations/                 # å¯è§†åŒ–ç»“æœ
â”‚   â”œâ”€â”€ tsne_comparison_A_to_C.png  # t-SNEå¯¹æ¯”å›¾
â”‚   â”œâ”€â”€ roc_curve_C.png             # ROCæ›²çº¿
â”‚   â””â”€â”€ ...
â”œâ”€â”€ metrics/                        # è¯¦ç»†æŒ‡æ ‡
â””â”€â”€ models/                         # ä¿å­˜çš„æ¨¡å‹
```

### results.json ç»“æ„
```json
{
  "cross_validation_A": {
    "accuracy": 0.8234,
    "auc": 0.8756,
    "f1": 0.8123,
    "fold_results": [...]
  },
  "external_validation_B": {
    "without_domain_adaptation": {
      "accuracy": 0.7123,
      "auc": 0.7456,
      "f1": 0.6987
    },
    "with_domain_adaptation": {
      "accuracy": 0.7834,
      "auc": 0.8123,
      "f1": 0.7654
    }
  },
  "external_validation_C": {
    "without_domain_adaptation": {
      "accuracy": 0.6987,
      "auc": 0.7234,
      "f1": 0.6543
    },
    "with_domain_adaptation": {
      "accuracy": 0.7456,
      "auc": 0.7789,
      "f1": 0.7123
    }
  },
  "experiment_config": {
    "model_type": "auto",
    "feature_type": "all",
    "mmd_method": "linear",
    "use_class_conditional": false,
    "use_threshold_optimizer": false
  }
}
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨
```
é”™è¯¯: æ•°æ®æ–‡ä»¶éªŒè¯å¤±è´¥
è§£å†³: æ£€æŸ¥ config/settings.py ä¸­çš„ DATA_PATHS é…ç½®
```

#### 2. æ¨¡å‹ç±»å‹ä¸å¯ç”¨
```
é”™è¯¯: æ¨¡å‹ç±»å‹ auto ä¸å¯ç”¨
è§£å†³: å®‰è£… autotabpfn åŒ…æˆ–é€‰æ‹©å…¶ä»–æ¨¡å‹ç±»å‹
```

#### 3. MMDè®¡ç®—å¤±è´¥
```
é”™è¯¯: MMDå˜æ¢è¿‡ç¨‹ä¸­å‡ºç°æ•°å€¼ä¸ç¨³å®š
è§£å†³: ä½¿ç”¨ --use-preset conservative æˆ–è°ƒæ•´å­¦ä¹ ç‡
```

#### 4. å†…å­˜ä¸è¶³
```
é”™è¯¯: CUDA out of memory
è§£å†³: å‡å°‘æ‰¹å¤§å° --batch-size 32 æˆ–ä½¿ç”¨CPU --device cpu
```

### è°ƒè¯•æŠ€å·§

#### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—
```bash
python scripts/run_analytical_mmd.py \
    --model-type auto \
    --method linear \
    --log-file debug.log
```

#### 2. ç›‘æ§æ¢¯åº¦
```bash
python scripts/run_analytical_mmd.py \
    --model-type auto \
    --method linear \
    --monitor-gradients
```

#### 3. å¿«é€ŸéªŒè¯
```bash
python scripts/run_analytical_mmd.py \
    --model-type auto \
    --method linear \
    --skip-cv-on-a \
    --no-visualizations
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. è®¡ç®—èµ„æºä¼˜åŒ–
- ä½¿ç”¨GPUåŠ é€Ÿ: `--device cuda`
- è°ƒæ•´æ‰¹å¤§å°: `--batch-size 128`
- å¹¶è¡Œå¤„ç†: è®¾ç½®ç¯å¢ƒå˜é‡ `OMP_NUM_THREADS=4`

### 2. å®éªŒæ•ˆç‡ä¼˜åŒ–
- è·³è¿‡äº¤å‰éªŒè¯: `--skip-cv-on-a`
- ç¦ç”¨å¯è§†åŒ–: `--no-visualizations`
- ä½¿ç”¨å¿«é€Ÿé¢„è®¾: `--model-preset fast`

### 3. ç®—æ³•æ”¶æ•›ä¼˜åŒ–
- ä½¿ç”¨åˆ†é˜¶æ®µè®­ç»ƒ: é»˜è®¤å¯ç”¨
- å¯ç”¨æ¢¯åº¦è£å‰ª: `--use-gradient-clipping`
- è°ƒæ•´å­¦ä¹ ç‡: `--lr 0.001`

## âœ… ä¿®å¤åçš„å¯è§†åŒ–åŠŸèƒ½

### ç°åœ¨ä¼šç”Ÿæˆçš„å¯è§†åŒ–æ–‡ä»¶
```
results_cross_domain_auto_linear_best7/
â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ performance_comparison.png           # æ€§èƒ½å¯¹æ¯”å›¾
â”‚   â”œâ”€â”€ AUTO-MMD-LINEAR_tsne_comparison.png  # t-SNEå¯¹æ¯”å›¾
â”‚   â”œâ”€â”€ AUTO-MMD-LINEAR_feature_histograms.png # ç‰¹å¾åˆ†å¸ƒç›´æ–¹å›¾
â”‚   â”œâ”€â”€ AUTO-MMD-LINEAR_statistics_table.png   # ç»Ÿè®¡è¡¨æ ¼
â”‚   â””â”€â”€ A_to_C/                              # å¦‚æœæœ‰æ•°æ®é›†C
â”‚       â”œâ”€â”€ AUTO-MMD-LINEAR_A_to_C_tsne_comparison.png
â”‚       â””â”€â”€ ...
```

### å¯è§†åŒ–å†…å®¹è¯´æ˜
1. **t-SNEå¯¹æ¯”å›¾**: æ˜¾ç¤ºåŸŸé€‚åº”å‰åçš„æ•°æ®åˆ†å¸ƒå˜åŒ–
2. **ç‰¹å¾åˆ†å¸ƒç›´æ–¹å›¾**: å¯¹æ¯”æºåŸŸã€ç›®æ ‡åŸŸå’Œé€‚åº”åçš„ç‰¹å¾åˆ†å¸ƒ
3. **ç»Ÿè®¡è¡¨æ ¼**: è¯¦ç»†çš„ç»Ÿè®¡æŒ‡æ ‡å¯¹æ¯”
4. **æ€§èƒ½å¯¹æ¯”å›¾**: ä¸åŒæ•°æ®é›†ä¸Šçš„æ¨¡å‹æ€§èƒ½å¯¹æ¯”

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.1  
**æœ€åæ›´æ–°**: 2024å¹´12æœˆ  
**ç»´æŠ¤è€…**: Analytical MMD A2B Feature58 é¡¹ç›®å›¢é˜Ÿ

## ğŸ”§ è´å¶æ–¯ä¼˜åŒ–æ¨¡å—é›†æˆ

### æ–°å¢åŠŸèƒ½ï¼šè´å¶æ–¯è¶…å‚æ•°ä¼˜åŒ–

#### æ¦‚è¿°
è´å¶æ–¯ä¼˜åŒ–æ¨¡å—å®ç°äº†åŸºäºç›®æ ‡åŸŸéªŒè¯é›†çš„è¶…å‚æ•°ä¼˜åŒ–ï¼Œé‡‡ç”¨ä¸‰åˆ†æ³•æ•°æ®åˆ’åˆ†ç­–ç•¥ï¼š

1. **AåŸŸè®­ç»ƒé›†**: ç”¨äºæ¨¡å‹è®­ç»ƒ
2. **BåŸŸéªŒè¯é›†**: ç”¨äºè´å¶æ–¯ä¼˜åŒ–ç›®æ ‡å‡½æ•°è¯„ä¼° (80%)
3. **BåŸŸä¿ç•™æµ‹è¯•é›†**: ç”¨äºæœ€ç»ˆæ¨¡å‹æ³›åŒ–èƒ½åŠ›è¯„ä¼° (20%)

#### ä½¿ç”¨æ–¹æ³•

##### 1. ç‹¬ç«‹è¿è¡Œè´å¶æ–¯ä¼˜åŒ–
```bash
# åŸºæœ¬ç”¨æ³•
python scripts/run_bayesian_optimization.py --model-type auto --feature-type best7

# é«˜çº§é…ç½®
python scripts/run_bayesian_optimization.py \
    --model-type auto \
    --feature-type best7 \
    --validation-split 0.7 \
    --n-calls 50 \
    --no-categorical
```

##### 2. é›†æˆåˆ°ä¸»å·¥ä½œæµç¨‹
åœ¨ `run_analytical_mmd.py` ä¸­æ·»åŠ è´å¶æ–¯ä¼˜åŒ–é€‰é¡¹ï¼š

```python
# æ·»åŠ å‘½ä»¤è¡Œå‚æ•°
parser.add_argument('--use-bayesian-optimization', action='store_true',
                   help='ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜')
parser.add_argument('--bo-n-calls', type=int, default=50,
                   help='è´å¶æ–¯ä¼˜åŒ–è¿­ä»£æ¬¡æ•°')

# åœ¨ä¸»å‡½æ•°ä¸­é›†æˆ
if args.use_bayesian_optimization:
    from analytical_mmd_A2B_feature58.modeling.bayesian_optimizer import run_bayesian_optimization
    
    # è¿è¡Œè´å¶æ–¯ä¼˜åŒ–
    bo_results = run_bayesian_optimization(
        model_type=args.model_type,
        feature_type=args.feature_type,
        n_calls=args.bo_n_calls,
        save_path=os.path.join(save_path, 'bayesian_optimization')
    )
    
    # ä½¿ç”¨ä¼˜åŒ–åçš„å‚æ•°
    optimized_params = bo_results['optimization_results']['best_params']
    model_kwargs.update(optimized_params)
```