#!/usr/bin/env python3
"""
è´å¶æ–¯ä¼˜åŒ–åŸŸé€‚åº”å®éªŒè„šæœ¬

ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–è‡ªåŠ¨æœç´¢æœ€ä½³çš„æ¨¡å‹å‚æ•°å’ŒåŸŸé€‚åº”å‚æ•°ç»„åˆã€‚
æ”¯æŒå¤šç§åŸŸé€‚åº”æ–¹æ³•å’Œæ€§èƒ½ç›®æ ‡çº¦æŸã€‚

æ€§èƒ½ç›®æ ‡:
- æºåŸŸ10æŠ˜äº¤å‰éªŒè¯å¹³å‡AUC â‰¥ 80%
- ç›®æ ‡åŸŸç›´æ¥é¢„æµ‹AUC â‰¥ 68%  
- ç›®æ ‡åŸŸCORALåŸŸé€‚åº”åAUC â‰¥ 70%

ä½¿ç”¨ç¤ºä¾‹:
python scripts/run_bayesian_optimization_domain_adaptation.py --target-domain B --domain-adapt-method coral
"""

import argparse
import logging
import os
import sys
import time
from typing import Optional, Dict, Any

# è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
# è®¡ç®— TabPFN é¡¹ç›®çš„æ ¹ç›®å½•
tabpfn_root = os.path.dirname(os.path.dirname(script_dir))

# å°† TabPFN é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° Python è·¯å¾„
sys.path.insert(0, tabpfn_root)

try:
    from analytical_mmd_A2B_feature58.modeling.standard_domain_adaptation_optimizer import StandardDomainAdaptationOptimizer
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿æ‚¨åœ¨æ­£ç¡®çš„ç›®å½•ä¸­è¿è¡Œæ­¤è„šæœ¬ï¼Œå¹¶ä¸”æ‰€æœ‰ä¾èµ–é¡¹éƒ½å·²å®‰è£…ã€‚")
    print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"è„šæœ¬ç›®å½•: {script_dir}")
    print(f"TabPFNæ ¹ç›®å½•: {tabpfn_root}")
    sys.exit(1)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='è´å¶æ–¯ä¼˜åŒ–åŸŸé€‚åº”å®éªŒ - è‡ªåŠ¨æœç´¢æœ€ä½³å‚æ•°ç»„åˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºæœ¬ä½¿ç”¨ï¼ˆAâ†’Bï¼ŒCORALæ–¹æ³•ï¼‰
  python scripts/run_bayesian_optimization_domain_adaptation.py --target-domain B --domain-adapt-method coral

  # æŒ‡å®šç›®æ ‡åŸŸä¸ºCï¼ˆAâ†’Cï¼ŒMMDçº¿æ€§æ–¹æ³•ï¼‰
  python scripts/run_bayesian_optimization_domain_adaptation.py --target-domain C --domain-adapt-method linear

  # ä½¿ç”¨ç±»æ¡ä»¶åŸŸé€‚åº”
  python scripts/run_bayesian_optimization_domain_adaptation.py --target-domain B --domain-adapt-method coral --use-class-conditional

  # ç¦ç”¨åŸŸé€‚åº”ï¼ˆåªä¼˜åŒ–æ¨¡å‹å‚æ•°ï¼‰
  python scripts/run_bayesian_optimization_domain_adaptation.py --target-domain B --no-mmd
  
  # åŒ…å«åŸºçº¿æ¨¡å‹å¯¹æ¯”å’Œæ›´å¤šä¼˜åŒ–è¿­ä»£
  python scripts/run_bayesian_optimization_domain_adaptation.py --target-domain B --domain-adapt-method coral --include-baselines --n-calls 100

æ€§èƒ½ç›®æ ‡:
  - æºåŸŸ10æŠ˜äº¤å‰éªŒè¯å¹³å‡AUC â‰¥ 80%
  - ç›®æ ‡åŸŸç›´æ¥é¢„æµ‹AUC â‰¥ 68%
  - ç›®æ ‡åŸŸCORALåŸŸé€‚åº”åAUC â‰¥ 70%
        """
    )
    
    # å®éªŒè®¾è®¡å‚æ•°
    parser.add_argument(
        '--target-domain',
        type=str,
        choices=['B', 'C'],
        default='B',
        help='ç›®æ ‡åŸŸé€‰æ‹©: B(æ²³å—ç™Œç—‡åŒ»é™¢) æˆ– C(å¹¿å·åŒ»ç§‘å¤§å­¦) (é»˜è®¤: B)'
    )
    
    parser.add_argument(
        '--feature-type',
        type=str,
        choices=['best7', 'all'],
        default='best7',
        help='ç‰¹å¾ç±»å‹ (é»˜è®¤: best7)'
    )
    
    parser.add_argument(
        '--domain-adapt-method',
        type=str,
        choices=['linear', 'kpca', 'mean_std', 'coral', 'adaptive_coral', 'mean_variance', 'adaptive_mean_variance', 'tca', 'adaptive_tca', 'jda', 'adaptive_jda'],
        default='coral',
        help='åŸŸé€‚åº”æ–¹æ³• (é»˜è®¤: coral)'
    )
    
    parser.add_argument(
        '--use-class-conditional',
        action='store_true',
        help='ä½¿ç”¨ç±»æ¡ä»¶åŸŸé€‚åº”'
    )
    
    parser.add_argument(
        '--no-categorical',
        action='store_true',
        help='ç¦ç”¨ç±»åˆ«ç‰¹å¾'
    )
    
    parser.add_argument(
        '--no-mmd',
        action='store_true',
        help='ç¦ç”¨åŸŸé€‚åº”ï¼ˆåªä¼˜åŒ–æ¨¡å‹å‚æ•°ï¼‰'
    )
    
    # æ–°å¢åŸºçº¿æ¨¡å‹å‚æ•°
    parser.add_argument(
        '--include-baselines',
        action='store_true',
        help='åŒ…å«åŸºçº¿æ¨¡å‹ï¼ˆPKUPHå’ŒMayoï¼‰å¯¹æ¯”è¯„ä¼°'
    )
    
    # è´å¶æ–¯ä¼˜åŒ–å‚æ•°
    parser.add_argument(
        '--n-calls',
        type=int,
        default=50,
        help='è´å¶æ–¯ä¼˜åŒ–è¿­ä»£æ¬¡æ•° (é»˜è®¤: 50)'
    )
    
    parser.add_argument(
        '--source-cv-folds',
        type=int,
        default=10,
        help='æºåŸŸäº¤å‰éªŒè¯æŠ˜æ•° (é»˜è®¤: 10)'
    )
    
    # æ•°æ®åˆ’åˆ†å‚æ•°
    parser.add_argument(
        '--source-val-split',
        type=float,
        default=0.2,
        help='æºåŸŸéªŒè¯é›†æ¯”ä¾‹ (é»˜è®¤: 0.2)'
    )
    
    # è¾“å‡ºç›¸å…³å‚æ•°
    parser.add_argument(
        '--output-dir',
        type=str,
        help='ç»“æœä¿å­˜ç›®å½• (é»˜è®¤: è‡ªåŠ¨ç”Ÿæˆ)'
    )
    
    parser.add_argument(
        '--random-state',
        type=int,
        default=42,
        help='éšæœºç§å­ (é»˜è®¤: 42)'
    )
    
    return parser.parse_args()


def setup_logging(log_file: Optional[str] = None) -> logging.Logger:
    """è®¾ç½®æ—¥å¿—"""
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    # æ¸…é™¤ç°æœ‰çš„å¤„ç†å™¨
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    # åˆ›å»ºæ ¼å¼å™¨
    formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # æ–‡ä»¶å¤„ç†å™¨
    if log_file:
        log_dir = os.path.dirname(log_file)
        if log_dir:
            os.makedirs(log_dir, exist_ok=True)
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
    
    return logger


def get_performance_targets() -> Dict[str, float]:
    """è·å–æ€§èƒ½ç›®æ ‡çº¦æŸ"""
    return {
        'source_cv_auc_min': 0.80,  # æºåŸŸ10æŠ˜CVå¹³å‡AUC â‰¥ 80%
        'target_direct_auc_min': 0.68,  # ç›®æ ‡åŸŸç›´æ¥é¢„æµ‹AUC â‰¥ 68%
        'target_adapted_auc_min': 0.70  # ç›®æ ‡åŸŸåŸŸé€‚åº”åAUC â‰¥ 70%
    }


def check_performance_targets(results: Dict[str, Any]) -> Dict[str, Any]:
    """æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ€§èƒ½ç›®æ ‡"""
    targets = get_performance_targets()
    evaluation = results.get('evaluation', {})
    
    # æ£€æŸ¥æºåŸŸCVæ€§èƒ½
    source_cv = evaluation.get('source_cv', {})
    source_cv_auc = source_cv.get('auc', {}).get('mean', 0.0) if source_cv else 0.0
    source_cv_ok = source_cv_auc >= targets['source_cv_auc_min']
    
    # æ£€æŸ¥ç›®æ ‡åŸŸç›´æ¥é¢„æµ‹æ€§èƒ½
    target_direct = evaluation.get('target_direct', {})
    target_direct_auc = target_direct.get('auc', 0.0)
    target_direct_ok = target_direct_auc >= targets['target_direct_auc_min']
    
    # æ£€æŸ¥ç›®æ ‡åŸŸåŸŸé€‚åº”åæ€§èƒ½
    target_adapted = evaluation.get('target_adapted', {})
    target_adapted_auc = target_adapted.get('auc', 0.0) if target_adapted else 0.0
    target_adapted_ok = target_adapted_auc >= targets['target_adapted_auc_min']
    
    return {
        'source_cv_target_met': source_cv_ok,
        'target_direct_target_met': target_direct_ok,
        'target_adapted_target_met': target_adapted_ok,
        'all_targets_met': source_cv_ok and target_direct_ok and target_adapted_ok,
        'metrics': {
            'source_cv_auc': source_cv_auc,
            'target_direct_auc': target_direct_auc,
            'target_adapted_auc': target_adapted_auc
        },
        'targets': targets
    }


def generate_output_dir(args: argparse.Namespace) -> str:
    """ç”Ÿæˆè¾“å‡ºç›®å½•åç§°"""
    domain_method = getattr(args, 'domain_adapt_method', 'coral')
    components = [
        'results_bayesian_optimization',
        'auto',  # å›ºå®šä½¿ç”¨autoæ¨¡å‹
        domain_method,
        args.feature_type
    ]
    
    if args.use_class_conditional:
        components.append('class_conditional')
    
    if args.no_categorical:
        components.append('no_categorical')
    
    if args.no_mmd:
        components.append('no_domain_adaptation')
    
    components.append(f'target_{args.target_domain}')
    components.append(f'calls_{args.n_calls}')
    components.append(f'cv{args.source_cv_folds}')
    
    # æ·»åŠ æ—¶é—´æˆ³
    timestamp = time.strftime('%Y%m%d_%H%M%S')
    components.append(timestamp)
    
    return '_'.join(components)


class BayesianOptimizationDomainAdaptation:
    """è´å¶æ–¯ä¼˜åŒ–åŸŸé€‚åº”å®éªŒç±»"""
    
    def __init__(self, args: argparse.Namespace):
        self.args = args
        
        # ç”Ÿæˆä¿å­˜è·¯å¾„
        if args.output_dir:
            self.save_path = args.output_dir
        else:
            self.save_path = generate_output_dir(args)
        
        # åˆ›å»ºä¼˜åŒ–å™¨ï¼ˆè¿›è¡ŒçœŸæ­£çš„è´å¶æ–¯ä¼˜åŒ–ï¼‰
        self.optimizer = StandardDomainAdaptationOptimizer(
            model_type='auto',
            feature_type=args.feature_type,
            mmd_method=getattr(args, 'domain_adapt_method', 'coral'),
            use_class_conditional=args.use_class_conditional,
            use_categorical=not args.no_categorical,
            source_val_split=args.source_val_split,
            cv_folds=args.source_cv_folds,  # ä½¿ç”¨æŒ‡å®šçš„CVæŠ˜æ•°
            n_calls=args.n_calls,  # ä½¿ç”¨æŒ‡å®šçš„ä¼˜åŒ–è¿­ä»£æ¬¡æ•°
            random_state=args.random_state,
            target_domain=args.target_domain,
            save_path=self.save_path,
            use_source_cv_for_mmd_tuning=not args.no_mmd  # å¦‚æœå¯ç”¨åŸŸé€‚åº”åˆ™è°ƒä¼˜åŸŸé€‚åº”å‚æ•°
        )
    
    def run_experiment(self) -> Dict[str, Any]:
        """è¿è¡Œè´å¶æ–¯ä¼˜åŒ–å®éªŒ"""
        logging.info("=" * 80)
        logging.info("è´å¶æ–¯ä¼˜åŒ–åŸŸé€‚åº”å®éªŒ")
        logging.info("=" * 80)
        
        # æ‰“å°å®éªŒé…ç½®
        logging.info("å®éªŒé…ç½®:")
        logging.info(f"  æ¨¡å‹ç±»å‹: auto (AutoTabPFN)")
        logging.info(f"  ç‰¹å¾ç±»å‹: {self.args.feature_type}")
        domain_method = getattr(self.args, 'domain_adapt_method', 'coral')
        logging.info(f"  åŸŸé€‚åº”æ–¹æ³•: {domain_method}")
        logging.info(f"  ç±»æ¡ä»¶åŸŸé€‚åº”: {self.args.use_class_conditional}")
        logging.info(f"  ä½¿ç”¨ç±»åˆ«ç‰¹å¾: {not self.args.no_categorical}")
        logging.info(f"  ä½¿ç”¨åŸŸé€‚åº”: {not self.args.no_mmd}")
        logging.info(f"  åŒ…å«åŸºçº¿æ¨¡å‹: {self.args.include_baselines}")
        logging.info(f"  ç›®æ ‡åŸŸ: {self.args.target_domain}")
        logging.info("")
        logging.info("ä¼˜åŒ–é…ç½®:")
        logging.info(f"  è´å¶æ–¯ä¼˜åŒ–è¿­ä»£æ¬¡æ•°: {self.args.n_calls}")
        logging.info(f"  æºåŸŸäº¤å‰éªŒè¯æŠ˜æ•°: {self.args.source_cv_folds}")
        logging.info(f"  åŸŸé€‚åº”å®éªŒ: æ•°æ®é›†AæŒ‰{int((1-self.args.source_val_split)*100)}%/{int(self.args.source_val_split*100)}%åˆ’åˆ†ä¸ºè®­ç»ƒ/éªŒè¯é›†")
        logging.info(f"  éšæœºç§å­: {self.args.random_state}")
        logging.info(f"  ç»“æœä¿å­˜è·¯å¾„: {self.save_path}")
        
        # æ˜¾ç¤ºæ€§èƒ½ç›®æ ‡
        targets = get_performance_targets()
        logging.info("\næ€§èƒ½ç›®æ ‡:")
        logging.info(f"  æºåŸŸ{self.args.source_cv_folds}æŠ˜CVå¹³å‡AUC â‰¥ {targets['source_cv_auc_min']:.1%}")
        logging.info(f"  ç›®æ ‡åŸŸç›´æ¥é¢„æµ‹AUC â‰¥ {targets['target_direct_auc_min']:.1%}")
        logging.info(f"  ç›®æ ‡åŸŸåŸŸé€‚åº”åAUC â‰¥ {targets['target_adapted_auc_min']:.1%}")
        
        try:
            # 1. åŠ è½½å’Œå‡†å¤‡æ•°æ®
            self.optimizer.load_and_prepare_data()
            
            # 2. è¯„ä¼°åŸºçº¿æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            baseline_results = None
            if self.args.include_baselines:
                logging.info("\n" + "=" * 50)
                logging.info("è¯„ä¼°åŸºçº¿æ¨¡å‹ (PKUPH & Mayo)")
                logging.info("=" * 50)
                baseline_results = self.optimizer.evaluate_baseline_models_performance()
            
            # 3. è¿è¡Œè´å¶æ–¯ä¼˜åŒ–
            logging.info("\n" + "=" * 50)
            logging.info("è¿è¡Œè´å¶æ–¯ä¼˜åŒ–")
            logging.info("=" * 50)
            optimization_results = self.optimizer.run_optimization()
            
            # 4. è®­ç»ƒæœ€ç»ˆæ¨¡å‹
            logging.info("\n" + "=" * 50)
            logging.info("è®­ç»ƒæœ€ç»ˆæ¨¡å‹")
            logging.info("=" * 50)
            self.optimizer.train_final_model()
            
            # 5. è¯„ä¼°AutoTabPFNæºåŸŸæ€§èƒ½ï¼ˆCVï¼‰
            autotabpfn_source_cv = None
            if self.args.source_cv_folds > 0:
                logging.info("\n" + "=" * 50)
                logging.info("è¯„ä¼°AutoTabPFNæºåŸŸäº¤å‰éªŒè¯æ€§èƒ½")
                logging.info("=" * 50)
                
                try:
                    autotabpfn_source_cv = self.optimizer.evaluate_autotabpfn_source_cv(cv_folds=self.args.source_cv_folds)
                except Exception as e:
                    logging.error(f"AutoTabPFNæºåŸŸCVè¯„ä¼°å¤±è´¥: {e}")
            
            # 6. è¯„ä¼°æœ€ç»ˆæ¨¡å‹
            logging.info("\n" + "=" * 50)
            logging.info("è¯„ä¼°æœ€ç»ˆæ¨¡å‹")
            logging.info("=" * 50)
            evaluation_results = self.optimizer.evaluate_final_model()
            
            # å°†æºåŸŸCVç»“æœæ·»åŠ åˆ°è¯„ä¼°ç»“æœä¸­
            if autotabpfn_source_cv is not None:
                evaluation_results['source_cv'] = autotabpfn_source_cv
            
            # 7. æ£€æŸ¥æ€§èƒ½ç›®æ ‡
            complete_results = {
                'optimization': optimization_results,
                'evaluation': evaluation_results,
                'baseline_models': baseline_results,
                'config': {
                    'model_type': 'auto',
                    'feature_type': self.args.feature_type,
                    'domain_adapt_method': domain_method,
                    'target_domain': self.args.target_domain,
                    'include_baselines': self.args.include_baselines,
                    'n_calls': self.args.n_calls,
                    'source_cv_folds': self.args.source_cv_folds,
                    'experiment_type': 'bayesian_optimization'
                }
            }
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ€§èƒ½ç›®æ ‡
            target_check = check_performance_targets(complete_results)
            complete_results['performance_targets'] = target_check
            
            # 8. ä¿å­˜ç»“æœ
            if baseline_results:
                self.optimizer.save_results(optimization_results, evaluation_results, baseline_results)
            else:
                self.optimizer.save_results(optimization_results, evaluation_results)
            
            # 9. æ‰“å°ä¸»è¦ç»“æœ
            self._print_results(evaluation_results, baseline_results, target_check)
            
            return complete_results
            
        except Exception as e:
            logging.error(f"å®éªŒå¤±è´¥: {e}")
            import traceback
            logging.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            raise
    
    def _print_results(self, evaluation_results: Dict[str, Any], baseline_results: Optional[Dict[str, Any]] = None, target_check: Optional[Dict[str, Any]] = None) -> None:
        """æ‰“å°å®éªŒç»“æœ"""
        logging.info("\n" + "=" * 80)
        logging.info("è´å¶æ–¯ä¼˜åŒ–åŸŸé€‚åº”å®éªŒå®Œæˆ! ä¸»è¦ç»“æœ:")
        logging.info("=" * 80)
        
        # æ‰“å°åŸºçº¿æ¨¡å‹ç»“æœ
        if baseline_results and self.args.include_baselines:
            logging.info("\nğŸ” åŸºçº¿æ¨¡å‹æ€§èƒ½å¯¹æ¯”:")
            logging.info("-" * 50)
            
            for model_name, results in baseline_results.items():
                if 'error' not in results:
                    source_cv = results['source_cv']
                    source_val = results['source_validation']
                    target_direct = results['target_direct']
                    
                    logging.info(f"\n{model_name.upper()} æ¨¡å‹:")
                    logging.info(f"  æºåŸŸ10æŠ˜CV - AUC: {source_cv['auc']['mean']:.4f} Â± {source_cv['auc']['std']:.4f}")
                    logging.info(f"  æºåŸŸ10æŠ˜CV - ACC: {source_cv['accuracy']['mean']:.4f} Â± {source_cv['accuracy']['std']:.4f}")
                    logging.info(f"  æºåŸŸ10æŠ˜CV - F1:  {source_cv['f1']['mean']:.4f} Â± {source_cv['f1']['std']:.4f}")
                    logging.info(f"  æºåŸŸéªŒè¯é›† - AUC: {source_val['auc']:.4f}")
                    logging.info(f"  ç›®æ ‡åŸŸæµ‹è¯• - AUC: {target_direct['auc']:.4f}")
                    
                    # è®¡ç®—åŸŸå·®è· - æ·»åŠ é™¤é›¶æ£€æŸ¥
                    domain_gap = source_val['auc'] - target_direct['auc']
                    if source_val['auc'] > 0:
                        logging.info(f"  åŸŸå·®è·: {domain_gap:.4f} ({domain_gap/source_val['auc']*100:.1f}%)")
                    else:
                        logging.info(f"  åŸŸå·®è·: {domain_gap:.4f} (æºåŸŸAUCä¸º0ï¼Œæ— æ³•è®¡ç®—ç™¾åˆ†æ¯”)")
                        logging.warning(f"  {model_name.upper()}æ¨¡å‹åœ¨æºåŸŸéªŒè¯é›†ä¸Šè¡¨ç°å¼‚å¸¸ï¼ŒAUCä¸º0")
                else:
                    logging.error(f"{model_name.upper()} æ¨¡å‹è¯„ä¼°å¤±è´¥: {results['error']}")
        
        # æ‰“å°AutoTabPFNç»“æœ
        logging.info("\nğŸš€ AutoTabPFNæ¨¡å‹æ€§èƒ½:")
        logging.info("-" * 50)
        
        source_metrics = evaluation_results['source_validation']
        direct_metrics = evaluation_results['target_direct']
        adapted_metrics = evaluation_results['target_adapted']
        source_cv_metrics = evaluation_results.get('source_cv')
        
        logging.info("æœ€ç»ˆæ¨¡å‹æ€§èƒ½:")
        
        # æ˜¾ç¤ºæºåŸŸè¯„ä¼°ç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if source_cv_metrics:
            if self.args.source_cv_folds > 0:
                logging.info(f"  æºåŸŸ{self.args.source_cv_folds}æŠ˜CV (å…¨éƒ¨æ•°æ®é›†A) - AUC: {source_cv_metrics['auc']['mean']:.4f} Â± {source_cv_metrics['auc']['std']:.4f}")
                logging.info(f"  æºåŸŸ{self.args.source_cv_folds}æŠ˜CV (å…¨éƒ¨æ•°æ®é›†A) - ACC: {source_cv_metrics['accuracy']['mean']:.4f} Â± {source_cv_metrics['accuracy']['std']:.4f}")
                logging.info(f"  æºåŸŸ{self.args.source_cv_folds}æŠ˜CV (å…¨éƒ¨æ•°æ®é›†A) - F1:  {source_cv_metrics['f1']['mean']:.4f} Â± {source_cv_metrics['f1']['std']:.4f}")
            else:
                logging.info(f"  æºåŸŸ8:2åˆ’åˆ† (å…¨éƒ¨æ•°æ®é›†A) - AUC: {source_cv_metrics['auc']['mean']:.4f} Â± {source_cv_metrics['auc']['std']:.4f}")
                logging.info(f"  æºåŸŸ8:2åˆ’åˆ† (å…¨éƒ¨æ•°æ®é›†A) - ACC: {source_cv_metrics['accuracy']['mean']:.4f} Â± {source_cv_metrics['accuracy']['std']:.4f}")
                logging.info(f"  æºåŸŸ8:2åˆ’åˆ† (å…¨éƒ¨æ•°æ®é›†A) - F1:  {source_cv_metrics['f1']['mean']:.4f} Â± {source_cv_metrics['f1']['std']:.4f}")
            logging.info("")
        
        logging.info(f"  æºåŸŸéªŒè¯é›† (80%æ•°æ®é›†Aç”¨äºåŸŸé€‚åº”) AUC: {source_metrics['auc']:.4f}")
        logging.info(f"  æºåŸŸéªŒè¯é›† (80%æ•°æ®é›†Aç”¨äºåŸŸé€‚åº”) ACC: {source_metrics['acc']:.4f}")
        logging.info(f"  æºåŸŸéªŒè¯é›† (80%æ•°æ®é›†Aç”¨äºåŸŸé€‚åº”) F1:  {source_metrics['f1']:.4f}")
        logging.info(f"  ç›®æ ‡åŸŸç›´æ¥é¢„æµ‹ AUC: {direct_metrics['auc']:.4f}")
        logging.info(f"  ç›®æ ‡åŸŸç›´æ¥é¢„æµ‹ ACC: {direct_metrics['acc']:.4f}")
        logging.info(f"  ç›®æ ‡åŸŸç›´æ¥é¢„æµ‹ F1:  {direct_metrics['f1']:.4f}")
        
        if adapted_metrics and not self.args.no_mmd:
            adapted_auc = adapted_metrics['auc']
            direct_auc = direct_metrics['auc']
            improvement = adapted_auc - direct_auc
            improvement_pct = improvement / direct_auc * 100 if direct_auc > 0 else 0
            
            logging.info(f"  ç›®æ ‡åŸŸåŸŸé€‚åº”å AUC: {adapted_auc:.4f}")
            logging.info(f"  ç›®æ ‡åŸŸåŸŸé€‚åº”å ACC: {adapted_metrics['acc']:.4f}")
            logging.info(f"  ç›®æ ‡åŸŸåŸŸé€‚åº”å F1:  {adapted_metrics['f1']:.4f}")
            if direct_auc > 0:
                logging.info(f"  åŸŸé€‚åº”æ”¹è¿›: {improvement:.4f} ({improvement_pct:.1f}%)")
            else:
                logging.info(f"  åŸŸé€‚åº”æ”¹è¿›: {improvement:.4f} (ç›´æ¥é¢„æµ‹AUCä¸º0ï¼Œæ— æ³•è®¡ç®—ç™¾åˆ†æ¯”)")
            
            if improvement > 0:
                logging.info("  âœ“ åŸŸé€‚åº”æœ‰æ•ˆæå‡äº†è·¨åŸŸæ€§èƒ½")
            else:
                logging.info("  âœ— åŸŸé€‚åº”æœªèƒ½æå‡è·¨åŸŸæ€§èƒ½")
        else:
            logging.info("  æœªè¿›è¡ŒåŸŸé€‚åº”ï¼ˆåŸŸé€‚åº”è¢«ç¦ç”¨ï¼‰")
        
        # æ€§èƒ½åˆ†æå’Œå¯¹æ¯”
        logging.info("\nğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”åˆ†æ:")
        logging.info("-" * 50)
        
        # AutoTabPFNåŸŸå·®è·
        source_auc = source_metrics['auc']
        target_direct_auc = direct_metrics['auc']
        autotabpfn_domain_gap = source_auc - target_direct_auc
        
        if source_auc > 0:
            logging.info(f"AutoTabPFN åŸŸå·®è·: {autotabpfn_domain_gap:.4f} ({autotabpfn_domain_gap/source_auc*100:.1f}%)")
        else:
            logging.info(f"AutoTabPFN åŸŸå·®è·: {autotabpfn_domain_gap:.4f} (æºåŸŸAUCä¸º0ï¼Œæ— æ³•è®¡ç®—ç™¾åˆ†æ¯”)")
        
        # ä¸åŸºçº¿æ¨¡å‹å¯¹æ¯”
        if baseline_results and self.args.include_baselines:
            logging.info("\nåŸºçº¿æ¨¡å‹ vs AutoTabPFN (ç›®æ ‡åŸŸAUCå¯¹æ¯”):")
            
            for model_name, results in baseline_results.items():
                if 'error' not in results:
                    baseline_target_auc = results['target_direct']['auc']
                    autotabpfn_auc = adapted_metrics['auc'] if adapted_metrics and not self.args.no_mmd else direct_metrics['auc']
                    
                    improvement_vs_baseline = autotabpfn_auc - baseline_target_auc
                    improvement_pct_vs_baseline = improvement_vs_baseline / baseline_target_auc * 100 if baseline_target_auc > 0 else 0
                    
                    if baseline_target_auc > 0:
                        logging.info(f"  AutoTabPFN vs {model_name.upper()}: {improvement_vs_baseline:+.4f} ({improvement_pct_vs_baseline:+.1f}%)")
                    else:
                        logging.info(f"  AutoTabPFN vs {model_name.upper()}: {improvement_vs_baseline:+.4f} (åŸºçº¿AUCä¸º0ï¼Œæ— æ³•è®¡ç®—ç™¾åˆ†æ¯”)")
                    
                    if improvement_vs_baseline > 0:
                        logging.info(f"    âœ“ AutoTabPFNä¼˜äº{model_name.upper()}æ¨¡å‹")
                    else:
                        logging.info(f"    âœ— AutoTabPFNæœªèƒ½è¶…è¶Š{model_name.upper()}æ¨¡å‹")
        
        if autotabpfn_domain_gap > 0.1:
            logging.info("\nâš ï¸  å­˜åœ¨æ˜¾è‘—çš„åŸŸå·®è·ï¼ŒåŸŸé€‚åº”å¾ˆæœ‰å¿…è¦")
        elif autotabpfn_domain_gap > 0.05:
            logging.info("\nâš ï¸  å­˜åœ¨ä¸­ç­‰çš„åŸŸå·®è·ï¼ŒåŸŸé€‚åº”å¯èƒ½æœ‰å¸®åŠ©")
        else:
            logging.info("\nâœ“ åŸŸå·®è·è¾ƒå°ï¼Œæ¨¡å‹å…·æœ‰è‰¯å¥½çš„è·¨åŸŸæ³›åŒ–èƒ½åŠ›")
        
        # æ˜¾ç¤ºæ€§èƒ½ç›®æ ‡è¾¾æˆæƒ…å†µ
        if target_check:
            logging.info("\nğŸ¯ æ€§èƒ½ç›®æ ‡è¾¾æˆæƒ…å†µ:")
            logging.info("-" * 50)
            
            targets = target_check['targets']
            metrics = target_check['metrics']
            
            # æºåŸŸCVç›®æ ‡
            source_cv_met = target_check['source_cv_target_met']
            source_cv_auc = metrics['source_cv_auc']
            source_cv_target = targets['source_cv_auc_min']
            status_icon = "âœ…" if source_cv_met else "âŒ"
            logging.info(f"{status_icon} æºåŸŸ{self.args.source_cv_folds}æŠ˜CVå¹³å‡AUC: {source_cv_auc:.1%} (ç›®æ ‡: â‰¥{source_cv_target:.1%})")
            
            # ç›®æ ‡åŸŸç›´æ¥é¢„æµ‹ç›®æ ‡
            target_direct_met = target_check['target_direct_target_met']
            target_direct_auc = metrics['target_direct_auc']
            target_direct_target = targets['target_direct_auc_min']
            status_icon = "âœ…" if target_direct_met else "âŒ"
            logging.info(f"{status_icon} ç›®æ ‡åŸŸç›´æ¥é¢„æµ‹AUC: {target_direct_auc:.1%} (ç›®æ ‡: â‰¥{target_direct_target:.1%})")
            
            # ç›®æ ‡åŸŸåŸŸé€‚åº”åç›®æ ‡
            target_adapted_met = target_check['target_adapted_target_met']
            target_adapted_auc = metrics['target_adapted_auc']
            target_adapted_target = targets['target_adapted_auc_min']
            status_icon = "âœ…" if target_adapted_met else "âŒ"
            if target_adapted_auc > 0:
                logging.info(f"{status_icon} ç›®æ ‡åŸŸåŸŸé€‚åº”åAUC: {target_adapted_auc:.1%} (ç›®æ ‡: â‰¥{target_adapted_target:.1%})")
            else:
                logging.info(f"âŒ ç›®æ ‡åŸŸåŸŸé€‚åº”åAUC: æœªå¯ç”¨åŸŸé€‚åº” (ç›®æ ‡: â‰¥{target_adapted_target:.1%})")
            
            # æ€»ä½“ç›®æ ‡è¾¾æˆ
            all_targets_met = target_check['all_targets_met']
            if all_targets_met:
                logging.info("\nğŸ‰ æ‰€æœ‰æ€§èƒ½ç›®æ ‡å‡å·²è¾¾æˆï¼")
            else:
                unmet_targets = []
                if not source_cv_met:
                    unmet_targets.append("æºåŸŸCVæ€§èƒ½")
                if not target_direct_met:
                    unmet_targets.append("ç›®æ ‡åŸŸç›´æ¥é¢„æµ‹æ€§èƒ½")
                if not target_adapted_met:
                    unmet_targets.append("ç›®æ ‡åŸŸåŸŸé€‚åº”æ€§èƒ½")
                logging.info(f"\nâš ï¸  æœªè¾¾æˆç›®æ ‡: {', '.join(unmet_targets)}")
        
        logging.info(f"\nå®éªŒç»“æœå·²ä¿å­˜åˆ°: {self.save_path}")
        logging.info("åŒ…å«ä»¥ä¸‹æ–‡ä»¶:")
        logging.info("  - optimization_results.json: è´å¶æ–¯ä¼˜åŒ–ç»“æœå’Œæœ€ä½³å‚æ•°")
        logging.info("  - evaluation_results.json: AutoTabPFNæ¨¡å‹è¯„ä¼°ç»“æœ")
        if baseline_results:
            logging.info("  - baseline_models_results.json: åŸºçº¿æ¨¡å‹è¯„ä¼°ç»“æœ")
        logging.info("  - experiment_config.json: å®éªŒé…ç½®ä¿¡æ¯")
        logging.info("  - experiment.log: å®Œæ•´å®éªŒæ—¥å¿—")


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    # å‚æ•°éªŒè¯
    if args.source_val_split <= 0 or args.source_val_split >= 1:
        print("é”™è¯¯: æºåŸŸéªŒè¯é›†æ¯”ä¾‹å¿…é¡»åœ¨ (0, 1) èŒƒå›´å†…")
        return
    
    # ç”Ÿæˆè¾“å‡ºç›®å½•
    if args.output_dir:
        save_path = args.output_dir
    else:
        save_path = generate_output_dir(args)
    
    # è®¾ç½®æ—¥å¿—
    log_file = os.path.join(save_path, 'experiment.log')
    setup_logging(log_file)
    
    try:
        # åˆ›å»ºå¹¶è¿è¡Œå®éªŒ
        experiment = BayesianOptimizationDomainAdaptation(args)
        experiment.run_experiment()
        
        logging.info("å®éªŒæˆåŠŸå®Œæˆ!")
        
    except KeyboardInterrupt:
        logging.info("å®éªŒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logging.error(f"å®éªŒå¤±è´¥: {e}")
        raise
    finally:
        logging.info("å®éªŒç»“æŸ")


if __name__ == '__main__':
    main() 