   [PANDA: Pretrained Adaptation
Network with Domain Alignment for
 Feature-Efficient Cross-Hospital
 Pulmonary Nodule Classification]


                  [LIU Qingyuan]




A dissertation submitted in partial fulfillment of the
requirements for the degree of [Master of Science in
              Blockchain Technology]




      The Hong Kong Polytechnic University
       [Date of Submission Recommended:
                  January 2026]
Certificate of Originality
I hereby declare that this dissertation is my own work and that, to the best of my knowledge
and belief, it reproduces no material previously published or written, nor material that has
been accepted for the award of any other degree or diploma, except where due
acknowledgement has been made in the text.




Signature of the Student: _____                      _____

Name of the Student: ___LIU Qingyuan__
Abstract
Fragmented hospital silos and strict privacy rules often leave medical AI models staring at
small, uneven, mismatched tabular cohorts, so anything trained straight on those data tends to
wobble once it crosses sites. Here we sketch PANDA (Pretrained Adaptation Network with
Domain Alignment)â€”a cross-hospital setup that leans on a pre-trained tabular foundation
model, keeps the feature budget lean, and folds in unsupervised domain adaptation, even if
calling it a "framework" may be a stretch. PANDA uses a TabPFN-style Transformer encoder
meta-trained on millions of synthetic tables; that pretraining appears to capture higher-order
interactions that tuned gradient-boosting ensembles often miss when samples are scarce. A
cross-cohort RFE step uses the foundation model to identify eight biomarkers that stay
predictive across both hospitals, cutting data-collection demands and stabilizing
interpretation. To ease distribution gaps, we add TCA to the training loop so source and
target cohorts land in a shared latent space. This mixâ€”foundation-model representations,
RFE-filtered features, and TCAâ€”seems to reduce covariate shift and keep those eight
variables useful even when each site ranks them differently. On two lung-nodule cohorts (295
training, 190 external), PANDA lifts AUC and sensitivity over supervised and non-adaptive
baselines, hinting that pairing foundation-model priors with statistical alignment may
improve generalization in small, cross-domain medical tasks.
Acknowledgements
I thank the clinical teams at Sun Yat-sen University Cancer Center and Henan Tumor
Hospital for sharing de-identified data and domain expertise, my advisor Wenqi Fan for
steady guidance, Bobo for patient, practical advice. Any remaining mistakes are mine.
Contents
TABLE OF CONTENTS
Introduction ................................................................................................................................ 7
Related Work ............................................................................................................................. 8
       Tabular foundation models ................................................................................................ 8
       Domain adaptation in medical AI ...................................................................................... 8
       Pulmonary nodule risk prediction and cross-hospital generalization ................................ 8
       Theoretical Foundation ...................................................................................................... 8
Problem Formulation ................................................................................................................. 9
       Cross-Domain Learning Setup ........................................................................................... 9
       Challenges in Cross-Institutional Learning ..................................................................... 10
Solution .................................................................................................................................... 10
       Compositional Architecture ............................................................................................. 10
       Unified Objective ............................................................................................................. 12
Methods.................................................................................................................................... 13
       Motivating Challenges and Methodological Response.................................................... 13
       Foundation Model Architecture ....................................................................................... 14
               TabPFN Backbone Details ....................................................................................... 14
               Synthetic Task Generation ....................................................................................... 14
       Feature Selection and Preprocessing ............................................................................... 14
               Cross-Domain RFE Algorithm ................................................................................ 14
               Multi-Branch Preprocessing Pipeline ...................................................................... 14
       Domain Adaptation Implementation................................................................................ 14
               TCA Optimization ................................................................................................... 14
       Ethics Statement and Data Collection.............................................................................. 15
               Data Variables and Measurements........................................................................... 15
       Experimental Procedures ................................................................................................. 15
               Cross-Validation Protocol........................................................................................ 15
               Baseline Methods ..................................................................................................... 15
Analysis.................................................................................................................................... 16
       In-Context Learning for Small-Sample Robustness ........................................................ 16
       Mitigating Distributional Heterogeneity .......................................................................... 16
       Addressing Feature Inconsistency ................................................................................... 17
       Latent Space Alignment for Covariate Shift .................................................................... 18
       Stabilizing Predictions with Ensemble Aggregation ....................................................... 19
       Why PANDA Outperforms Baselines ............................................................................. 19
Evaluation ................................................................................................................................ 20
       Evaluation Metrics and Statistical Analysis .................................................................... 20
               Classification Performance Metrics ......................................................................... 20
               Visualization-Based Evaluation ............................................................................... 21
       Experimental Setup and Results ...................................................................................... 22
       Model Explainability, Reliability, and Clinical Utility .................................................... 24
Conclusion ............................................................................................................................... 26
Introduction
Early and accurate prediction of pulmonary nodule malignancy still shapes lung cancer
outcomes, yet many decision support tools struggle in everyday clinical use. Nodules
discovered on routine CT scans create tricky triage decisions, with malignancy estimates
ranging anywhere from 5% to 70% depending on setting and patient mix [1]. Classic risk
scores like the Mayo Clinic and Veterans Affairs models remain helpful, though their
performance often drops once they leave the cohorts they were built on [1â€“3]. The gap is
familiar by now: we need methods that can travel between hospitals while still meeting the
sensitivity expectations of screening workflows.
Recent tabular foundation modelsâ€”most notably TabPFNâ€”have changed small-sample
learning by relying on large-scale pre-training to perform well with limited data [4]. Yet these
models implicitly assume that feature distributions remain aligned across sites, which makes
them surprisingly fragile when real cross-hospital shifts come into play [5].Domain
adaptation techniques that succeed in imaging remain thin for structured clinical data [6], so
algorithmic progress has not translated into predictable bedside gains.
Three knots entangle cross-hospital deployment. First, datasets are small; many hospitals
share only a few hundred patients with complete records, too little to train deep models from
scratch [7]. Second, domain shift magnifies the issue because patient mixes, workflows, and
collection protocols differ enough to drag external AUC down by 20â€“30% [8]. Third, feature
heterogeneity shows up when sites record variables inconsistently, use different codes, or
leave gaps, so models do not transfer cleanly [9]. Tackling each problem alone has not
proved durable.
Tabular foundation models shine in small-sample regimes yet come without built-in domain
adaptation [10]. Domain adaptation work mostly targets images, not structured clinical
data [6]. We have not seen a single approach that marries pre-trained tabular models with
cross-domain feature selection and unsupervised alignment, which keeps reliable deployment
out of reach in mixed healthcare settings.
We present PANDA (Pretrained Adaptation Network with Domain Alignment), a pragmatic
attempt to pair a pre-trained tabular foundation model with unsupervised domain adaptation
for cross-hospital pulmonary nodule malignancy prediction. The recipe mixes three pieces:
(1) TabPFNâ€™s small-sample modeling via meta-training on millions of synthetic tasks; (2)
Transfer Component Analysis (TCA) to align feature distributions across hospitals while
keeping signal; and (3) Recursive Feature Elimination (RFE) to surface stable clinical
variables across sites, softening feature heterogeneity. The goal is cross-hospital prediction
while holding the high sensitivity (94.4%) screening usually demands.
The promise rests on four points that seem worth testing in practice: it appears to be the first
time a pre-trained tabular foundation model is paired with domain adaptation in a medical
setting; external validation hints the approach might travel across hospital systems without
falling apart; the sensitivity target of 94.4% lines up with what screening workflows expect,
with calibration and decision-curve gains to match; and the alignment path tries to juggle
small sample sizes, class imbalance, and distribution shift in one pass.
Related Work
Tabular foundation models
Tabular foundation models have shifted small-sample learning by pairing large-scale pre-
training with meta-learning. Gradient-boosted trees remain strong baselines for
heterogeneous clinical data but need ample examples and often overfit small cohorts [7,11].
Attention-based designsâ€”TabNet, TabTransformer, SAINT, FT-Transformerâ€”brought
competitive performance with interpretability or streamlined architectures [12â€“15].
Pre-trained tabular foundation models take the next step by training on millions of synthetic
tasks to work with minimal real examples. TabPFN is a good example: its meta-trained
Transformer can make a full prediction in a single forward pass, often matching the accuracy
of tuned ensembles that typically take hours to run [4,16]. This speedâ€”and the way it
handles tiny datasetsâ€”is well suited to clinical settings where data are rarely abundant. Still,
the model implicitly counts on reasonably stable feature distributions, which real hospitals
donâ€™t always provide.

Domain adaptation in medical AI
Domain adaptation has tried to bridge these distribution gaps, especially in medical imaging,
where scanners, protocols, and patient mixes routinely differ from one institution to another.
Alignment strategiesâ€”adversarial discriminators, CORAL, maximum mean discrepancy
minimizationâ€”and domain generalization methods like meta-learning and invariant risk
minimization have shown gains [8,17,18].
Even so, evaluations show that methods such as GroupDRO, IRM, and adversarial training
still leave gaps on truly shifted populations [8]. The focus on imaging leaves structured
clinical data underexplored; feature heterogeneity and missingness pose different challenges
than those in images [6]. Tabular deployment thus inherits the hard parts of adaptation
without many tailored tools.

Pulmonary nodule risk prediction and cross-hospital generalization
Pulmonary nodule malignancy prediction makes the cross-hospital problem concrete. Clinical
risk models (Mayo Clinic, Veterans Affairs, Brock University) perform well in development
cohorts (AUC 0.83â€“0.94) but drop sharply on external validation (AUC 0.60â€“0.77) [1â€“
3,19,20]. Radiomics and deep learning show similar declines, often losing 0.1â€“0.2 AUC
when moved across institutions because of scanner variation and demographic shifts [21,22].
Cross-hospital variability stems from demographic differences, equipment heterogeneity, and
practice patterns that change coding and disease definitions [5,23,24]. Feature heterogeneity
adds inconsistent documentation and missing data patterns [9]. No single approach currently
handles small sample sizes, feature heterogeneity, and distribution shift together for
pulmonary nodules, leaving a gap for integrating pre-trained tabular models with feature
selection and unsupervised adaptation.

Theoretical Foundation
Our approach leans on three theoretical ideas that motivate joining foundation models with
domain adaptation; they hold under specific assumptions and should be read with that caveat.
The smooth representation benefit notes that foundation model representations can contract
domain discrepancies. Let Î¦!" : ğ’³ â†’ ğ’µ be ğ¿-Lipschitz. Let ğ‘ƒ# , ğ‘ƒ$ be source and target
distributions on ğ’³ and ğ‘ƒ%,# , ğ‘ƒ%,$ their pushforwards on ğ’µ. For an RKHS â„‹ with a Lipschitz-
bounded feature map, the induced MMD admits the bound
                                ğ‘‘â„‹ (ğ‘ƒ%,# , ğ‘ƒ%,$ ) â‰¤ ğ¿ â‹… ğ‘‘â„‹ (ğ‘ƒ# , ğ‘ƒ$ ),
where ğ‘‘â„‹ denotes maximum mean discrepancy. Under suitable kernel assumptions, smoother
representations may contract domain discrepancies.
Feature selection and domain adaptation interact. Let â„± â‹† be the subset of shared features
minimizing cross-domain variance, i.e.
                                  â„± â‹† = arg min
                                             !
                                                Vardomain (ğ‘¥â„± ! ),
                                             â„± âŠ†â„±

where Vardomain (â‹…) denotes the pooled covariance across source and target domains.
Assuming the TCA operator ğ´+,- is linear with bounded operator norm and letting Î£â„± , Î£â„± â‹†
denote the corresponding covariance matrices in the encoded space, we have
Var(ğ´+,- (Î¦!" (ğ‘¥â„± â‹† ))) = tr(ğ´+,- Î£â„± â‹† ğ´.+,- ) â‰¤ tr(ğ´+,- Î£â„± ğ´.+,- ) = Var(ğ´+,- (Î¦!" (ğ‘¥â„± ))),
which indicates that selecting low-variance features can reduce alignment complexity.
Finally, sample complexity reduction motivates the use of pre-training. Standard
generalization bounds for classification in a hypothesis class of effective dimension ğ‘‘/00 yield
                                                    ğ‘‘/00
                                          ğ‘›/00 = ğ‘‚ ? 1 A.
                                                    ğœ€
Mapping inputs into a pretrained representation Î¦!" shapes a lower-dimensional, more
structured hypothesis space than the raw ğ‘‘ 2 -dimensional space, effectively reducing ğ‘‘/00 to
roughly âˆšğ‘‘ 2 in our setting. The sample size then scales as ğ‘‚(âˆšğ‘‘ 2 /ğœ€ 1 ) instead of ğ‘‚(ğ‘‘ 2 /ğœ€ 1 ),
reflecting transferred sample efficiency [4,25].


Problem Formulation
Cross-hospital medical classification mixes distribution shift, sample scarcity, and feature
heterogeneity. We cast it as an unsupervised domain adaptation (UDA) problem on structured
clinical data: the goal is reliable prediction in a target hospital without target labels. The
framing mirrors common deployment constraints in medical AI.

Cross-Domain Learning Setup
                                                                                                 6
We consider two cohorts from different institutions. The source domain is ğ’Ÿ# = {(ğ± 3# , ğ‘¦3# )}345
                                                                                               #

                                          6$
with labels; the target domain ğ’Ÿ$ = {ğ±7$ }745 has only unlabeled records. Each sample ğ± âˆˆ â„8
is a tabular feature vector and ğ‘¦ âˆˆ {0,1} denotes malignancy.
Institutional differences in populations and measurement protocols create both marginal and
conditional shifts:
                             ğ‘ƒ# (ğ±) â‰  ğ‘ƒ$ (ğ±),       ğ‘ƒ# (ğ‘¦|ğ±) â‰  ğ‘ƒ$ (ğ‘¦|ğ±).
Hospitals usually record only partially overlapping feature sets. Let â„±# and â„±$ be the
available indices, and â„± = â„±# âˆ© â„±$ the shared subset with dimension ğ‘‘ 2 < ğ‘‘. We assume the
shared features hold enough discriminative information for prediction in the reduced space.
The aim is to learn a classifier ğ‘“: ğ’³â„± â†’ ğ’´ using ğ’Ÿ# and unlabeled target samples so that the
target risk
                                    â„›$ (ğ‘“) = ğ”¼(ğ±,;)âˆ¼>$ [â„“(ğ‘“(ğ±), ğ‘¦)]

is minimized. This mirrors deployment settings where target labels cannot be shared because
of privacy constraints.

Challenges in Cross-Institutional Learning
Clinical tabular cohorts usually include only a few hundred labeled patients. For hypothesis
classes on ğ‘‘ 2 shared features, estimation error scales as ğ‘‚Z([ğ‘‘ 2 /ğ‘›# ), making high-capacity
models unreliable once ğ‘›# â‰¤ 500. Many UDA techniques implicitly bank on larger sample
sizes than most hospitals can release.
Distributional mismatch compounds the limits. Under the standard domain adaptation bound
                                              1
                             â„›$ (ğ‘“) â‰¤ â„›# (ğ‘“) + ğ‘‘â„‹?â„‹ (ğ‘ƒ# , ğ‘ƒ$ ) + ğœ†,
                                              2
the divergence term dominates when variability is substantialâ€”differences in CT scanners,
assays, and patient populations. Partial feature overlap means source and target supports only
partly coincide, straining assumptions behind kernel alignment and adversarial methods.
Deep neural networks face the same hurdle: effective dimension ğ‘‘/00 yields sample
complexity ğ‘›# = Î©(ğ‘‘/00 /ğœ– 1 ), leaving conventional representation learning under-specified in
medical tabular contexts where ğ‘‘ 2 is modest but ğ‘›# is tiny.


Solution
PANDA targets the three core limitations identified in sample scarcity, distribution shift, and
feature heterogeneity.

Compositional Architecture
PANDA consists of four sequential operators, each resolving a specific challenge in cross-
hospital prediction, as depicted in Fig. 1.
(1) Cross-domain feature selection.
                              !
The operator ğ’¯RFE : â„8 â†’ â„8 selects a domain-stable subset of features via cross-domain
recursive elimination:

               ğ’¯RFE (ğ±) = ğ± â„± âˆ— ,       â„± âˆ— = argmin
                                                  !
                                                     c VarABCDEF (ğ±7 ) + ğœ†|â„± 2 |.
                                                   â„±
                                                       7âˆˆâ„± !

This yields a compact and clinically consistent feature set shared across institutions.
(2) Foundation-model representation.
                                             !
The pretrained TabPFN encoder Î¦!" : â„8 â†’ â„H maps the reduced features into a smooth
latent space:
                          Î¦!" (ğ±) = TransformerIâˆ— (Tokenize(ğ±)).
This step injects inductive priors learned from millions of synthetic tasks, yielding
representations that generalize even when few labeled samples exist.
(3) Domain-invariant alignment via TCA.
Transfer Component Analysis (TCA) learns a projection that reduces distribution
discrepancies between hospitals:
                         min tr(ğ‘Š . ğ¾ğ¿ğ¾ . ğ‘Š) + ğœ‡ tr(ğ‘Š . ğ¾ğ»ğ¾ . ğ‘Š),
                          J

where ğ¿ encodes maximum mean discrepancy (MMD), ğ» is a centering matrix, and ğ¾ is a
kernel matrix (linear kernel in our implementation). The aligned representation is
                               ğ³ = ğ‘Š . ğœ™(ğ±),       ğœ™: â„8 â†’ â„K ,
with ğ‘˜ chosen automatically to preserve information while enabling effective alignment.
(4) Classification head with ensemble aggregation.
The final classifier â„: â„K â†’ [0,1] operates on aligned features and aggregates predictions
across multiple preprocessing branches and random seeds:
                                         M
                                    1             (L)
                              ğ‘“(ğ±) = c â„L uğ’œ+,- (Î¦!" (ğ±))w.
                                    ğµ
                                        L45
 a PANDA


          Train
                                                                                                                   Output Predicted
                                                                                                                  Cla ss Probabilitie s



                                     Patients


                                                   Features + Lab el
    Feature Select ion                          Developm ent Cohort
                                                    (Cohort A)




                                                                               Data Preprocess ing      Pre-traine d Tabular Foundation Model
                                     Patients




                                                                                           Pre-train
                                                       Features
          UDA                                Ada pte d Cohort
                                         (Cohort Bâ€™ without label)


         Predict



                                                                             Synthetic task generator              Synthetic Da taset



 b Data Preprocessing



                    Feature O rder                       No Dis tribut ion    Tre at Cat egoric al           Parallel
                      Rot ation                          Tra nsf ormat ion   Features as Numeric        Inf ere nce (Ã—8)




                    Feature O rder                           Quantile        Ordinal Enc oding of            Parallel
                      Rot ation                          Tra nsf ormat ion   Categorical Fea tures      Inf ere nce (Ã—8)



 Input data                                                                                                                           Ensem ble
                                                                                                                                     Aggregation


                    Feature O rder                       No Dis tribut ion   Ordinal Enc oding of            Parallel
                      Rot ation                          Tra nsf ormat ion   Categorical Fea tures      Inf ere nce (Ã—8)




                    Feature O rder                           Quantile         Tre at Cat egoric al           Parallel
                      Rot ation                          Tra nsf ormat ion   Features as Numeric        Inf ere nce (Ã—8)



Figure 1: The PANDA framework architecture. (a) Compositional pipeline: from original
tabular data through ensemble training, prediction aggregation, class imbalance adjustment,
to final classification output. (b) Multi-branch ensemble with ğµ = 4 preprocessing strategies,
each generating ğ‘† = 8 ensemble members via different random seeds.

Unified Objective
The complete PANDA mapping is:

                                                          ğ‘“(ğ±) = â„ uğ’œ+,- {Î¦!" (ğ’¯N!O (ğ±))|w.
The joint optimization objective minimizes source-domain classification loss while aligning
source and target distributions:
                         6#
                     1
                 min c â„“ (â„(ğ’œ+,- (Î¦!" (ğ± 3# ))), ğ‘¦3# ) + ğœ†5 ğ‘‘""P (ğ™# , ğ™$ ),
                 J,H ğ‘›#
                         345

where ğ™# = ğ’œ+,- (Î¦!" (ğ’Ÿ# )) and ğ™$ = ğ’œ+,- (Î¦!" (ğ— $ )).


Methods
Motivating Challenges and Methodological Response
Cross-hospital malignancy prediction poses interdependent obstacles that destabilize standard
pipelines, and PANDA is shaped around those pain points. Small cohorts mean most
hospitals contribute only a few hundred annotated patients, leaving deep networks
hypersensitive to randomness and prone to overfitting. PANDA leans on a pre-trained tabular
foundation model that performs in-context learning, reusing inductive biases from millions of
synthetic tasks instead of trying to learn everything from scratch in a tiny clinical cohort.
Pronounced distributional differences between hospitals sit on the next rung: divergent CT
scanners, laboratory ranges, and demographics nudge covariates far enough to erode
boundaries learned at one site. PANDA embeds Transfer Component Analysis (TCA) inside
the latent space produced by the foundation model so alignment happens before
classification, which seems to soften the covariate shift without discarding signal.
Feature heterogeneity complicates things further. Institutions disagree on which variables
they collect and how they encode them; missingness patterns differ as well. Training on every
available variable bakes in site-specific artifacts, while tightening to the intersection risks
losing signal. PANDA applies cross-domain recursive feature elimination to keep a compact
subset of variables that stay predictive in both hospitals, making sure the downstream
adaptation actually operates on features the sites share in practice.
Class imbalance becomes especially visible in small datasets, where the number of malignant
cases can differ sharply by hospital. NaÃ¯ve models tend to collapse onto the majority class, a
pattern weâ€™ve seen more than once. Using class-balanced sampling and calibrated loss terms
helps the minority signals stay present enough to maintain the sensitivity that screening
workflows typically expect.
Small samples also inflate variance: minor tweaks in preprocessing, feature ordering, or even
the random seed can shift predictions more than one might like to admit. A multi-branch
ensemble counters this by viewing each patient through several slightly different
representationsâ€”shuffled feature orders, alternate encodings, and varied distribution
transformsâ€”and then pooling the results. The averaged probabilities, once temperature-
scaled, tend to stay calibrated enough to support clinical thresholds rather than forcing
everything into brittle hard labels.
The pieces fit together as a challenge-driven architecture: each module targets a known
failure mode in cross-hospital prediction instead of being bolted on for novelty.
Foundation Model Architecture
TabPFN Backbone Details
TabPFN uses a 10-layer Transformer with four attention heads and 128-dimensional
embeddings. Clinical samples are tokenized as [CLS, ğ±5 , â€¦ , ğ± 8 ,SEP] with positional
encodings to preserve ordering. Training instances and test queries are processed jointly in
one forward pass, enabling in-context learning without gradient updates.

Synthetic Task Generation
Pre-training draws diverse synthetic classification tasks from several function priors,
including Gaussian processes, multilayer perceptrons, and ridge regression families. This
variety teaches generalizable tabular reasoning patterns that appear to transfer to real-world
medical classification tasks.

Feature Selection and Preprocessing
Cross-Domain RFE Algorithm
We recursively eliminate features based on domain-invariant importance scores:
                                            R
                                     1    (Q)            (Q)
                    Importance(ğ±7 ) = c â€¢â„›# (â„±\{ğ±7 }) âˆ’ â„›# (â„±)â€¢
                                     ğ‘€
                                           Q45

where ğ‘€ = 5 permutation repeats evaluate feature stability. The RFE procedure first surfaced
nine highly discriminative features. To enforce cross-institutional availability, one feature
absent from the target domain (Dataset B) was removed, yielding a final set of |â„± âˆ— | = 8
clinical variables that both hospitals record.

Multi-Branch Preprocessing Pipeline
The 32-model ensemble comes from four simple branches: two keep the original or rotated
feature order with plain numerical encodings, and two pair those orders with a quantile
transform plus ordinal encoding. Each branch spits out eight runs with seeds 1â€“8, and a
majority vote settles the label. Balanced-accuracy weights keep the malignant class from
getting drowned out.

Domain Adaptation Implementation
TCA Optimization
Transfer Component Analysis learns domain-invariant representations by solving:
                              mintr(ğ– . ğ—ğ‹ğ— . ğ–) + ğœ‡tr(ğ– . ğ–)
                                ğ–

where ğ‹ is the MMD kernel matrix with entries ğ¿37 = ğ¾37 /(ğ‘›#1 ) + ğ¾37 /(ğ‘›$1 ) âˆ’ 2ğ¾37 /(ğ‘›# ğ‘›$ ).
The kernel matrix ğ¾ adopts Gaussian RBF kernels with bandwidth ğœ set via the median
heuristic.
The alignment step preserves discriminative information while reducing domain discrepancy:
                                 ğ³ = ğ– . ğœ™(ğ±),     ğœ™: â„8 â†’ â„H
where latent dimensionality â„ = 15 balances information preservation with alignment
effectiveness.

Ethics Statement and Data Collection
This study received Institutional Review Board approval from Sun Yat-sen University Cancer
Center (Guangzhou, China) and Henan Tumor Hospital (Zhengzhou, China) and followed the
Declaration of Helsinki. Patient data were retrospectively extracted from electronic medical
records and fully de-identified before analysis. Written informed consent for research use of
clinical information was obtained from all patients with solitary pulmonary nodules (SPNs) at
admission, and no identifiable personal data were retained.
The training cohort (Cohort A, ğ‘› = 295) originated from Sun Yat-sen University Cancer
Center between January 2011 and December 2016. The external test cohort (Cohort B, ğ‘› =
190) was collected at Henan Tumor Hospital. All participants provided written informed
consent for scientific use of their clinical data at the time of admission.

Data Variables and Measurements
Collected variables included demographics (age, sex, height, weight, body mass index),
smoking history, family cancer history, and symptoms (fever, cough, hemoptysis, chest pain).
Radiologic descriptors of SPNs covered anatomical location (lung side and lobe), nodule
diameter and area, calcification, cavity, spiculation, pleural thickening, and adhesion.
Laboratory data comprised hematologic and biochemical indices such as white blood cell
count (WBC), neutrophil-to-lymphocyte ratio (NLR), platelet-to-lymphocyte ratio (PLR),
albumin/globulin ratio (AGR), liver and renal function markers, and tumor biomarkers
including CEA, Cyfra21-1, and NSE.

Experimental Procedures
Cross-Validation Protocol
For internal validation, we applied 10-fold cross-validation on Cohort A. The dataset was
randomly split into 10 equal parts with class balance preserved. Each fold served once as
validation while the remaining nine folds trained the model. This cycle was repeated 10 times
with different random seeds to strengthen robustness of performance estimates.

Baseline Methods
For comparison, we included a few familiar baselines:
   â€¢   Decision Tree (CART) [26]

   â€¢   Gradient Boosting Decision Tree [27]

   â€¢   Random Forest [28]

   â€¢   XGBoost [11]

   â€¢   Support Vector Machine [29]

   â€¢   LASSO Logistic Regression for nodule risk [30]

   â€¢   Clinical scores (Mayo Clinic, PKUPH) [1,31]
Analysis
We trace how PANDA deals with the main sources of failure in cross-site medical AI. Each
component is tied to a specific hurdle rather than bolted on for convenience, and the
mechanics show up in both the math and the observed gains.

In-Context Learning for Small-Sample Robustness
Deep models tend to overfit on small cohorts (e.g., ğ‘›# = 295) and swing wildly with minor
perturbations. PANDA avoids heavy re-training by casting classification as in-context
learning. The TabPFN backbone uses a Per-Feature Transformer Architecture, treating each
input ğ± = [ğ‘¥5 , ğ‘¥1 , â€¦ , ğ‘¥8 ] âˆˆ â„8 as a token sequence:
                             ğ3 = Embed(ğ‘¥3 ) + ğ©3 ,            ğ‘– = 1, â€¦ , ğ‘‘
where Embed(â‹…): â„ â†’ â„8model maps features to a ğ‘‘model -dimensional space. This embedded
sequence ğ„ = [ğ5 , â€¦ , ğ8 ] is processed through a 12-layer Transformer encoder:
                      ğ‡ (â„“) = LayerNorm(MultiHead(ğ‡ (â„“U5) ) + ğ‡ (â„“U5) )
                          ğ‡ (â„“V5) = LayerNorm(FFN(ğ‡ (â„“) ) + ğ‡ (â„“) )
where ğ‡ (W) = ğ„. To circumvent data scarcity, the model is pre-trained using a stochastic task
generator that synthesizes classification problems from diverse function priors. For each
batch, we sample a prior family and hyperparameters:
                           ğ‘Ÿ âˆ¼ Categorical(ğ›‘),                ğ›‰ âˆ¼ ğ‘(ğ›‰ âˆ£ ğ‘Ÿ),
where ğ‘Ÿ âˆˆ {gp,mlp,ridge,mix_gp}. Inputs are sampled independently from a factorized base
distribution and optionally transformed:
                               ğ± $ âˆ¼ ğ‘base (ğ±),           ğ±â€“ $ = ğœ“ğ›‰ (ğ± $ )
During inference, the model performs in-context learning by processing the entire sequence
                                        6ctx
of context examples ğ’Ÿctx = {(ğ± 3 , ğ‘¦3 )}345  and query inputs ğ± query :

                               ğ³ = [ğ±5 , ğ‘¦5 , â€¦ , ğ± 6ctx , ğ‘¦6ctx , ğ± query ]

The prediction minimizes the in-context loss over query positions (averaged over a batch of
size ğµ):
                                         M       Y
                                  1
                            â„’ICL = c c â„“ (ğ‘“Z (ğ³5:$U5 ), ğ‘¦$ )
                                  ğµ
                                        345 $46ctx V5

The pre-trained priors act as regularizers, helping the model interpolate in sparse regions
where conventional models often fail to learn stable boundaries.

Mitigating Distributional Heterogeneity
Performance usually drops when moving across hospitals because of small shifts in encoding
and feature distributions. A dual preprocessing strategy tackles positional bias and
distribution mismatch. To reduce ordering bias in the Transformer input, each ensemble
member applies a cyclical permutation to the features:
              (Q)
             ğ± rotated = rotate(ğ±, ğ‘š) = [ğ‘¥(Q) CBA 8 , ğ‘¥(QV5) CBA 8 , â€¦ , ğ‘¥(QV8U5) CBA 8 ]

with rotation offsets generated deterministically for each ensemble member ğ‘š âˆˆ [0, ğ‘ âˆ’ 1].
In parallel, we employ Adaptive Feature Transformation to bridge distributional gaps. The
Enhanced Feature Transformation performs a quantile transform followed by
dimensionality expansion:
              ğ± quantile = QuantileTransformer(ğ±, ğ‘›quantiles = max(âŒŠğ‘›samples /10âŒ‹,2))

                        ğ— expanded = SVD(ğ— quantile , ğ‘›components = min(4, ğ‘‘))

yielding a final representation ğ± final = [ğ± original ; ğ± quantile ; ğ± SVD ]. A complementary Preserved
Feature Transformation keeps the raw feature distribution:
                                           ğ± preserved = ğ± original

Categorical variables are processed using Intelligent Categorical Encoding:
                           ğœ™7 (ğ‘¥37 )      if feature ğ‘— has frequently occurring categories
           encode(ğ‘¥37 ) = Å¸
                           ğ‘¥37            otherwise

where ğœ™7 = ğœ‹({0,1, â€¦ , |ğ‘ˆ7 | âˆ’ 1}) employs randomized integer assignment. Alternatively, the
Numeric Treatment Strategy treats categorical features as continuous:
                                        encode(ğ‘¥37 ) = float(ğ‘¥37 )
Providing multiple â€œviewsâ€ of the data lets the model marginalize hospital-specific artifacts
and focus on the clinical signal.

Addressing Feature Inconsistency
Noisy or missing variables across cohorts make careful selection essential, and RFE offers a
fairly transparent way to handle it. The workflow is straightforward:
                                                                      ($)
    1. Train the Pre-trained Tabular Foundation Model ğ‘“Z on the current feature subset
       â„± ($) .
                                                   ($)   ($)      ($)
    2. Estimate importance scores ğˆ ($) = [ğ¼5 , ğ¼1 , â€¦ , ğ¼|â„± ($) | ] using permutation-based
        evaluation.
    3. Remove the feature with the smallest score:
                                   ($)
       â„± ($V5) â† â„± ($) \{argmin7 ğ¼7 }.

    4. Repeat until the subset reaches the target size |â„± ($V5) | = ğ‘˜.
Feature importance here is defined by how much performance drops when a variable is
randomly shuffled:
                                   _
                              1                           (^)
                          ğ¼7 = c Â§AUC(ğ‘“Z , ğ’Ÿ) âˆ’ AUC(ğ‘“Z , ğ’Ÿperm(7) )Âª.
                              ğ‘…
                                  ^45
To determine the optimal feature subset, we optimize a comprehensive cost-effectiveness
index:
       CostEffectiveness(ğ‘˜) = ğ‘¤5 â‹… ğ‘†perf (ğ‘˜) + ğ‘¤1 â‹… ğ‘†eff (ğ‘˜) + ğ‘¤` â‹… ğ‘†stab (ğ‘˜) + ğ‘¤a â‹… ğ‘†simp (ğ‘˜)

where the component scores are normalized as follows:
   â€¢     Performance Score:

                  ğ‘†perf (ğ‘˜) = 0.5 â‹… AUC(ğ‘˜) + 0.3 â‹… Accuracy(ğ‘˜) + 0.2 â‹… F1(ğ‘˜)

   â€¢     Efficiency Score:
                                                      ğ‘‡(ğ‘˜) âˆ’ ğ‘‡CEF
                                     ğ‘†eff (ğ‘˜) = 1 âˆ’
                                                      ğ‘‡CDb âˆ’ ğ‘‡CEF
   â€¢     Stability Score:
                                                     ğ¶ğ‘‰(ğ‘˜) âˆ’ ğ¶ğ‘‰CEF
                                   ğ‘†stab (ğ‘˜) = 1 âˆ’
                                                     ğ¶ğ‘‰CDb âˆ’ ğ¶ğ‘‰CEF
   â€¢     Simplicity Score:

                                      ğ‘†simp (ğ‘˜) = exp(âˆ’ğ›¼ â‹… ğ‘˜)

The optimal subset is chosen as ğ‘˜ âˆ— = argmaxK CostEffectiveness(ğ‘˜), yielding a feature set
that keeps strong discriminative value while still matching what hospitals can reliably collect.

Latent Space Alignment for Covariate Shift
A noticeable gap between internal and external validation often hints at covariate shift
(ğ‘ƒ# (ğ±) â‰  ğ‘ƒ$ (ğ±)). Transfer Component Analysis (TCA) addresses this by mapping both
domains into a shared latent subspace where their distributions look closer. Let ğ‘‹# âˆˆ â„6# Ã—8
and ğ‘‹$ âˆˆ â„6$ Ã—8 be source and target feature matrices. A combined kernel matrix ğ¾ âˆˆ
â„(6# V6$ )Ã—(6# V6$ ) with a linear kernel ğ¾(ğ‘¥3 , ğ‘¥7 ) = ğ‘¥3. ğ‘¥7 is partitioned as:
                                                    ğ¾     ğ¾#$
                                               ğ¾ = Â³ ##       Â´
                                                    ğ¾$#   ğ¾$$
A projection matrix ğ‘Š âˆˆ â„(6# V6$ )Ã—K is learned by solving:
                            min tr(ğ‘Š . ğ¾ğ¿ğ¾ . ğ‘Š) + ğœ‡ â‹… tr(ğ‘Š . ğ¾ğ»ğ¾ . ğ‘Š),
                             J

where the alignment matrix ğ¿ encourages domain alignment:
                                         1                      1
                                      â¡ 1 ğŸ6# Ã—6#         âˆ’         ğŸ      â¤
                                         ğ‘›                    ğ‘›# ğ‘›$ 6# Ã—6$ â¥
                                 ğ¿ = â¢â¢ #                                  â¥
                                           1                  1
                                      â¢âˆ’     ğŸ6 Ã—6               ğŸ 6 Ã—6
                                                                           â¥
                                      â£ ğ‘›# ğ‘›$ $ #             ğ‘›$1 $ $ â¦
                                           5
and the centering matrix ğ» = ğ¼ âˆ’ 6 V6 ğŸğŸ. ensures zero-centered features. The eigen-
                                       #       $
decomposition (ğ¼ + ğœ‡ğ¾ğ¿ğ¾)ğ‘† = ğ¾ğ»ğ¾ğ‘† yields ğ‘Š, and source and target samples project via
ğ‘# = ğ¾# ğ‘Š and ğ‘$ = ğ¾$ ğ‘Š. Distances are computed in the TCA space using pooled statistics
ğœ‡Ì‚ , ğœÂ¾ and standardized features ğ— norm
                                    #    , ğ— norm
                                             $    :
                                             ğ— # âˆ’ ğœ‡Ì‚                     ğ— $ âˆ’ ğœ‡Ì‚
                                ğ— norm
                                  #    =              ,        ğ— norm
                                                                 $    =
                                                ğœÂ¾                           ğœÂ¾
These metrics include Wasserstein Distance:
                                                           8
                                                  1       norm    norm
                              ğ‘Šnorm (ğ— # , ğ— $ ) = c ğ‘Š5 (ğ‘‹#,3  , ğ‘‹$,3  )
                                                  ğ‘‘
                                                       345

Symmetric KL Divergence:
                                            8
                                            norm    norm         norm    norm
                                     1  ğ¾ğ¿(ğ‘ƒ#,3  ||ğ‘ƒ$,3  ) + ğ¾ğ¿(ğ‘ƒ$,3  ||ğ‘ƒ#,3  )
                ğ¾ğ¿norm (ğ— # , ğ— $ ) = c
                                     ğ‘‘                     2
                                          345

and MMD with RBF Kernel:
                          1                                       1                              2
MMD1 (ğ— # , ğ— $ ) =                 c ğ‘˜ (ğ‘¥3# , ğ‘¥7# ) +                     c ğ‘˜ (ğ‘¥3$ , ğ‘¥7$ ) âˆ’         c ğ‘˜ (ğ‘¥3# , ğ‘¥7$ )
                      ğ‘›# (ğ‘›# âˆ’ 1)                          ğ‘›$ (ğ‘›$ âˆ’ 1)                          ğ‘›# ğ‘›$
                                    3d7                                    3d7                        3,7

where ğ‘˜(ğ±, ğ²) = exp(âˆ’ğ›¾||ğ± âˆ’ ğ²||1 ).

Stabilizing Predictions with Ensemble Aggregation
Single models often give poorly calibrated scores that drift toward the majority class.
PANDA tempers this tendency with an ensemble setup, which aggregates multiple slightly
varied representations to steady both calibration and overall stability. Class imbalance
handling uses inverse-frequency reweighting:
                                                              ğ‘Ì‚ 3 /ğœ‹3
                                          ğ‘Ì‚ 3balanced =
                                                           âˆ‘e745 ğ‘Ì‚7 /ğœ‹7

where ğ‘Ì‚ = (ğ‘5 , â€¦ , ğ‘e ) are predicted probabilities and ğœ‹ the empirical class distribution.
Ensemble aggregation takes a simple but surprisingly steadying approach: it averages the
temperature-scaled outputs from ğ‘ = 32 members,
                                                       g
                                            1      exp(ğ‘§3f /ğ‘‡)
                              ğ‘(ğ‘¦ = ğ‘ âˆ£ ğ±) = c e              !    ,
                                            ğ‘ âˆ‘f ! 45 exp (ğ‘§3f /ğ‘‡)
                                                      345

where ğ‘§3f are the logits and ğ‘‡ = 0.9 sets the softmax temperature. This kind of averaging
tends to smooth out the quirks of any single model. It usually improves calibration and cuts
down variance, giving risk scores that feel a bit more stableâ€”something clinicians often care
about more than a marginal bump in accuracy.

Why PANDA Outperforms Baselines
Before applying TCA, the PCA and t-SNE plots (Fig. 3a,c) show that the two hospitalsâ€™ data
donâ€™t quite land in the same neighborhoodâ€”thereâ€™s some separation, though perhaps not as
dramatic as one might expect from a textbook domain-shift example. Still, the shape of the
clusters hints at meaningful differences in how the two cohorts distribute themselves in
feature space. After alignment (Fig. 3b,d), those clouds pull a bit closer together. They donâ€™t
collapse into a single blob, but the overlap becomes tighter in a way that feels more
reassuring than the raw-input view.
When we looked at the numbers behind the scenesâ€”the MMD, Wasserstein-1 distance, and
symmetric KL divergence computed on the latent representationsâ€”they all moved in the
direction we hoped for: smaller gaps, less tug-of-war between hospitals. These werenâ€™t
included as explicit figures, but the calculations (following the definitions in Sec. 6) back up
the visual impression. Itâ€™s not perfect alignment, but it seems to argue that the method is at
least nudging the domains toward the same latent "language."
Another piece that quietly helps is the cross-domain RFE step. By trimming the features
down to the eight variables both hospitals actually measureâ€”and that stay predictive across
bothâ€”it strips away a lot of those site-specific quirks that often masquerade as signal. This
makes the alignment problem less messy. Thereâ€™s even a theoretical hint supporting this: the
covariance bound discussed in the Theoretical Foundation â€“ Feature selection and domain
adaptation interact section suggests that selecting lower-variance shared features may shrink
the alignment complexity. In practice, that seems to match what we observed: once the
feature set stops dragging along hospital-specific noise, TCA has an easier time finding a
common subspace that both cohorts can live with.




Evaluation
We assess PANDA across cross-institutional performance, domain adaptation,
interpretability, and clinical utility, using a protocol meant to resemble what deployment
would actually look like.

Evaluation Metrics and Statistical Analysis
Classification Performance Metrics
Results are averaged over 10-fold stratified cross-validation to temper label imbalance, the
metrics are:
                                                   ğ‘‡ğ‘ƒ(ğœ)
                 True Positive Rate: ğ‘‡ğ‘ƒğ‘…(ğœ) =
                                               ğ‘‡ğ‘ƒ(ğœ) + ğ¹ğ‘(ğœ)
                                                   ğ¹ğ‘ƒ(ğœ)
                 False Positive Rate: ğ¹ğ‘ƒğ‘…(ğœ) =
                                               ğ¹ğ‘ƒ(ğœ) + ğ‘‡ğ‘(ğœ)
                                                        5
                 AUC:                     ğ´ğ‘ˆğ¶ = Ã† ğ‘‡ ğ‘ƒğ‘…(ğœ) ğ‘‘(ğ¹ğ‘ƒğ‘…(ğœ))
                                                        W
                                              ğ‘‡ğ‘ƒ + ğ‘‡ğ‘
                 Accuracy:
                                       ğ‘‡ğ‘ƒ + ğ‘‡ğ‘ + ğ¹ğ‘ƒ + ğ¹ğ‘
                                           ğ‘‡ğ‘ƒ
                 Precision:
                                       ğ‘‡ğ‘ƒ + ğ¹ğ‘ƒ
                                           ğ‘‡ğ‘ƒ
                 Recall (Sensitivity):
                                       ğ‘‡ğ‘ƒ + ğ¹ğ‘
                                       2 â‹… Precision â‹… Recall        2ğ‘‡ğ‘ƒ
                 F1 Score:                                    =
                                        Precision + Recall      2ğ‘‡ğ‘ƒ + ğ¹ğ‘ƒ + ğ¹ğ‘
                                           ğ‘‡ğ‘
                 Specificity:
                                       ğ‘‡ğ‘ + ğ¹ğ‘ƒ
Let ğ’Ÿ = {(ğ± 3 , ğ‘¦3 )}6345 denote the full dataset, and ğ’ŸK be the ğ‘˜-th fold. For metric ğ‘€, the mean
and standard deviation over ğ¾ = 10 folds are:

                                 h                                    h
                           1                           1
                        â€¾ = c ğ‘€K ,
                        ğ‘€                      ğœR = Ãˆ             â€¾ )1
                                                          c( ğ‘€K âˆ’ ğ‘€
                           ğ¾                          ğ¾âˆ’1
                                 K45                                 K45


Visualization-Based Evaluation
   â€¢   ROC Curves: Plot ğ‘‡ğ‘ƒğ‘…(ğœ) versus ğ¹ğ‘ƒğ‘…(ğœ) for ğœ âˆˆ [0,1] to see the sensitivity-
       specificity trade-off.

   â€¢   Calibration Curves: Check agreement between predicted probability ğ‘Ì‚3 and
       observed frequency ğ‘¦3 . For ğ¾ equal-width bins ğµK = [ğ‘˜/ğ¾, (ğ‘˜ + 1)/ğ¾):
                                        1                            1
                             ğ‘â€¾K =           c ğ‘Ì‚ 3 ,       ğ‘¦â€¾K =         c ğ‘¦3
                                       |ğµK |                        |ğµK |
                                            3âˆˆM(                           3âˆˆM(

   â€¢   Decision Curve Analysis (DCA):
                                             ğ‘‡ğ‘ƒ(ğ‘$ ) ğ¹ğ‘ƒ(ğ‘$ )     ğ‘$
                             ğ‘ğµ(ğ‘$ ) =              âˆ’        â‹…
                                               ğ‘›       ğ‘›       1 âˆ’ ğ‘$
       With benchmark strategies:
                                                                            ğ‘$
            ğ‘ğµijj (ğ‘$ ) = Prevalence âˆ’ (1 âˆ’ Prevalence) â‹…                        ,   ğ‘ğµ6k6l = 0
                                                                          1 âˆ’ ğ‘$
                             5
       where Prevalence = 6 âˆ‘6345 ğ‘¦3
Experimental Setup and Results
Structured clinical data from two cancer centers in China provided a training cohort (Cohort
A, ğ‘›# = 295) and an external test cohort (Cohort B, ğ‘›$ = 190). Cohort A contained 63
structured features; Cohort B contained 58 (Table 1).
Table 1: The training (Cohort A) and testing (Cohort B) cohorts.
 Characteristic          Cohort A (n = 295)   Cohort B (n = 190)
 Upper lobe
 Yes/Positive               121 (41.0%)           98 (51.6%)
 No/Negative                174 (59.0%)           92 (48.4%)
 Age (years)               56.95 Â± 11.03         58.26 Â± 9.57
 Lobe location (upper)
 Category 1                 161 (54.6%)          98 (51.6%)
 Category 2                  29 (9.8%)            18 (9.5%)
 Category 3                 105 (35.6%)          74 (38.9%)
 DLCO1                      5.90 Â± 2.89          6.31 Â± 1.55
 VC                         3.33 Â± 0.80          2.92 Â± 0.73
 CEA                        4.23 Â± 6.90          4.15 Â± 10.61
 CRE                       73.41 Â± 17.16        62.94 Â± 13.64
 NSE                        13.07 Â± 3.90         13.82 Â± 4.36
 Outcome (Malignant)
 Yes/Positive               189 (64.1%)          125 (65.8%)
 No/Negative                106 (35.9%)           65 (34.2%)

In source-domain evaluation (10-fold cross-validation on Cohort A), PANDA led on all
metrics (Fig. 2): AUC 0.829, accuracy 0.746, F1-score 0.810, precision 0.786, recall 0.846.
The high recall is what screening workflows tend to care about. Classical machine learning
methods were moderate (Random Forest AUC 0.752; XGBoost 0.742), and clinical scores
fared poorly.
For external validation (train on Cohort A, test on Cohort B), the TCA-enhanced PANDA
model again came out ahead (AUC 0.705, F1-score 0.808, recall 0.944), with the non-
adaptive version slightly behind at AUC 0.698. Among baselines, LASSO LR reached AUC
0.668 with recall 0.943; Random Forest dropped to 0.632; SVM, GBDT, and XGBoost fell
below 0.59, underscoring shift sensitivity.
Figure 2: Performance comparison across source and target domains. a Source domain 10-
fold cross-validation performance heatmap across five classification metrics. The PANDA
framework achieves the best overall performance across all metrics. b Cross-domain
performance heatmap on the external validation set. The TCA-enhanced PANDA model
shows the highest AUC and recall, indicating improved generalization under domain shift.
Feature-space checks (Fig. 3) suggest TCA is doing its job: PCA and t-SNE views tighten the
alignment between source and target after transformation, even if some scatter remains.
Figure 3: TCA-based domain adaptation visualization. a,b PCA visualization before and
after TCA transformation, showing improved alignment of target samples with source
samples. c,d t-SNE visualization before and after TCA transformation, demonstrating
enhanced cluster center alignment and distribution consistency.

Model Explainability, Reliability, and Clinical Utility
RFE with the pre-trained model kept interpretation manageable, and performance across
subset sizes leveled off around 9â€“13 features (Fig. 4). In terms of reliability, the ROC curves
give PANDA a clear edgeâ€”AUC 0.829 on the source cohort and 0.705 for the TCA-
augmented model on the external one. Calibration plots also place PANDA closer to the
diagonal, with TCA nudging the target-side curve a bit nearer to what we would hope for.
Decision curves, which weigh net clinical benefit across thresholds, tilt in PANDAâ€™s favor as
well, and the TCA variant adds a small but noticeable gain on the external cohort.
Figure 4: Comprehensive feature selection and performance analysis using recursive feature
elimination (RFE). a AUC, accuracy, and F1 curves as functions of the number of selected
features. Performance plateaus around 9â€“13 features, aligning with the preference for
simpler models. Shaded regions show variance across 10-fold cross-validation. b Class-
specific accuracy for malignant and benign cases across feature subset sizes, illustrating how
predictive balance shifts as features are removed. c Training-time analysis (seconds per fold)
as a function of feature dimensionality, highlighting the computational gain from smaller
subsets. d Stability assessment using the coefficient of variation across folds; lower values
indicate steadier performance. e Cost-effectiveness index combining multiple criteria
(PerformanceÃ—0.45 + SimplicityÃ—0.25 + EfficiencyÃ—0.15 + StabilityÃ—0.15) to identify a
feature count that balances accuracy with practical deployment considerations.
Figure 5: Performance and utility across source and target domains. a,b ROC curves. c,d
Calibration plots. e,f Decision curves.


Conclusion
This work links pre-trained tabular foundation models with domain adaptation to address
long-standing issues in tabular learning under distribution shift. PANDA suggests that
foundation-model priors and statistical alignment can reinforce one another, helping models
generalize from scarce, heterogeneous samples where standard supervised approaches often
stumble. The evidence is not sweeping, but it does point toward a practical recipe rather than
a one-off trick.
Several methodological themes stand out. Pre-trained representations reduce the effective
sample burden, letting high-capacity models behave sensibly in low-data regimes. Cross-
domain feature selection pinpoints predictors that consistently transfer between sites, which
makes alignment less fragile. Embedding TCA into these smoother representation spaces also
seems to make domain transitions more workable. Taken together, these pieces outline a
reasonable blueprint for adapting pre-trained tabular models across domains without relying
on abundant labels.
Beyond pulmonary nodules, the same ingredients likely extend to other structured settings
with small samples and noticeable shiftâ€”financial risk scores that change across branches,
industrial monitoring when sensors drift, or hospital-adjacent analytics where coding
practices evolve. PANDA is meant as a reusable template that treats pre-trained
representations as portable priors rather than site-specific quirks.
The claims about smoother representations, featureâ€“selection interactions, and reduced
sample complexity align with the observed reduction in discrepancy and the improved
external performance, hinting that pre-trained tabular models may broaden what is feasible in
domain adaptation.
Open questions remain: scaling to larger tabular foundation models, moving toward
multimodal pre-training, tightening feature selection for distributional robustness, and
handling continual shift. As tabular models mature, pairing them with principled alignment
may redefine how we handle shift.
In sum, PANDA frames tabular domain adaptation around pre-trained representations that
support cross-domain generalization, aiming for deployments where shift is the rule rather
than the exception.
List of Figures
  Figure 1: The PANDA framework architecture. (a) Compositional pipeline: from
      original tabular data through ensemble training, prediction aggregation, class
      imbalance adjustment, to final classification output. (b) Multi-branch ensemble
      with ğµ = 4 preprocessing strategies, each generating ğ‘† = 8 ensemble members via
      different random seeds. ..................................................................................... 12
  Figure 2: Performance comparison across source and target domains. a Source
      domain 10-fold cross-validation performance heatmap across five classification
      metrics. The PANDA framework achieves the best overall performance across all
      metrics. b Cross-domain performance heatmap on the external validation set. The
      TCA-enhanced PANDA model shows the highest AUC and recall, indicating
      improved generalization under domain shift. ................................................... 23
  Figure 3: TCA-based domain adaptation visualization. a,b PCA visualization before and
      after TCA transformation, showing improved alignment of target samples with
      source samples. c,d t-SNE visualization before and after TCA transformation,
      demonstrating enhanced cluster center alignment and distribution consistency.24
  Figure 4: Comprehensive feature selection and performance analysis using recursive
      feature elimination (RFE). a AUC, accuracy, and F1 curves as functions of the
      number of selected features. Performance plateaus around 9â€“13 features, aligning
      with the preference for simpler models. Shaded regions show variance across 10-
      fold cross-validation. b Class-specific accuracy for malignant and benign cases
      across feature subset sizes, illustrating how predictive balance shifts as features are
      removed. c Training-time analysis (seconds per fold) as a function of feature
      dimensionality, highlighting the computational gain from smaller subsets. d
      Stability assessment using the coefficient of variation across folds; lower values
      indicate steadier performance. e Cost-effectiveness index combining multiple
      criteria (PerformanceÃ—0.45 + SimplicityÃ—0.25 + EfficiencyÃ—0.15 + StabilityÃ—0.15)
      to identify a feature count that balances accuracy with practical deployment
      considerations. .................................................................................................. 25
  Figure 5: Performance and utility across source and target domains. a,b ROC
      curves. c,d Calibration plots. e,f Decision curves............................................. 26
List of Tables
  Table 1: The training (Cohort A) and testing (Cohort B) cohorts. ........................... 22
Chapter [chapter index]
The thesis is organized into the following major components:

1.   Introduction â€“ Presents the motivation for cross-hospital pulmonary nodule prediction
     and outlines the limitations of existing clinical and machine learning methods.

2.   Related Work â€“ Summarizes research on tabular foundation models, domain adaptation,
     and pulmonary nodule risk modeling.

3.   Problem Formulation â€“ Formalizes cross-institutional prediction as an unsupervised
     domain adaptation problem under distribution shift, small sample sizes, and feature
     heterogeneity.

4.   Solution â€“ Introduces the PANDA framework, combining cross-domain feature
     selection, pre-trained tabular foundation models, and domain alignment via TCA.

5.   Methods â€“ Details the architectural components, preprocessing strategies, feature
     selection, alignment mechanisms, evaluation protocol, and datasets.

6.   Analysis â€“ Examines how each module addresses specific challenges, including small-
     sample learning, distribution shift, feature inconsistency, and model calibration.

7.   Evaluation â€“ Reports cross-validation and external validation results, including
     performance metrics, calibration, ROC curves, and decision-curve analysis.

8.   Conclusion â€“ Summarizes contributions, discusses broader implications, and outlines
     future research directions.
References
[1]    Swensen SJ, Silverstein MD, Ilstrup DM, Schleck CD, Edell ES 1997. The
probability of malignancy in solitary pulmonary nodules: Application to clinical practice.
Chest.111:228â€“234
[2]     Gould MK, Ananth L, Barnett PG, others 2007. Clinical prediction of 1-year survival
for patients with lung cancer. Chest.132:872â€“880
[3]    Cui X, Heuvelmans MA, Han D, Zhao Y, Fan S, Zheng S, Sidorenkov G, Groen
HJM, Dorrius MD, Oudkerk M, Bock GH de, Vliegenthart R, Ye Z 2019. Comparison of
veterans affairs, mayo, brock classification models and radiologist diagnosis for classifying
the malignancy of pulmonary nodules in chinese clinical population. Translational Lung
Cancer Research.8:
[4]    Hollmann N, MÃ¼ller S, Purucker L, Krishnakumar A, KÃ¶rfer M, Hoo SB,
Schirrmeister RT, Hutter F 2025. Accurate predictions on small data with a tabular
foundation model. Nature.637:319â€“326
[5]    Zech JR, Badgeley MA, Liu M, Costa AB, Titano JJ, Oermann EK 2018. Variable
generalization performance of a deep learning model to detect pneumonia in chest
radiographs: A cross-sectional study. PLOS Medicine.15:e1002683
[6]    Guan H, Liu M 2021. Domain adaptation for medical image analysis: A survey. IEEE
Transactions on Biomedical Engineering.69:1173â€“1185
[7]   Borisov V, Leemann T, Selegue P, Miotto R, May M, ZÃ¼fle A 2022. Deep neural
networks and tabular data: A survey. IEEE Transactions on Neural Networks and Learning
Systems.33:4472â€“4492
[8]    Guo LL, Pfohl SR, Fries J, Johnson AEW, Posada J, Aftandilian C, Shah N, Sung L
2022. Evaluation of domain generalization and adaptation on improving model robustness to
temporal dataset shift in clinical medicine. Scientific Reports.12:2726
[9]     Zhou D, Tong H, Wang L, Liu S, Xiong X, Gan Z, Griffier R, Hejblum B, Liu Y-C,
Hong C, Bonzel C-L, Cai T, Pan K, Ho Y-L, Costa L, Panickan VA, Gaziano JM, Mandl K,
Jouhet V, Thiebaut R, Xia Z, Cho K, Liao K, Cai T 2025. Representation learning to advance
multi-institutional studies with electronic health record data.
[10] Schneider J, Meske C, Kuss P 2024. Foundation models: A new paradigm for
artificial intelligence. Business & Information Systems Engineering.66:221â€“231
[11] Chen T, Guestrin C 2016. Xgboost: A scalable tree boosting system. Proceedings of
the 22nd acm sigkdd international conference on knowledge discovery and data mining.785â€“
794
[12] Arik SO, Pfister T 2021. TabNet: Attentive interpretable tabular learning. Proceedings
of the AAAI conference on artificial intelligence.35:6679â€“6687
[13] Huang X, Khetan A, Cvitkovic M, Karnin Z 2020. TabTransformer: Tabular data
modeling using contextual embeddings. Advances in neural information processing
systems.33:14914â€“14925
[14] Somepalli G, Goldblum M, Schwarzschild A, Bruss CB, Goldstein T 2021. Saint:
Improved neural networks for tabular data via row attention and contrastive pre-training.
arXiv preprint arXiv:2106.01342.
[15] Gorishniy Y, Rubachev I, Khrulkov V, Babenko A 2021. Revisiting deep learning
models for tabular data. Advances in neural information processing systems.34:18932â€“18943
[16] Hollmann N, MÃ¼ller S, Purucker L, Krishnakumar A, KÃ¶rfer M, Hoo SB,
Schirrmeister RT, Hutter F 2025. Accurate predictions on small data with a tabular
foundation model. Nature.637:319â€“326
[17] Zhang T, Chen M, Bui AAT 2022. AdaDiag: Adversarial domain adaptation of
diagnostic prediction with clinical event sequences. J Biomed Inform.134:104168
[18] Sun B, Feng J, Saenko K 2016. Correlation alignment for unsupervised domain
adaptation.
[19] McWilliams A, Tammemagi MC, Mayo JR, Roberts H, Liu G, Soghrati K, Yasufuku
K, Martel S, Laberge F, Gingras M, Atsu K, Pastis N, Hett K, Sejpal T, Stewart T, Tsao M-S,
Goffin J 2013. Probability of malignancy in pulmonary nodules detected on first screening
CT. New England Journal of Medicine.369:910â€“919
[20] Li Y, Hu H, Wu Z, Yan G, Wu T, Liu S, Chen W, Lu Z 2020. Evaluation of models
for predicting the probability of malignancy in patients with pulmonary nodules. Biosci
Rep.40:BSR20193875
[21] Hassani C, Varghese BA, Nieva J, Duddalwar V 2019. Radiomics in pulmonary
lesion imaging. American Journal of Roentgenology.212:497â€“504
[22] Causey JL, Zhang J, Ma S, Jiang B, Qualls JA, Politte DG, Prior F, Zhang S, Huang
X 2018. Highly accurate model for prediction of lung nodule malignancy with CT scans. Sci
Rep.8:9286
[23] Koch LM, Baumgartner CF, Berens P 2024. Distribution shift detection for the
postmarket surveillance of medical AI algorithms: A retrospective simulation study. NPJ
Digital Medicine.7:120
[24] Musa A, Prasad R, Hernandez M 2025. Addressing cross-population domain shift in
chest x-ray classification through supervised adversarial domain adaptation. Scientific
Reports.15:11383
[25] Bommasani R, Hudson DA, Adeli E, al. et 2021. On the opportunities and risks of
foundation models. arXiv preprint arXiv:2108.07258.
[26] Breiman L, Friedman J, Olshen RA, Stone CJ 1984. Classification and regression
trees.
[27] Friedman JH 2001. Greedy function approximation: A gradient boosting machine.
Annals of statistics.1189â€“1232
[28]   Breiman L 2001. Random forests. Machine learning.45:5â€“32
[29]   Cortes C, Vapnik V 1995. Support-vector networks. Machine learning.20:273â€“297
[30] He X, Xue N, Liu X, Tang X, Peng S, Qu Y, Jiang L, Xu Q, Liu W, Chen S 2021. A
novel clinical model for predicting malignancy of solitary pulmonary nodules: A multicenter
study in chinese population. Cancer cell international.21:115
[31] Perandini S, Soardi GA, Motton M, Rossi A, Signorini M, Montemezzi S 2016. Solid
pulmonary nodule risk assessment and decision analysis: Comparison of four prediction
models in 285 cases. Eur Radiol.26:3071â€“3076
