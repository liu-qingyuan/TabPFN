\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\citation{swensen1997chest}
\citation{mcwilliams2013probability}
\citation{li2011development}
\citation{he2021novel}
\citation{garau_external_2020}
\citation{zhang_comprehensive_2022}
\citation{liu_establishment_2024}
\citation{chen2016xgboost}
\citation{gorishniy2021revisiting}
\citation{garau_external_2020}
\citation{hellin2024unraveling}
\citation{arik2021tabnet}
\citation{huang2020tabtransformer}
\citation{somepalli2021saint}
\citation{borisov2022deep}
\citation{gorishniy2021revisiting}
\citation{hollmann2025accurate}
\citation{noauthor_prior_nodate}
\citation{noauthor_closer_nodate}
\citation{noauthor_realistic_nodate}
\citation{noauthor_automldrift-resilient_tabpfn_2025}
\citation{eremeev_turning_2025}
\citation{schneider2024foundation}
\citation{guan2021domain}
\citation{musa2025addressing}
\citation{koch2024distribution}
\citation{guo_evaluation_2022}
\citation{orouji_domain_nodate}
\citation{guan2021domain}
\citation{gardner_benchmarking_2024}
\citation{ahn_unsupervised_2023}
\citation{koch2024distribution}
\citation{schneider2024foundation}
\citation{noauthor_realistic_nodate}
\citation{noauthor_prior_nodate}
\citation{noauthor_automldrift-resilient_tabpfn_2025}
\citation{swensen1997chest}
\citation{mcwilliams2013probability}
\citation{li2011development}
\citation{he2021novel}
\citation{zhang_comprehensive_2022}
\citation{garau_external_2020}
\citation{liu_establishment_2024}
\citation{ardila_end--end_2019}
\citation{zech_variable_2018}
\citation{hellin2024unraveling}
\citation{guan2021domain}
\citation{ahn_unsupervised_2023}
\citation{gardner_benchmarking_2024}
\citation{ahn_unsupervised_2023}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\newlabel{sec:intro-start}{{1}{3}{Introduction}{section.1}{}}
\citation{gorishniy2021revisiting}
\citation{borisov2022deep}
\citation{schneider2024foundation}
\citation{noauthor_realistic_nodate}
\citation{noauthor_automldrift-resilient_tabpfn_2025}
\citation{koch2024distribution}
\citation{garau_external_2020}
\citation{hellin2024unraveling}
\citation{zech_variable_2018}
\citation{chen2016xgboost}
\citation{borisov2022deep}
\citation{arik2021tabnet}
\citation{huang2020tabtransformer}
\citation{somepalli2021saint}
\citation{gorishniy2021revisiting}
\citation{schneider2024foundation}
\citation{noauthor_realistic_nodate}
\citation{noauthor_automldrift-resilient_tabpfn_2025}
\citation{eremeev_turning_2025}
\citation{sun2019informative}
\citation{garau_external_2020}
\citation{liu_establishment_2024}
\citation{zhang_comprehensive_2022}
\citation{hellin2024unraveling}
\citation{koch2024distribution}
\citation{koch2024distribution}
\citation{guan2021domain}
\citation{ahn_unsupervised_2023}
\citation{gardner_benchmarking_2024}
\citation{sun2019informative}
\citation{eremeev_turning_2025}
\citation{chen2016xgboost}
\citation{gorishniy2021revisiting}
\citation{borisov2022deep}
\citation{schneider2024foundation}
\citation{noauthor_realistic_nodate}
\citation{ahn_unsupervised_2023}
\citation{gardner_benchmarking_2024}
\citation{koch2024distribution}
\citation{hollmann2025accurate}
\citation{pan2010domain}
\citation{sun2019informative}
\citation{bommasani2021opportunities}
\citation{schneider2024foundation}
\citation{chen2016xgboost}
\citation{grinsztajn_why_2022}
\citation{borisov2022deep}
\citation{gorishniy2021revisiting}
\citation{shmuel_comprehensive_2024}
\citation{fan_tabular_2024}
\citation{borisov_deep_2024}
\citation{liu_tabpfn_2025}
\newlabel{sec:intro-end}{{1}{7}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{7}{section.2}\protected@file@percent }
\newlabel{sec:rw-start}{{2}{7}{Related Work}{section.2}{}}
\newlabel{sec:related-work}{{2}{7}{Related Work}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Tabular learning for medical data: tree ensembles, deep tabular networks, and tabular foundation models}{7}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Tree ensembles for clinical tabular data}{7}{subsubsection.2.1.1}\protected@file@percent }
\citation{arik2021tabnet}
\citation{huang_tabtransformer_2020}
\citation{gorishniy_revisiting_2021}
\citation{somepalli2021saint}
\citation{margeloiu2023weight}
\citation{loh_basis_2025}
\citation{khoeini_fttransformer_2024}
\citation{bytezcom_tabicl_2025}
\citation{somvanshi2024survey}
\citation{fan_tabular_2024}
\citation{shmuel_comprehensive_2024}
\citation{ren_deep_2025}
\citation{gorishniy2021revisiting}
\citation{guo_evaluation_2022}
\citation{ren_deep_2025}
\citation{hollmann2025accurate}
\citation{hollmann_accurate_2025}
\citation{noauthor_prior_nodate}
\citation{noauthor_closer_nodate}
\citation{noauthor_realistic_nodate}
\citation{helli_drift-resilient_2024}
\citation{noauthor_automldrift-resilient_tabpfn_2025}
\citation{chen_tabpfn_2025}
\citation{eremeev_turning_2025}
\citation{liu_tabular_2025}
\citation{brown2020language}
\citation{eremeev_turning_2025}
\citation{jayawardhana_transformers_2025}
\citation{zhou_limitations_2025}
\citation{noauthor_pdf_nodate}
\citation{kolesnikov_wild-tab_2023}
\citation{liu_tabpfn_2025}
\citation{loh_basis_2025}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Deep tabular networks}{8}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Tabular foundation models}{8}{subsubsection.2.1.3}\protected@file@percent }
\citation{koch2024distribution}
\citation{guo_evaluation_2022}
\citation{pan2010domain}
\citation{sun2016correlationalignmentunsuperviseddomain}
\citation{grubinger2015domain}
\citation{zhang_adadiag_2022}
\citation{li_transport-based_2024}
\citation{guo_evaluation_2022}
\citation{zhang_adadiag_2022}
\citation{guan2021domain}
\citation{pan2010domain}
\citation{gardner_benchmarking_2024}
\citation{koch2024distribution}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparative strengths and weaknesses of tabular model families in medical AI.}}{9}{table.1}\protected@file@percent }
\newlabel{tab:model_summary}{{1}{9}{Comparative strengths and weaknesses of tabular model families in medical AI}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Domain shift and domain adaptation in medical AI}{9}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Statistical alignment vs. adversarial objectives}{9}{subsubsection.2.2.1}\protected@file@percent }
\citation{luo2021fsda}
\citation{grubinger2015domain}
\citation{pham_open-set_2025}
\citation{li_transport-based_2024}
\citation{guan2021domain}
\citation{guan_domainatm_2023}
\citation{guan_domain_2022}
\citation{zhou_domain_2023}
\citation{stokes_domain_2025}
\citation{ahn_unsupervised_2023}
\citation{he_multi-attention_2022}
\citation{gardner_benchmarking_2024}
\citation{noauthor_mlfoundationstableshift_nodate}
\citation{gardner_tableshift_nodate}
\citation{kolesnikov_wild-tab_2023}
\citation{ahn_unsupervised_2023}
\citation{koch2024distribution}
\citation{guyon2002gene}
\citation{chen2023graces}
\citation{liu2022deepfs}
\citation{li2023deep}
\citation{arik2021tabnet}
\citation{huang2020tabtransformer}
\citation{somepalli2021saint}
\citation{somvanshi2024survey}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Heterogeneity, missingness, and temporal drift}{10}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Domain generalization and open-set gaps}{10}{subsubsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Feature selection and domain-aware stability for small medical cohorts}{10}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Small-sample and high-dimensional feature selection}{10}{subsubsection.2.3.1}\protected@file@percent }
\citation{luo2021fsda}
\citation{sun2019informative}
\citation{swensen1997chest}
\citation{swensen1997archives}
\citation{mcwilliams2013probability}
\citation{li2011development}
\citation{he2021novel}
\citation{garau_external_2020}
\citation{zhang_comprehensive_2022}
\citation{liu_establishment_2024}
\citation{garau_external_2020}
\citation{zhang_comprehensive_2022}
\citation{liu_establishment_2024}
\citation{chen_pulmonary_2025}
\citation{swensen1997chest}
\citation{swensen1997archives}
\citation{mcwilliams2013probability}
\citation{li2011development}
\citation{he2021novel}
\citation{liu_establishment_2024}
\citation{chen_pulmonary_2025}
\citation{garau_external_2020}
\citation{zhang_comprehensive_2022}
\citation{liu_establishment_2024}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Feature selection with transformers and foundation models}{11}{subsubsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Domain-aware and cross-site feature selection}{11}{subsubsection.2.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Pulmonary nodule malignancy prediction: from clinical scores to multi-modal AI}{11}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Clinical risk scores and logistic models}{11}{subsubsection.2.4.1}\protected@file@percent }
\citation{chen_pulmonary_2025}
\citation{li2011development}
\citation{he2021novel}
\citation{liu_establishment_2024}
\citation{hellin2024unraveling}
\citation{garau_external_2020}
\citation{ardila_end--end_2019}
\citation{zech_variable_2018}
\citation{koch2024distribution}
\citation{hellin2024unraveling}
\citation{garau_external_2020}
\citation{hellin2024unraveling}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Representative pulmonary nodule malignancy scores and common external-validation issues.}}{12}{table.2}\protected@file@percent }
\newlabel{tab:nodule_scores}{{2}{12}{Representative pulmonary nodule malignancy scores and common external-validation issues}{table.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Radiomics pipelines with traditional machine learning}{12}{subsubsection.2.4.2}\protected@file@percent }
\citation{ardila_end--end_2019}
\citation{li_predicting_2019}
\citation{lin_combined_2024}
\citation{zech_variable_2018}
\citation{hellin2024unraveling}
\citation{koch2024distribution}
\citation{he2021novel}
\citation{garau_external_2020}
\citation{li_predicting_2019}
\citation{lin_combined_2024}
\citation{garau_external_2020}
\citation{hellin2024unraveling}
\citation{garau_external_2020}
\citation{hellin2024unraveling}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Deep-learning CAD systems}{13}{subsubsection.2.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.4}Tabular and multi-modal nodule models}{13}{subsubsection.2.4.4}\protected@file@percent }
\citation{gardner_benchmarking_2024}
\citation{gardner_tableshift_nodate}
\citation{kolesnikov_wild-tab_2023}
\citation{ahn_unsupervised_2023}
\citation{gardner_benchmarking_2024}
\citation{noauthor_mlfoundationstableshift_nodate}
\citation{ahn_unsupervised_2023}
\citation{koch2024distribution}
\citation{guo_evaluation_2022}
\citation{gardner_benchmarking_2024}
\citation{ahn_unsupervised_2023}
\citation{hellin2024unraveling}
\citation{koch2024distribution}
\citation{gardner_benchmarking_2024}
\citation{noauthor_mlfoundationstableshift_nodate}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Benchmarks and open problems for cross-domain tabular learning}{14}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Gap analysis and positioning of PANDA}{14}{subsubsection.2.5.1}\protected@file@percent }
\newlabel{sec:rw-end}{{2.5.1}{14}{Gap analysis and positioning of PANDA}{subsubsection.2.5.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Problem Formulation}{14}{section.3}\protected@file@percent }
\newlabel{sec:pf-start}{{3}{14}{Problem Formulation}{section.3}{}}
\newlabel{sec:problem-formulation}{{3}{14}{Problem Formulation}{section.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Feature partitioning for the two cross-domain tasks. $\mathcal  {F}_{\cap }$ contains the variables usable across domains; $\mathcal  {F}_{\setminus }$ collects site- or demographic-specific factors excluded from modeling.}}{15}{table.3}\protected@file@percent }
\newlabel{tab:feature_partitions}{{3}{15}{Feature partitioning for the two cross-domain tasks. $\mathcal {F}_{\cap }$ contains the variables usable across domains; $\mathcal {F}_{\setminus }$ collects site- or demographic-specific factors excluded from modeling}{table.3}{}}
\newlabel{sec:pf-end}{{3}{16}{Challenges in Cross-Institutional Learning}{section*.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Solution}{16}{section.4}\protected@file@percent }
\newlabel{sec:solution}{{4}{16}{Solution}{section.4}{}}
\newlabel{sec:sol-start}{{4}{16}{Solution}{section.4}{}}
\@writefile{toc}{\contentsline {paragraph}{(1) Cross-domain feature selection.}{16}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(2) Foundation-model representation.}{16}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(3) Domain-invariant alignment via TCA.}{16}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(4) Classification head with ensemble aggregation.}{16}{section*.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {The PANDA framework architecture.} (a) Compositional pipeline: from original tabular data through ensemble training, prediction aggregation, class imbalance adjustment, to final classification output. (b) Multi-branch ensemble with $B=4$ preprocessing strategies, each generating $S=8$ ensemble members via different random seeds.}}{17}{figure.1}\protected@file@percent }
\newlabel{fig:model_details}{{1}{17}{\textbf {The PANDA framework architecture.} (a) Compositional pipeline: from original tabular data through ensemble training, prediction aggregation, class imbalance adjustment, to final classification output. (b) Multi-branch ensemble with $B=4$ preprocessing strategies, each generating $S=8$ ensemble members via different random seeds}{figure.1}{}}
\newlabel{sec:sol-end}{{4}{18}{Unified Objective}{section*.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Methods}{18}{section.5}\protected@file@percent }
\newlabel{sec:methods}{{5}{18}{Methods}{section.5}{}}
\newlabel{sec:meth-start}{{5}{18}{Methods}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Motivating Challenges and Methodological Response}{18}{subsection.5.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Challenge--mechanism mapping in PANDA. Each component targets a known failure mode, and the same design is reused for pulmonary nodules and the TableShift BRFSS race-shift task.}}{18}{table.4}\protected@file@percent }
\newlabel{tab:challenge_mapping}{{4}{18}{Challenge--mechanism mapping in PANDA. Each component targets a known failure mode, and the same design is reused for pulmonary nodules and the TableShift BRFSS race-shift task}{table.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Training and Inference Pipeline}{18}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Foundation Model Architecture}{19}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}TabPFN Backbone Details}{19}{subsubsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Synthetic Task Generation}{19}{subsubsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Feature Selection and Preprocessing}{19}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1}Cross-Domain RFE Algorithm}{19}{subsubsection.5.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.2}Multi-Branch Preprocessing Pipeline}{19}{subsubsection.5.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Domain Adaptation Implementation}{20}{subsection.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.1}TCA Optimization}{20}{subsubsection.5.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.2}Label Prevalence Handling}{20}{subsubsection.5.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Assumptions and Mitigation Strategies}{20}{subsection.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Ethics Statement and Data Collection}{20}{subsection.5.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.7.1}Data Variables and Measurements}{20}{subsubsection.5.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}Experimental Procedures}{20}{subsection.5.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.8.1}Cross-Validation Protocol}{20}{subsubsection.5.8.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Key assumptions behind PANDA and the mitigation strategies employed when deployments deviate from them.}}{21}{table.5}\protected@file@percent }
\newlabel{tab:assumption_table}{{5}{21}{Key assumptions behind PANDA and the mitigation strategies employed when deployments deviate from them}{table.5}{}}
\citation{breiman1984classification}
\citation{friedman2001greedy}
\citation{breiman2001random}
\citation{chen2016xgboost}
\citation{cortes1995support}
\citation{he2021novel}
\citation{swensen1997chest}
\citation{perandini_solid_2016}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.8.2}Baseline Methods}{22}{subsubsection.5.8.2}\protected@file@percent }
\newlabel{sec:meth-end}{{5.8.2}{22}{Baseline Methods}{subsubsection.5.8.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Analysis}{22}{section.6}\protected@file@percent }
\newlabel{sec:analysis-start}{{6}{22}{Analysis}{section.6}{}}
\newlabel{sec:analysis}{{6}{22}{Analysis}{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}In-Context Learning for Small-Sample Robustness}{22}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Mitigating Distributional Heterogeneity}{23}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Addressing Feature Inconsistency}{23}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Latent Space Alignment for Covariate Shift}{24}{subsection.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Stabilizing Predictions with Ensemble Aggregation}{25}{subsection.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Why PANDA Outperforms Baselines}{25}{subsection.6.6}\protected@file@percent }
\newlabel{sec:analysis-end}{{6.6}{25}{Why PANDA Outperforms Baselines}{subsection.6.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Evaluation}{25}{section.7}\protected@file@percent }
\newlabel{sec:eval-start}{{7}{25}{Evaluation}{section.7}{}}
\newlabel{sec:evaluation}{{7}{25}{Evaluation}{section.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Evaluation Metrics and Statistical Analysis}{26}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}Classification Performance Metrics}{26}{subsubsection.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}Visualization-Based Evaluation}{26}{subsubsection.7.1.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces The training (Cohort A) and testing (Cohort B) cohorts.}}{27}{table.6}\protected@file@percent }
\newlabel{tab:cohort_summary}{{6}{27}{The training (Cohort A) and testing (Cohort B) cohorts}{table.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Experimental Setup and Results}{27}{subsection.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Additional Cross-Domain Validation on a Public Benchmark}{27}{subsection.7.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Performance comparison across source and target domains.} \textbf  {a} Source domain 10-fold cross-validation performance heatmap across five classification metrics. The PANDA framework achieves the best overall performance across all metrics. \textbf  {b} Cross-domain performance heatmap on the external validation set. The TCA-enhanced PANDA model shows the highest AUC and recall, indicating improved generalization under domain shift.}}{28}{figure.2}\protected@file@percent }
\newlabel{fig:performance-heatmaps}{{2}{28}{\textbf {Performance comparison across source and target domains.} \textbf {a} Source domain 10-fold cross-validation performance heatmap across five classification metrics. The PANDA framework achieves the best overall performance across all metrics. \textbf {b} Cross-domain performance heatmap on the external validation set. The TCA-enhanced PANDA model shows the highest AUC and recall, indicating improved generalization under domain shift}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces TCA-based domain adaptation visualization. \textbf  {a,b} PCA visualization before and after TCA transformation, showing improved alignment of target samples with source samples. \textbf  {c,d} t-SNE visualization before and after TCA transformation, demonstrating enhanced cluster center alignment and distribution consistency.}}{29}{figure.3}\protected@file@percent }
\newlabel{fig:tca-visualization}{{3}{29}{TCA-based domain adaptation visualization. \textbf {a,b} PCA visualization before and after TCA transformation, showing improved alignment of target samples with source samples. \textbf {c,d} t-SNE visualization before and after TCA transformation, demonstrating enhanced cluster center alignment and distribution consistency}{figure.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces In-distribution (ID) versus out-of-distribution (OOD) BRFSS Diabetes cohorts under race shift.}}{30}{table.7}\protected@file@percent }
\newlabel{tab:brfss_cohort_summary}{{7}{30}{In-distribution (ID) versus out-of-distribution (OOD) BRFSS Diabetes cohorts under race shift}{table.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {TableShift BRFSS Diabetes (race shift: White $\rightarrow $ non-White).} \textbf  {a,b} ROC curves for baselines and PANDA variants on the public benchmark. \textbf  {c,d} Calibration curves highlighting probability alignment post-adaptation. \textbf  {e,f} Decision curves illustrating net benefit across threshold ranges.}}{31}{figure.4}\protected@file@percent }
\newlabel{fig:brfss-roc}{{4}{31}{\textbf {TableShift BRFSS Diabetes (race shift: White $\rightarrow $ non-White).} \textbf {a,b} ROC curves for baselines and PANDA variants on the public benchmark. \textbf {c,d} Calibration curves highlighting probability alignment post-adaptation. \textbf {e,f} Decision curves illustrating net benefit across threshold ranges}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Performance heatmaps for the TableShift BRFSS Diabetes task.} \textbf  {a} Source cross-validation metrics. \textbf  {b} Race-shift (White $\rightarrow $ non-White) OOD metrics.}}{32}{figure.5}\protected@file@percent }
\newlabel{fig:brfss-heatmap}{{5}{32}{\textbf {Performance heatmaps for the TableShift BRFSS Diabetes task.} \textbf {a} Source cross-validation metrics. \textbf {b} Race-shift (White $\rightarrow $ non-White) OOD metrics}{figure.5}{}}
\bibstyle{unsrt}
\bibdata{refs}
\bibcite{swensen1997chest}{1}
\bibcite{mcwilliams2013probability}{2}
\bibcite{li2011development}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Model Explainability, Reliability, and Clinical Utility}{33}{subsection.7.4}\protected@file@percent }
\newlabel{sec:eval-end}{{7.4}{33}{Model Explainability, Reliability, and Clinical Utility}{figure.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{33}{section.8}\protected@file@percent }
\newlabel{sec:conclusion}{{8}{33}{Conclusion}{section.8}{}}
\newlabel{sec:concl-end}{{8}{33}{Conclusion}{section.8}{}}
\newlabel{sec:ack-start}{{8}{33}{Acknowledgements}{section*.9}{}}
\newlabel{sec:ack-end}{{8}{33}{Acknowledgements}{section*.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Comprehensive feature selection and performance analysis using recursive feature elimination (RFE). \textbf  {a} AUC, accuracy, and F1 curves as functions of the number of selected features. Performance plateaus around 9--13 features, aligning with the preference for simpler models. Shaded regions show variance across 10-fold cross-validation. \textbf  {b} Class-specific accuracy for malignant and benign cases across feature subset sizes, illustrating how predictive balance shifts as features are removed. \textbf  {c} Training-time analysis (seconds per fold) as a function of feature dimensionality, highlighting the computational gain from smaller subsets. \textbf  {d} Stability assessment using the coefficient of variation across folds; lower values indicate steadier performance. \textbf  {e} Cost-effectiveness index combining multiple criteria (Performance×0.45 + Simplicity×0.25 + Efficiency×0.15 + Stability×0.15) to identify a feature count that balances accuracy with practical deployment considerations.}}{34}{figure.6}\protected@file@percent }
\newlabel{fig:rfe-performance}{{6}{34}{Comprehensive feature selection and performance analysis using recursive feature elimination (RFE). \textbf {a} AUC, accuracy, and F1 curves as functions of the number of selected features. Performance plateaus around 9--13 features, aligning with the preference for simpler models. Shaded regions show variance across 10-fold cross-validation. \textbf {b} Class-specific accuracy for malignant and benign cases across feature subset sizes, illustrating how predictive balance shifts as features are removed. \textbf {c} Training-time analysis (seconds per fold) as a function of feature dimensionality, highlighting the computational gain from smaller subsets. \textbf {d} Stability assessment using the coefficient of variation across folds; lower values indicate steadier performance. \textbf {e} Cost-effectiveness index combining multiple criteria (Performance×0.45 + Simplicity×0.25 + Efficiency×0.15 + Stability×0.15) to identify a feature count that balances accuracy with practical deployment considerations}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {Cross-hospital pulmonary nodule task (Cohort A $\rightarrow $ Cohort B).} \textbf  {a,b} ROC curves on source and target cohorts. \textbf  {c,d} Calibration plots showing probability reliability after TCA. \textbf  {e,f} Decision curves quantifying net benefit for internal versus external deployment.}}{35}{figure.7}\protected@file@percent }
\newlabel{fig:combined_analysis}{{7}{35}{\textbf {Cross-hospital pulmonary nodule task (Cohort A $\rightarrow $ Cohort B).} \textbf {a,b} ROC curves on source and target cohorts. \textbf {c,d} Calibration plots showing probability reliability after TCA. \textbf {e,f} Decision curves quantifying net benefit for internal versus external deployment}{figure.7}{}}
\bibcite{he2021novel}{4}
\bibcite{garau_external_2020}{5}
\bibcite{zhang_comprehensive_2022}{6}
\bibcite{liu_establishment_2024}{7}
\bibcite{chen2016xgboost}{8}
\bibcite{gorishniy2021revisiting}{9}
\bibcite{hellin2024unraveling}{10}
\bibcite{arik2021tabnet}{11}
\bibcite{huang2020tabtransformer}{12}
\bibcite{somepalli2021saint}{13}
\bibcite{borisov2022deep}{14}
\bibcite{hollmann2025accurate}{15}
\bibcite{noauthor_prior_nodate}{16}
\bibcite{noauthor_closer_nodate}{17}
\bibcite{noauthor_realistic_nodate}{18}
\bibcite{noauthor_automldrift-resilient_tabpfn_2025}{19}
\bibcite{eremeev_turning_2025}{20}
\bibcite{schneider2024foundation}{21}
\bibcite{guan2021domain}{22}
\bibcite{musa2025addressing}{23}
\bibcite{koch2024distribution}{24}
\bibcite{guo_evaluation_2022}{25}
\bibcite{orouji_domain_nodate}{26}
\bibcite{gardner_benchmarking_2024}{27}
\bibcite{ahn_unsupervised_2023}{28}
\bibcite{ardila_end--end_2019}{29}
\bibcite{zech_variable_2018}{30}
\bibcite{sun2019informative}{31}
\bibcite{pan2010domain}{32}
\bibcite{bommasani2021opportunities}{33}
\bibcite{grinsztajn_why_2022}{34}
\bibcite{shmuel_comprehensive_2024}{35}
\bibcite{fan_tabular_2024}{36}
\bibcite{borisov_deep_2024}{37}
\bibcite{liu_tabpfn_2025}{38}
\bibcite{huang_tabtransformer_2020}{39}
\bibcite{gorishniy_revisiting_2021}{40}
\bibcite{margeloiu2023weight}{41}
\bibcite{loh_basis_2025}{42}
\bibcite{khoeini_fttransformer_2024}{43}
\bibcite{bytezcom_tabicl_2025}{44}
\bibcite{somvanshi2024survey}{45}
\bibcite{ren_deep_2025}{46}
\bibcite{hollmann_accurate_2025}{47}
\bibcite{helli_drift-resilient_2024}{48}
\bibcite{chen_tabpfn_2025}{49}
\bibcite{liu_tabular_2025}{50}
\bibcite{brown2020language}{51}
\bibcite{jayawardhana_transformers_2025}{52}
\bibcite{zhou_limitations_2025}{53}
\bibcite{noauthor_pdf_nodate}{54}
\bibcite{kolesnikov_wild-tab_2023}{55}
\bibcite{sun2016correlationalignmentunsuperviseddomain}{56}
\bibcite{grubinger2015domain}{57}
\bibcite{zhang_adadiag_2022}{58}
\bibcite{li_transport-based_2024}{59}
\bibcite{luo2021fsda}{60}
\bibcite{pham_open-set_2025}{61}
\bibcite{guan_domainatm_2023}{62}
\bibcite{guan_domain_2022}{63}
\bibcite{zhou_domain_2023}{64}
\bibcite{stokes_domain_2025}{65}
\bibcite{he_multi-attention_2022}{66}
\bibcite{noauthor_mlfoundationstableshift_nodate}{67}
\bibcite{gardner_tableshift_nodate}{68}
\bibcite{guyon2002gene}{69}
\bibcite{chen2023graces}{70}
\bibcite{liu2022deepfs}{71}
\bibcite{li2023deep}{72}
\bibcite{swensen1997archives}{73}
\bibcite{chen_pulmonary_2025}{74}
\bibcite{li_predicting_2019}{75}
\bibcite{lin_combined_2024}{76}
\bibcite{breiman1984classification}{77}
\bibcite{friedman2001greedy}{78}
\bibcite{breiman2001random}{79}
\bibcite{cortes1995support}{80}
\bibcite{perandini_solid_2016}{81}
\gdef \@abspage@last{40}
