\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\citation{swensen1997chest}
\citation{mcwilliams2013probability}
\citation{li2011development}
\citation{he2021novel}
\citation{zhang_comprehensive_2022}
\citation{liu_establishment_2024}
\citation{garau_external_2020}
\citation{zhang_comprehensive_2022}
\citation{liu_establishment_2024}
\citation{chen2016xgboost}
\citation{gorishniy2021revisiting}
\citation{arik2021tabnet}
\citation{huang2020tabtransformer}
\citation{somepalli2021saint}
\citation{borisov2022deep}
\citation{gorishniy2021revisiting}
\citation{ardila_end--end_2019}
\citation{zech_variable_2018}
\citation{garau_external_2020}
\citation{hellin2024unraveling}
\citation{hollmann2025accurate}
\citation{schneider2024foundation}
\citation{noauthor_prior_nodate}
\citation{noauthor_realistic_nodate}
\citation{noauthor_automldrift-resilient_tabpfn_2025}
\citation{noauthor_closer_nodate}
\citation{noauthor_realistic_nodate}
\citation{eremeev_turning_2025}
\citation{guan2021domain}
\citation{musa2025addressing}
\citation{borisov2022deep}
\citation{koch2024distribution}
\citation{guo_evaluation_2022}
\citation{orouji_domain_nodate}
\citation{guan2021domain}
\citation{ahn_unsupervised_2023}
\citation{gardner_benchmarking_2024}
\citation{ahn_unsupervised_2023}
\citation{koch2024distribution}
\citation{schneider2024foundation}
\citation{noauthor_realistic_nodate}
\citation{noauthor_automldrift-resilient_tabpfn_2025}
\citation{noauthor_prior_nodate}
\citation{noauthor_automldrift-resilient_tabpfn_2025}
\citation{eremeev_turning_2025}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\newlabel{sec:intro-start}{{1}{3}{Introduction}{section.1}{}}
\citation{swensen1997chest}
\citation{mcwilliams2013probability}
\citation{li2011development}
\citation{he2021novel}
\citation{zhang_comprehensive_2022}
\citation{garau_external_2020}
\citation{liu_establishment_2024}
\citation{hellin2024unraveling}
\citation{ardila_end--end_2019}
\citation{zech_variable_2018}
\citation{gardner_benchmarking_2024}
\citation{gardner_benchmarking_2024}
\citation{koch2024distribution}
\citation{sun2019informative}
\citation{sun2019informative}
\citation{borisov2022deep}
\citation{chen2016xgboost}
\citation{gorishniy2021revisiting}
\citation{borisov2022deep}
\citation{hollmann2025accurate}
\citation{schneider2024foundation}
\citation{noauthor_realistic_nodate}
\citation{guan2021domain}
\citation{ahn_unsupervised_2023}
\citation{gardner_benchmarking_2024}
\citation{koch2024distribution}
\citation{guan2021domain}
\citation{musa2025addressing}
\citation{hollmann2025accurate}
\citation{schneider2024foundation}
\citation{sun2019informative}
\citation{pan2010domain}
\citation{gardner_benchmarking_2024}
\citation{koch2024distribution}
\citation{gardner_benchmarking_2024}
\citation{chen2016xgboost}
\citation{arik2021tabnet}
\citation{huang2020tabtransformer}
\citation{somepalli2021saint}
\citation{borisov2022deep}
\citation{schneider2024foundation}
\citation{guan2021domain}
\citation{ahn_unsupervised_2023}
\citation{bommasani2022opportunities}
\citation{schneider2024foundation}
\citation{chen2016xgboost}
\citation{grinsztajn_why_2022}
\citation{borisov2022deep}
\citation{gorishniy2021revisiting}
\citation{shmuel_comprehensive_2024}
\citation{fan_tabular_2024}
\citation{borisov_deep_2024}
\citation{liu_tabpfn_2025}
\citation{gorishniy2021revisiting}
\citation{fan_tabular_2024}
\citation{gardner_benchmarking_2024}
\newlabel{sec:intro-end}{{1}{5}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{5}{section.2}\protected@file@percent }
\newlabel{sec:rw-start}{{2}{5}{Related Work}{section.2}{}}
\newlabel{sec:related-work}{{2}{5}{Related Work}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Tabular learning for medical data: tree ensembles, deep tabular networks, and tabular foundation models}{5}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Tree ensembles for clinical tabular data}{5}{subsubsection.2.1.1}\protected@file@percent }
\citation{fan_tabular_2024}
\citation{gardner_benchmarking_2024}
\citation{guo_evaluation_2022}
\citation{koch2024distribution}
\citation{arik2021tabnet}
\citation{huang_tabtransformer_2020}
\citation{gorishniy_revisiting_2021}
\citation{somepalli2021saint}
\citation{margeloiu2023weight}
\citation{loh_basis_2025}
\citation{khoeini_fttransformer_2024}
\citation{bytezcom_tabicl_2025}
\citation{somvanshi2024survey}
\citation{fan_tabular_2024}
\citation{shmuel_comprehensive_2024}
\citation{ren_deep_2025}
\citation{gorishniy2021revisiting}
\citation{shmuel_comprehensive_2024}
\citation{fan_tabular_2024}
\citation{ren_deep_2025}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Deep tabular networks}{6}{subsubsection.2.1.2}\protected@file@percent }
\citation{fan_tabular_2024}
\citation{guo_evaluation_2022}
\citation{ren_deep_2025}
\citation{gorishniy2021revisiting}
\citation{guo_evaluation_2022}
\citation{ren_deep_2025}
\citation{hollmann2025accurate}
\citation{hollmann_accurate_2025}
\citation{noauthor_prior_nodate}
\citation{noauthor_closer_nodate}
\citation{noauthor_realistic_nodate}
\citation{helli_drift-resilient_2024}
\citation{noauthor_automldrift-resilient_tabpfn_2025}
\citation{chen_tabpfn_2025}
\citation{eremeev_turning_2025}
\citation{liu_tabular_2025}
\citation{brown2020language}
\citation{hegselmann2023tabllm}
\citation{jayawardhana_transformers_2025}
\citation{zhou_limitations_2025}
\citation{noauthor_pdf_nodate}
\citation{kolesnikov_wild-tab_2023}
\citation{liu_tabpfn_2025}
\citation{loh_basis_2025}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Tabular foundation models}{7}{subsubsection.2.1.3}\protected@file@percent }
\citation{koch2024distribution}
\citation{guo_evaluation_2022}
\citation{pan2010domain}
\citation{sun2016correlationalignmentunsuperviseddomain}
\citation{grubinger2015domain}
\citation{zhang_adadiag_2022}
\citation{li_transport-based_2024}
\citation{guo_evaluation_2022}
\citation{zhang_adadiag_2022}
\citation{guan2021domain}
\citation{pan2010domain}
\citation{gardner_benchmarking_2024}
\citation{koch2024distribution}
\citation{luo2021fsda}
\citation{grubinger2015domain}
\citation{pham_open-set_2025}
\citation{li_transport-based_2024}
\citation{guan2021domain}
\citation{guan_domainatm_2023}
\citation{guan_domain_2022}
\citation{zhou_domain_2023}
\citation{stokes_domain_2025}
\citation{ahn_unsupervised_2023}
\citation{he_multi-attention_2022}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparative strengths and weaknesses of tabular model families in medical AI.}}{8}{table.1}\protected@file@percent }
\newlabel{tab:model_summary}{{1}{8}{Comparative strengths and weaknesses of tabular model families in medical AI}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Domain shift and domain adaptation in medical AI}{8}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Statistical alignment vs. adversarial objectives}{8}{subsubsection.2.2.1}\protected@file@percent }
\citation{gardner_benchmarking_2024}
\citation{noauthor_mlfoundationstableshift_nodate}
\citation{gardner_tableshift_nodate}
\citation{kolesnikov_wild-tab_2023}
\citation{ahn_unsupervised_2023}
\citation{koch2024distribution}
\citation{fan_tabular_2024}
\citation{shmuel_comprehensive_2024}
\citation{somvanshi2024survey}
\citation{zhang_adadiag_2022}
\citation{guan2021domain}
\citation{noauthor_multi-center_nodate}
\citation{pan2010domain}
\citation{guo_evaluation_2022}
\citation{rehman_federated_2023}
\citation{guan_federated_2024}
\citation{kahenga_fedfusion_2025}
\citation{pan2010domain}
\citation{sun2016correlationalignmentunsuperviseddomain}
\citation{grubinger2015domain}
\citation{li_transport-based_2024}
\citation{gardner_benchmarking_2024}
\citation{koch2024distribution}
\citation{guo_evaluation_2022}
\citation{guo_evaluation_2022}
\citation{zhang_adadiag_2022}
\citation{zhang_adadiag_2022}
\citation{guan2021domain}
\citation{luo2021fsda}
\citation{guan2021domain}
\citation{guan_domainatm_2023}
\citation{guan_domain_2022}
\citation{gardner_benchmarking_2024}
\citation{gardner_tableshift_nodate}
\citation{kolesnikov_wild-tab_2023}
\citation{ahn_unsupervised_2023}
\citation{gardner_benchmarking_2024}
\citation{noauthor_mlfoundationstableshift_nodate}
\citation{rehman_federated_2023}
\citation{guan_federated_2024}
\citation{kahenga_fedfusion_2025}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Heterogeneity, missingness, and temporal drift}{9}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Domain generalization and open-set gaps}{9}{subsubsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Domain adaptation and transfer learning for clinical tabular and EHR data}{9}{subsubsection.2.2.4}\protected@file@percent }
\citation{guyon2002gene}
\citation{chen2023graces}
\citation{liu2022deepfs}
\citation{li2023deep}
\citation{chen2023graces}
\citation{liu2022deepfs}
\citation{li2023deep}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Representative domain-adaptation strategies in medical AI and their relevance to cross-hospital tabular risk prediction.}}{10}{table.2}\protected@file@percent }
\newlabel{tab:da_strategies}{{2}{10}{Representative domain-adaptation strategies in medical AI and their relevance to cross-hospital tabular risk prediction}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Feature selection and domain-aware stability for small medical cohorts}{10}{subsection.2.3}\protected@file@percent }
\citation{arik2021tabnet}
\citation{huang2020tabtransformer}
\citation{somepalli2021saint}
\citation{somvanshi2024survey}
\citation{luo2021fsda}
\citation{sun2019informative}
\citation{guyon2002gene}
\citation{tibshirani1996regression}
\citation{chen2023graces}
\citation{liu2022deepfs}
\citation{li2023deep}
\citation{luo2021fsda}
\citation{arik2021tabnet}
\citation{huang2020tabtransformer}
\citation{somvanshi2024survey}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Small-sample and high-dimensional feature selection}{11}{subsubsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Feature selection with transformers and foundation models}{11}{subsubsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Domain-aware and cross-site feature selection}{11}{subsubsection.2.3.3}\protected@file@percent }
\citation{swensen1997chest}
\citation{swensen1997archives}
\citation{mcwilliams2013probability}
\citation{li2011development}
\citation{he2021novel}
\citation{garau_external_2020}
\citation{zhang_comprehensive_2022}
\citation{liu_establishment_2024}
\citation{garau_external_2020}
\citation{zhang_comprehensive_2022}
\citation{chen_pulmonary_2025}
\citation{zhang_comprehensive_2022}
\citation{liu_establishment_2024}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Representative feature selection methods for small, imbalanced, high-dimensional biomedical tabular data.}}{12}{table.3}\protected@file@percent }
\newlabel{tab:fs_methods}{{3}{12}{Representative feature selection methods for small, imbalanced, high-dimensional biomedical tabular data}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Pulmonary nodule malignancy prediction: from clinical scores to multi-modal AI}{12}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Clinical risk scores and logistic models}{12}{subsubsection.2.4.1}\protected@file@percent }
\citation{yang_comparison_2018}
\citation{cui_comparison_2019}
\citation{li_evaluation_2020}
\citation{herder_clinical_2005}
\citation{yang_comparison_2018}
\citation{swensen1997chest}
\citation{swensen1997archives}
\citation{mcwilliams2013probability}
\citation{li2011development}
\citation{he2021novel}
\citation{liu_establishment_2024}
\citation{chen_pulmonary_2025}
\citation{garau_external_2020}
\citation{zhang_comprehensive_2022}
\citation{liu_establishment_2024}
\citation{chen_pulmonary_2025}
\citation{li2011development}
\citation{he2021novel}
\citation{liu_establishment_2024}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Representative pulmonary nodule malignancy scores and common external-validation issues.}}{13}{table.4}\protected@file@percent }
\newlabel{tab:nodule_scores}{{4}{13}{Representative pulmonary nodule malignancy scores and common external-validation issues}{table.4}{}}
\citation{hellin2024unraveling}
\citation{garau_external_2020}
\citation{ardila_end--end_2019}
\citation{zech_variable_2018}
\citation{koch2024distribution}
\citation{perandini_solid_2016}
\citation{garau_external_2020}
\citation{hellin2024unraveling}
\citation{garau_external_2020}
\citation{hellin2024unraveling}
\citation{hellin2024unraveling}
\citation{garau_external_2020}
\citation{hellin2024unraveling}
\citation{garau_external_2020}
\citation{hellin2024unraveling}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Radiomics pipelines with traditional machine learning}{14}{subsubsection.2.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Representative radiomics-based pulmonary nodule malignancy models and reported generalization behavior.}}{14}{table.5}\protected@file@percent }
\newlabel{tab:radiomics_models}{{5}{14}{Representative radiomics-based pulmonary nodule malignancy models and reported generalization behavior}{table.5}{}}
\citation{ardila_end--end_2019}
\citation{li_predicting_2019}
\citation{lin_combined_2024}
\citation{causey_highly_2018}
\citation{ardila_end--end_2019}
\citation{zech_variable_2018}
\citation{hellin2024unraveling}
\citation{koch2024distribution}
\citation{he2021novel}
\citation{garau_external_2020}
\citation{li_predicting_2019}
\citation{lin_combined_2024}
\citation{garau_external_2020}
\citation{hellin2024unraveling}
\citation{garau_external_2020}
\citation{hellin2024unraveling}
\citation{garau_external_2020}
\citation{hellin2024unraveling}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Deep-learning CAD systems}{15}{subsubsection.2.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.4}Tabular and multi-modal nodule models}{15}{subsubsection.2.4.4}\protected@file@percent }
\citation{gardner_benchmarking_2024}
\citation{gardner_tableshift_nodate}
\citation{kolesnikov_wild-tab_2023}
\citation{ahn_unsupervised_2023}
\citation{gardner_benchmarking_2024}
\citation{noauthor_mlfoundationstableshift_nodate}
\citation{ahn_unsupervised_2023}
\citation{koch2024distribution}
\citation{guo_evaluation_2022}
\citation{gardner_benchmarking_2024}
\citation{ahn_unsupervised_2023}
\citation{hellin2024unraveling}
\citation{koch2024distribution}
\citation{gardner_benchmarking_2024}
\citation{noauthor_mlfoundationstableshift_nodate}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Benchmarks and open problems for cross-domain tabular learning}{16}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Gap analysis and positioning of PANDA}{16}{subsubsection.2.5.1}\protected@file@percent }
\newlabel{sec:rw-end}{{2.5.1}{16}{Gap analysis and positioning of PANDA}{subsubsection.2.5.1}{}}
\gdef \LT@i {\LT@entry 
    {1}{122.8946pt}\LT@entry 
    {1}{233.78923pt}\LT@entry 
    {1}{78.53406pt}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Problem Formulation}{17}{section.3}\protected@file@percent }
\newlabel{sec:problem-formulation}{{3}{17}{Problem Formulation}{section.3}{}}
\newlabel{sec:pf-start}{{3}{17}{Problem Formulation}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Task definition and notation}{17}{subsection.3.1}\protected@file@percent }
\newlabel{subsec:notation}{{3.1}{17}{Task definition and notation}{subsection.3.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{Unified Mathematical Notation System}}{17}{table.6}\protected@file@percent }
\newlabel{tab:notation}{{6}{17}{Unified Mathematical Notation System}{table.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{Unified Mathematical Notation System}}{18}{table.6}\protected@file@percent }
\newlabel{tab:notation}{{6}{18}{Unified Mathematical Notation System}{table.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{Unified Mathematical Notation System}}{19}{table.6}\protected@file@percent }
\newlabel{tab:notation}{{6}{19}{Unified Mathematical Notation System}{table.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Prior-data fitted networks as tabular foundation models}{19}{subsection.3.2}\protected@file@percent }
\newlabel{subsec:pfn-generation}{{3.2}{19}{Prior-data fitted networks as tabular foundation models}{subsection.3.2}{}}
\citation{barros_pulmonary_2023}
\citation{yang_comparison_2018}
\citation{shipe_validation_2021}
\citation{lang_asymptomatic_2017}
\citation{ben2010theory}
\citation{ben2010theory}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Formalizing Domain Shift}{20}{subsection.3.3}\protected@file@percent }
\newlabel{subsec:domain-shift}{{3.3}{20}{Formalizing Domain Shift}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Covariate Shift: The Acquisition Gap}{20}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Label Shift: The Prevalence Gap}{20}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Concept Shift: The Definition Gap}{20}{subsubsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.4}Theoretical Bound on Generalization Error}{21}{subsubsection.3.3.4}\protected@file@percent }
\newlabel{eq:ben-david}{{5}{21}{Theoretical Bound on Generalization Error}{equation.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Theoretical Constraints of Existing Models}{21}{subsection.3.4}\protected@file@percent }
\newlabel{subsec:model-constraints}{{3.4}{21}{Theoretical Constraints of Existing Models}{subsection.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Gradient Boosted Decision Trees (GBDT)}{21}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Deep Tabular Models}{22}{subsubsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Transfer Component Analysis (TCA) Optimization Objective}{22}{subsection.3.5}\protected@file@percent }
\newlabel{subsec:tca-optimization}{{3.5}{22}{Transfer Component Analysis (TCA) Optimization Objective}{subsection.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}The PANDA Framework: A Unified Formalization}{22}{subsection.3.6}\protected@file@percent }
\newlabel{subsec:panda-formalization}{{3.6}{22}{The PANDA Framework: A Unified Formalization}{subsection.3.6}{}}
\newlabel{eq:panda-formalization}{{8}{22}{The PANDA Framework: A Unified Formalization}{equation.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1}Stage 1: Recursive Feature Elimination (RFE) with TabPFN}{23}{subsubsection.3.6.1}\protected@file@percent }
\newlabel{subsubsec:rfe-formalization}{{3.6.1}{23}{Stage 1: Recursive Feature Elimination (RFE) with TabPFN}{subsubsection.3.6.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2}Stage 2: Feature Alignment ($\pi _{\cap }$)}{23}{subsubsection.3.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.3}Stage 3: Domain Adaptation Mapping ($\psi $)}{23}{subsubsection.3.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.4}Stage 4: Classification and Ensemble ($h$)}{23}{subsubsection.3.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Clinical-Statistical Mapping}{24}{subsection.3.7}\protected@file@percent }
\newlabel{subsec:clinical-mapping}{{3.7}{24}{Clinical-Statistical Mapping}{subsection.3.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Mathematical Mapping of Clinical Problems to PANDA Components}}{24}{table.7}\protected@file@percent }
\newlabel{tab:clinical-mapping}{{7}{24}{Mathematical Mapping of Clinical Problems to PANDA Components}{table.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8}Problem Constraints and Research Scope}{24}{subsection.3.8}\protected@file@percent }
\newlabel{sec:problem-constraints}{{3.8}{24}{Problem Constraints and Research Scope}{subsection.3.8}{}}
\newlabel{subsec:constraints}{{3.8}{24}{Problem Constraints and Research Scope}{subsection.3.8}{}}
\newlabel{eq:small-sample-constraint}{{14}{24}{Problem Constraints and Research Scope}{equation.14}{}}
\newlabel{sec:pf-end}{{3.8}{24}{Problem Constraints and Research Scope}{equation.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Solution}{24}{section.4}\protected@file@percent }
\newlabel{sec:solution}{{4}{24}{Solution}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Architectural Overview}{25}{subsection.4.1}\protected@file@percent }
\newlabel{sec:solution-architecture}{{4.1}{25}{Architectural Overview}{subsection.4.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Data flow and transformations in the PANDA framework. The pipeline progressively refines raw, high-dimensional inputs into low-dimensional, domain-invariant embeddings and, ultimately, a calibrated probability. In the pulmonary nodule experiments, $k = 8$, $d_{\cap } = 8$, and $m = 15$, but these dimensions are dataset-dependent.}}{25}{table.8}\protected@file@percent }
\newlabel{tab:data-flow}{{8}{25}{Data flow and transformations in the PANDA framework. The pipeline progressively refines raw, high-dimensional inputs into low-dimensional, domain-invariant embeddings and, ultimately, a calibrated probability. In the pulmonary nodule experiments, $k = 8$, $d_{\cap } = 8$, and $m = 15$, but these dimensions are dataset-dependent}{table.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Mapping to the Formal Problem Formulation}{26}{subsection.4.2}\protected@file@percent }
\newlabel{sec:solution-mapping}{{4.2}{26}{Mapping to the Formal Problem Formulation}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Pointers to Implementation Details}{26}{subsection.4.3}\protected@file@percent }
\newlabel{sec:solution-pointers}{{4.3}{26}{Pointers to Implementation Details}{subsection.4.3}{}}
\newlabel{sec:sol-end}{{4.3}{26}{Pointers to Implementation Details}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Methods}{26}{section.5}\protected@file@percent }
\newlabel{sec:methods}{{5}{26}{Methods}{section.5}{}}
\newlabel{sec:meth-start}{{5}{26}{Methods}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Motivating Challenges and Methodological Response}{26}{subsection.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {PANDA framework architecture.} (a) Compositional pipeline from original tabular data through ensemble training, prediction aggregation, class-imbalance adjustment, and final classification output. (b) Multi-branch ensemble with $B=4$ preprocessing strategies, each generating $R=8$ ensemble members via different random seeds.}}{27}{figure.1}\protected@file@percent }
\newlabel{fig:model_details}{{1}{27}{\textbf {PANDA framework architecture.} (a) Compositional pipeline from original tabular data through ensemble training, prediction aggregation, class-imbalance adjustment, and final classification output. (b) Multi-branch ensemble with $\numpreprocessbranches =4$ preprocessing strategies, each generating $\numrandomseeds =8$ ensemble members via different random seeds}{figure.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Challenge--mechanism mapping in PANDA. Each component targets a known failure mode, and the same design is applied to pulmonary nodules and the TableShift BRFSS race-shift task.}}{28}{table.9}\protected@file@percent }
\newlabel{tab:challenge_mapping}{{9}{28}{Challenge--mechanism mapping in PANDA. Each component targets a known failure mode, and the same design is applied to pulmonary nodules and the TableShift BRFSS race-shift task}{table.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Feature Engineering and Selection Implementation}{28}{subsection.5.2}\protected@file@percent }
\newlabel{subsec:feature_engineering}{{5.2}{28}{Feature Engineering and Selection Implementation}{subsection.5.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Cross-Domain Recursive Feature Elimination (RFE)}{28}{subsubsection.5.2.1}\protected@file@percent }
\newlabel{sec:methods-rfe}{{5.2.1}{28}{Cross-Domain Recursive Feature Elimination (RFE)}{subsubsection.5.2.1}{}}
\newlabel{subsubsec:rfe_implementation}{{5.2.1}{28}{Cross-Domain Recursive Feature Elimination (RFE)}{subsubsection.5.2.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Cross-Domain Recursive Feature Elimination (RFE) with CEI Optimization}}{29}{algorithm.1}\protected@file@percent }
\newlabel{alg:cross_domain_rfe}{{1}{29}{Cross-Domain Recursive Feature Elimination (RFE)}{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Multi-Branch Preprocessing Strategy}{29}{subsubsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Foundation Model Integration Mechanism}{29}{subsection.5.3}\protected@file@percent }
\newlabel{sec:methods-tabpfn}{{5.3}{29}{Foundation Model Integration Mechanism}{subsection.5.3}{}}
\newlabel{subsec:foundation_model_integration}{{5.3}{29}{Foundation Model Integration Mechanism}{subsection.5.3}{}}
\citation{de2021adapt}
\citation{noauthor_welcome_nodate}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}In-Context Serialization and Tokenization}{30}{subsubsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Ensemble Construction and Inference}{30}{subsubsection.5.3.2}\protected@file@percent }
\newlabel{sec:methods-ensemble}{{5.3.2}{30}{Ensemble Construction and Inference}{subsubsection.5.3.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces PANDA Inference with TabPFN Backbone}}{30}{algorithm.2}\protected@file@percent }
\newlabel{alg:tabpfn_inference}{{2}{30}{Ensemble Construction and Inference}{algorithm.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Transfer Component Analysis (TCA)}{31}{subsubsection.5.3.3}\protected@file@percent }
\newlabel{sec:methods-tca}{{5.3.3}{31}{Transfer Component Analysis (TCA)}{subsubsection.5.3.3}{}}
\newlabel{subsubsec:tca_implementation}{{5.3.3}{31}{Transfer Component Analysis (TCA)}{subsubsection.5.3.3}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Transfer Component Analysis (TCA) Optimization}}{31}{algorithm.3}\protected@file@percent }
\newlabel{alg:tca_optimization}{{3}{31}{Transfer Component Analysis (TCA)}{algorithm.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Mathematical Formulation}{31}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Data Flow and Transformation}{31}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Hyperparameter Configuration and Kernel Choice}{32}{section*.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces TCA hyperparameter configuration in PANDA}}{32}{table.10}\protected@file@percent }
\newlabel{tab:tca_hyperparams}{{10}{32}{TCA hyperparameter configuration in PANDA}{table.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}Parameter Sensitivity Diagnostics}{32}{subsubsection.5.3.4}\protected@file@percent }
\newlabel{sec:param_sensitivity}{{5.3.4}{32}{Parameter Sensitivity Diagnostics}{subsubsection.5.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Experimental Configuration}{32}{subsection.5.4}\protected@file@percent }
\newlabel{subsec:experimental_config}{{5.4}{32}{Experimental Configuration}{subsection.5.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1}Baseline Hyperparameters}{32}{subsubsection.5.4.1}\protected@file@percent }
\citation{swensen1997chest}
\citation{li2011development}
\citation{he2021novel}
\citation{cortes1995support}
\citation{breiman1984classification}
\citation{breiman2001random}
\citation{friedman2001greedy}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Configuration for baseline models. Default parameters were used with basic settings for reproducibility and class imbalance handling.}}{33}{table.11}\protected@file@percent }
\newlabel{tab:hyperparams}{{11}{33}{Configuration for baseline models. Default parameters were used with basic settings for reproducibility and class imbalance handling}{table.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.2}Clinical Scoring Models}{33}{subsubsection.5.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.3}ML Baseline Models}{33}{subsubsection.5.4.3}\protected@file@percent }
\citation{chen2016xgboost}
\citation{gorishniy2021revisiting}
\citation{borisov2022deep}
\citation{ben2010theory}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.4}Computational Framework}{34}{subsubsection.5.4.4}\protected@file@percent }
\newlabel{sec:meth-end}{{5.4.4}{34}{Computational Framework}{subsubsection.5.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Analysis}{34}{section.6}\protected@file@percent }
\newlabel{sec:analysis}{{6}{34}{Analysis}{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Theoretical Foundation: The Generalization Bound}{34}{subsection.6.1}\protected@file@percent }
\newlabel{subsec:generalization_bound}{{6.1}{34}{Theoretical Foundation: The Generalization Bound}{subsection.6.1}{}}
\newlabel{eq:ben_david_bound}{{22}{35}{Ben-David et al., 2010}{equation.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}The $\mathcal  {H}\Delta \mathcal  {H}$-Divergence}{35}{subsubsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Minimizing Source Risk $\epsilon _S(h)$: The TabPFN Mechanism}{35}{subsection.6.2}\protected@file@percent }
\newlabel{subsec:analysis_source_risk}{{6.2}{35}{Minimizing Source Risk $\sourceerror $: The TabPFN Mechanism}{subsection.6.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Prior-Data Fitted Networks vs. Parametric Learning}{35}{subsubsection.6.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Minimizing Divergence $d_{\mathcal  {H}\Delta \mathcal  {H}}$: Latent Space TCA}{36}{subsection.6.3}\protected@file@percent }
\newlabel{subsec:analysis_divergence}{{6.3}{36}{Minimizing Divergence $\domaindivergence $: Latent Space TCA}{subsection.6.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1}Why Feature Space Alignment?}{36}{subsubsection.6.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.2}The TCA Optimization Objective}{36}{subsubsection.6.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Minimizing Adaptability Error $\lambda $: Cross-Domain RFE}{36}{subsection.6.4}\protected@file@percent }
\newlabel{subsec:analysis_adaptability}{{6.4}{36}{Minimizing Adaptability Error $\adaptabilityterm $: Cross-Domain RFE}{subsection.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Synthesis: Linking Theory to Empirical Results}{36}{subsection.6.5}\protected@file@percent }
\newlabel{subsec:analysis_synthesis}{{6.5}{36}{Synthesis: Linking Theory to Empirical Results}{subsection.6.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces Mapping theoretical error terms to PANDA components and empirical results.}}{36}{table.12}\protected@file@percent }
\newlabel{tab:theory_empirics}{{12}{36}{Mapping theoretical error terms to PANDA components and empirical results}{table.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Summary of Theoretical Insights}{37}{subsection.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Evaluation}{37}{section.7}\protected@file@percent }
\newlabel{sec:eval-start}{{7}{37}{Evaluation}{section.7}{}}
\newlabel{sec:evaluation}{{7}{37}{Evaluation}{section.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Evaluation Protocols for Cross-Domain Diagnostic Models}{37}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}Classification Performance Metrics}{37}{subsubsection.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}Visualization-Based Evaluation}{37}{subsubsection.7.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Experiment 1 (E1): Cross-Hospital Pulmonary Nodule Malignancy Prediction}{38}{subsection.7.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces Training (Cohort A) and testing (Cohort B) cohorts.}}{38}{table.13}\protected@file@percent }
\newlabel{tab:cohort_summary}{{13}{38}{Training (Cohort A) and testing (Cohort B) cohorts}{table.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}E1: Internal and Cross-Hospital Generalization}{39}{subsection.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.1}Source and Target Domain Performance}{39}{subsubsection.7.3.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces Comprehensive performance comparison. Source results are from 10-fold cross-validation; target results are from external validation on Cohort B. Best values are bolded.}}{39}{table.14}\protected@file@percent }
\newlabel{tab:main_results_table}{{14}{39}{Comprehensive performance comparison. Source results are from 10-fold cross-validation; target results are from external validation on Cohort B. Best values are bolded}{table.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Performance comparison across domains.} \textbf  {a} Source-domain 10-fold cross-validation heatmap over five metrics, showing PANDA’s leading performance in AUC, accuracy, and precision. \textbf  {b} Cross-domain external validation heatmap; the TCA-enhanced PANDA model maintains the highest AUC and recall, highlighting its stability under domain shift.}}{40}{figure.2}\protected@file@percent }
\newlabel{fig:performance-heatmaps}{{2}{40}{\textbf {Performance comparison across domains.} \textbf {a} Source-domain 10-fold cross-validation heatmap over five metrics, showing PANDA’s leading performance in AUC, accuracy, and precision. \textbf {b} Cross-domain external validation heatmap; the TCA-enhanced PANDA model maintains the highest AUC and recall, highlighting its stability under domain shift}{figure.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.2}Stratified Analysis}{41}{subsubsection.7.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {15}{\ignorespaces Stratified performance of PANDA+TCA on the target cohort.}}{41}{table.15}\protected@file@percent }
\newlabel{tab:stratified_analysis}{{15}{41}{Stratified performance of PANDA+TCA on the target cohort}{table.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Experiment 2 (E2): Cross-Population Validation on TableShift}{41}{subsection.7.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Performance comparison on the TableShift BRFSS Diabetes benchmark.} Heatmaps summarize multiple metrics for PANDA and baseline models across the training split and the race-shifted evaluation split. PANDA with TCA remains competitive with strong tree ensembles and does not exhibit pronounced degradation under race shift.}}{42}{figure.3}\protected@file@percent }
\newlabel{fig:tableshift-heatmaps}{{3}{42}{\textbf {Performance comparison on the TableShift BRFSS Diabetes benchmark.} Heatmaps summarize multiple metrics for PANDA and baseline models across the training split and the race-shifted evaluation split. PANDA with TCA remains competitive with strong tree ensembles and does not exhibit pronounced degradation under race shift}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {TableShift BRFSS Diabetes analysis.} \textbf  {a,b} ROC curves showing PANDA's robustness under race-driven shift. \textbf  {c,d} Calibration curves assessing probability estimates. \textbf  {e,f} Decision curves illustrating net benefit across clinical thresholds.}}{43}{figure.4}\protected@file@percent }
\newlabel{fig:brfss-roc}{{4}{43}{\textbf {TableShift BRFSS Diabetes analysis.} \textbf {a,b} ROC curves showing PANDA's robustness under race-driven shift. \textbf {c,d} Calibration curves assessing probability estimates. \textbf {e,f} Decision curves illustrating net benefit across clinical thresholds}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Interpretability and Stability}{44}{subsection.7.5}\protected@file@percent }
\newlabel{sec:eval-end}{{7.5}{44}{Interpretability and Stability}{figure.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{44}{section.8}\protected@file@percent }
\newlabel{sec:concl-start}{{8}{44}{Conclusion}{section.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Summary of Contributions}{44}{subsection.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Limitations}{44}{subsection.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.1}Closed-World Assumption}{44}{subsubsection.8.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.2}Missing Data Mechanisms}{44}{subsubsection.8.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Comprehensive feature selection and performance analysis using recursive feature elimination (RFE).} (a) AUC, accuracy, and F1 curves as functions of the number of selected features; performance plateaus around 9--13 features, aligning with the preference for simpler models. Shaded regions show variance across 10-fold cross-validation. (b) Class-specific accuracy for malignant and benign cases across subset sizes, illustrating how predictive balance shifts as features are removed. (c) Training-time analysis (seconds per fold) as a function of feature dimensionality, highlighting the computational gain from smaller subsets. (d) Stability assessment using the coefficient of variation across folds; lower values indicate steadier performance. (e) Cost-effectiveness index combining multiple criteria (Performance$\times $0.45 + Simplicity$\times $0.25 + Efficiency$\times $0.15 + Stability$\times $0.15) to identify a feature count that balances accuracy with practical deployment considerations.}}{45}{figure.5}\protected@file@percent }
\newlabel{fig:rfe-performance}{{5}{45}{\textbf {Comprehensive feature selection and performance analysis using recursive feature elimination (RFE).} (a) AUC, accuracy, and F1 curves as functions of the number of selected features; performance plateaus around 9--13 features, aligning with the preference for simpler models. Shaded regions show variance across 10-fold cross-validation. (b) Class-specific accuracy for malignant and benign cases across subset sizes, illustrating how predictive balance shifts as features are removed. (c) Training-time analysis (seconds per fold) as a function of feature dimensionality, highlighting the computational gain from smaller subsets. (d) Stability assessment using the coefficient of variation across folds; lower values indicate steadier performance. (e) Cost-effectiveness index combining multiple criteria (Performance$\times $0.45 + Simplicity$\times $0.25 + Efficiency$\times $0.15 + Stability$\times $0.15) to identify a feature count that balances accuracy with practical deployment considerations}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Performance and utility across source and target domains.} \textbf  {a,b} ROC curves comparing source (Cohort A) and external (Cohort B) behavior. \textbf  {c,d} Calibration plots for the same splits. \textbf  {e,f} Decision curves illustrating the net clinical benefit of PANDA and its TCA extension.}}{46}{figure.6}\protected@file@percent }
\newlabel{fig:combined_analysis}{{6}{46}{\textbf {Performance and utility across source and target domains.} \textbf {a,b} ROC curves comparing source (Cohort A) and external (Cohort B) behavior. \textbf {c,d} Calibration plots for the same splits. \textbf {e,f} Decision curves illustrating the net clinical benefit of PANDA and its TCA extension}{figure.6}{}}
\bibstyle{unsrt}
\bibdata{refs}
\bibcite{swensen1997chest}{1}
\bibcite{mcwilliams2013probability}{2}
\bibcite{li2011development}{3}
\bibcite{he2021novel}{4}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.3}Computational Resource Requirements}{47}{subsubsection.8.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Future Directions}{47}{subsection.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.3.1}Federated Domain Adaptation}{47}{subsubsection.8.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.3.2}Multimodal Integration}{47}{subsubsection.8.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}Final Remarks}{47}{subsection.8.4}\protected@file@percent }
\newlabel{sec:concl-end}{{8.4}{47}{Final Remarks}{subsection.8.4}{}}
\newlabel{sec:ack-start}{{8.4}{47}{Acknowledgements}{section*.4}{}}
\newlabel{sec:ack-end}{{8.4}{47}{Acknowledgements}{section*.4}{}}
\bibcite{zhang_comprehensive_2022}{5}
\bibcite{liu_establishment_2024}{6}
\bibcite{garau_external_2020}{7}
\bibcite{chen2016xgboost}{8}
\bibcite{gorishniy2021revisiting}{9}
\bibcite{arik2021tabnet}{10}
\bibcite{huang2020tabtransformer}{11}
\bibcite{somepalli2021saint}{12}
\bibcite{borisov2022deep}{13}
\bibcite{ardila_end--end_2019}{14}
\bibcite{zech_variable_2018}{15}
\bibcite{hellin2024unraveling}{16}
\bibcite{hollmann2025accurate}{17}
\bibcite{schneider2024foundation}{18}
\bibcite{noauthor_prior_nodate}{19}
\bibcite{noauthor_realistic_nodate}{20}
\bibcite{noauthor_automldrift-resilient_tabpfn_2025}{21}
\bibcite{noauthor_closer_nodate}{22}
\bibcite{eremeev_turning_2025}{23}
\bibcite{guan2021domain}{24}
\bibcite{musa2025addressing}{25}
\bibcite{koch2024distribution}{26}
\bibcite{guo_evaluation_2022}{27}
\bibcite{orouji_domain_nodate}{28}
\bibcite{ahn_unsupervised_2023}{29}
\bibcite{gardner_benchmarking_2024}{30}
\bibcite{sun2019informative}{31}
\bibcite{pan2010domain}{32}
\bibcite{bommasani2022opportunities}{33}
\bibcite{grinsztajn_why_2022}{34}
\bibcite{shmuel_comprehensive_2024}{35}
\bibcite{fan_tabular_2024}{36}
\bibcite{borisov_deep_2024}{37}
\bibcite{liu_tabpfn_2025}{38}
\bibcite{huang_tabtransformer_2020}{39}
\bibcite{gorishniy_revisiting_2021}{40}
\bibcite{margeloiu2023weight}{41}
\bibcite{loh_basis_2025}{42}
\bibcite{khoeini_fttransformer_2024}{43}
\bibcite{bytezcom_tabicl_2025}{44}
\bibcite{somvanshi2024survey}{45}
\bibcite{ren_deep_2025}{46}
\bibcite{hollmann_accurate_2025}{47}
\bibcite{helli_drift-resilient_2024}{48}
\bibcite{chen_tabpfn_2025}{49}
\bibcite{liu_tabular_2025}{50}
\bibcite{brown2020language}{51}
\bibcite{hegselmann2023tabllm}{52}
\bibcite{jayawardhana_transformers_2025}{53}
\bibcite{zhou_limitations_2025}{54}
\bibcite{noauthor_pdf_nodate}{55}
\bibcite{kolesnikov_wild-tab_2023}{56}
\bibcite{sun2016correlationalignmentunsuperviseddomain}{57}
\bibcite{grubinger2015domain}{58}
\bibcite{zhang_adadiag_2022}{59}
\bibcite{li_transport-based_2024}{60}
\bibcite{luo2021fsda}{61}
\bibcite{pham_open-set_2025}{62}
\bibcite{guan_domainatm_2023}{63}
\bibcite{guan_domain_2022}{64}
\bibcite{zhou_domain_2023}{65}
\bibcite{stokes_domain_2025}{66}
\bibcite{he_multi-attention_2022}{67}
\bibcite{noauthor_mlfoundationstableshift_nodate}{68}
\bibcite{gardner_tableshift_nodate}{69}
\bibcite{noauthor_multi-center_nodate}{70}
\bibcite{rehman_federated_2023}{71}
\bibcite{guan_federated_2024}{72}
\bibcite{kahenga_fedfusion_2025}{73}
\bibcite{guyon2002gene}{74}
\bibcite{chen2023graces}{75}
\bibcite{liu2022deepfs}{76}
\bibcite{li2023deep}{77}
\bibcite{tibshirani1996regression}{78}
\bibcite{swensen1997archives}{79}
\bibcite{chen_pulmonary_2025}{80}
\bibcite{yang_comparison_2018}{81}
\bibcite{cui_comparison_2019}{82}
\bibcite{li_evaluation_2020}{83}
\bibcite{herder_clinical_2005}{84}
\bibcite{perandini_solid_2016}{85}
\bibcite{li_predicting_2019}{86}
\bibcite{lin_combined_2024}{87}
\bibcite{causey_highly_2018}{88}
\bibcite{ben2010theory}{89}
\bibcite{de2021adapt}{90}
\bibcite{noauthor_welcome_nodate}{91}
\bibcite{cortes1995support}{92}
\bibcite{breiman1984classification}{93}
\bibcite{breiman2001random}{94}
\bibcite{friedman2001greedy}{95}
\gdef \@abspage@last{53}
