\section{Methods}
\label{sec:methods}
\label{sec:meth-start}

\subsection{Motivating Challenges and Methodological Response}
Cross-hospital malignancy prediction and public health surveillance pose intertwined constraints, including small labeled cohorts, label imbalance, feature mismatch, and multiple forms of distribution shift. PANDA is structured to address these constraints rather than to introduce architectural novelty. In this section, we explicitly link each methodological component to the specific failure mode it is designed to mitigate. Table~\ref{tab:challenge_mapping} summarizes the main obstacles and the mechanisms assigned to each of them.

\begin{table}[htbp]
  \centering
  \caption{Challenge--mechanism mapping in PANDA. Each component targets a known failure mode, and the same design is applied to pulmonary nodules and the TableShift BRFSS race-shift task.}
  \label{tab:challenge_mapping}
  \begin{tabular}{p{0.22\textwidth}p{0.32\textwidth}p{0.33\textwidth}}
    \toprule
    Challenge & Mechanism & Expected benefit \\ \midrule
    Small $\sourcedatasize$ with high-dimensional covariates & TabPFN prior-data-fitted network that performs in-context learning with frozen weights & Transfers structural priors from millions of synthetic tasks and reduces estimation variance without local fine-tuning \\ 
    Feature heterogeneity across institutions/demographics & Cross-domain RFE identifies stable subsets (``best8'') that are definable at every site, together with schema-alignment utilities & Removes site-specific artifacts before adaptation and ensures that downstream models operate only on shared attributes \\ 
    Covariate shift and mixed acquisition protocols & TCA applied to RFE-selected features realigns marginal distributions before the TabPFN classifier & Reduces the $\domaindivergence$ divergence so that context examples remain relevant to target queries \\ 
    Label prevalence drift and class imbalance & Class-balanced sampling, calibrated decision thresholds, and ensemble temperature scaling & Maintains sensitivity for malignant/SPN-positive cohorts and accounts for higher diabetes rates in non-White BRFSS respondents \\ 
    Variance from preprocessing choices & Multi-branch preprocessing (ordering, quantile transforms, ordinal encoding) with ensemble averaging & Introduces diversity without retraining new weights and stabilizes predictions under minor data perturbations \\ \bottomrule
  \end{tabular}
\end{table}

This architecture is explicitly designed so that each component addresses a specific question: why do small-sample medical deployments fail, and which prior or alignment mechanism mitigates that failure? Specifically, the TabPFN backbone addresses the small-sample, high-dimensional regime; cross-domain RFE addresses feature mismatch and feature heterogeneity across institutions; the TCA module addresses covariate shift and mixed acquisition protocols; the calibration and sampling utilities address label prevalence drift and class imbalance; and the multi-branch preprocessing ensemble addresses instability arising from preprocessing choices.

\subsection{Feature Engineering and Selection Implementation}
\label{subsec:feature_engineering}

The feature engineering pipeline in PANDA is designed to accommodate the heterogeneity of medical data sources while preserving domain-invariant signals. This component directly targets the feature mismatch and feature heterogeneity challenges by enforcing that downstream models operate only on features that are consistently available and stable across hospitals. It comprises two stages: global feature selection via Cross-Domain RFE and local feature transformation via TabPFN's internal preprocessing branches.

\subsubsection{Cross-Domain Recursive Feature Elimination (RFE)}
\label{subsubsec:rfe_implementation}
To address the \emph{feature mismatch} challenge, we implement a Cross-Domain Recursive Feature Elimination (RFE) strategy. Unlike standard RFE, which optimizes for a single dataset, this approach seeks a feature subset $\rfeselectedfeatures$ that maximizes predictive performance on the source domain $\sourcedomaindist$ while satisfying availability constraints in the target domain $\targetdomaindist$.

The process uses a wrapper around the TabPFN classifier to compute permutation importance. We define the importance of feature $j$ as the degradation in \auc when its values are randomly shuffled:
\begin{equation}
    \rfeimportance_j = \lossauc(\mathcal{D}_{\text{val}}) - \frac{1}{\numfolds} \sum_{k=1}^{\numfolds} \lossauc(\mathcal{D}_{\text{val}}^{(j, \text{shuffled})})
\end{equation}
where $\numfolds=5$ repeats. Algorithm~\ref{alg:cross_domain_rfe} details the iterative elimination process.

\begin{algorithm}[H]
\caption{Cross-Domain Recursive Feature Elimination (RFE) with CEI Optimization}
\label{alg:cross_domain_rfe}
\begin{algorithmic}[1]
\REQUIRE Source Data $\sourcedatafeatures, \sourcedatalabels$, Target Feature Count Range $[k_{\min}, k_{\max}]$
\ENSURE Optimal Feature Subset $\rfeselectedfeatures$
\STATE \textbf{Initialize TabPFN Wrapper} with permutation importance computation
\STATE \textbf{Initialize performance records:} $\mathcal{M} \leftarrow \emptyset$
\FOR{$k = k_{\max}$ \TO $k_{\min}$}
    \STATE \textbf{Configure sklearn RFE:} estimator=TabPFNWrapper, $n\_features\_to\_select = k$, step=1
    \STATE \textbf{Fit RFE:} $(\rfeset_k, \text{ranking}_k) \leftarrow \text{RFE.fit}(\sourcedatafeatures, \sourcedatalabels)$
    \STATE \textbf{Evaluate performance:} $\metrick(k) = \text{CV-AUC}(\rfeset_k)$ using $\numfolds$-fold CV
    \STATE \textbf{Compute CEI components:}
    \STATE \quad $\rfeperformance(k) = \metrick(k)$ \COMMENT{Performance score}
    \STATE \quad $\rfeefficiency(k) = 1 - \frac{\text{Cost}(\rfeset_k)}{\text{Cost}(\text{all features})}$ \COMMENT{Cost efficiency}
    \STATE \quad $\rfestability(k) = 1 - \text{Std}(\text{AUC across CV folds})$ \COMMENT{Stability score}
    \STATE \quad $\rfesimplicity(k) = \exp(-\sparsityparam \cdot k)$ \COMMENT{Sparsity penalty}
    \STATE \textbf{Compute CEI:} $\text{CEI}(k) = \rfecomponentweights_1 \rfeperformance(k) + \rfecomponentweights_2 \rfeefficiency(k) + \rfecomponentweights_3 \rfestability(k) + \rfecomponentweights_4 \rfesimplicity(k)$
    \STATE $\mathcal{M} \leftarrow \mathcal{M} \cup \{(k, \rfeset_k, \text{CEI}(k))\}$
\ENDFOR
\STATE \textbf{Select optimal subset:} $\rfecurrentdim^* = \argmax_k \text{CEI}(k)$
\STATE $\rfeselectedfeatures \leftarrow \rfeset_{\rfecurrentdim^*}$
\RETURN $\rfeselectedfeatures$
\end{algorithmic}
\end{algorithm}

This algorithm yields the standard feature subsets referenced throughout the study (for example, ``best8'').

\subsubsection{Multi-Branch Preprocessing Strategy}
Once the feature set is fixed, PANDA leverages TabPFN's internal ensemble mechanism to handle distribution shifts in feature scaling and encoding. This step primarily addresses the variance introduced by different preprocessing choices and minor covariate shifts in the marginal feature distributions. This mechanism can be viewed as a form of test-time augmentation for tabular data. The ensemble generation mechanism produces 32 distinct views of the data through four preprocessing pipelines:
\begin{enumerate}
    \item \textbf{No-Op Branch:} Raw features are passed directly, preserving their original distributions, which is useful for tree-like decision logic.
    \item \textbf{Quantile Branch:} Features are transformed via $F^{-1}(\Phi(\featurevec))$, mapping the empirical CDF to a standard Normal $\mathcal{N}(0,1)$. This transformation mitigates extreme outliers and skewed distributions common in medical markers (for example, CEA levels).
    \item \textbf{Ordinal Branch:} All unique values are ranked and replaced by their integer rank. This transformation removes magnitude information but preserves order, making the model robust to unit changes (for example, centimetres vs millimetres).
    \item \textbf{Power Transform Branch:} Applies $\featurevec \mapsto \featurevec^\powertransformparam$ (for example, square root or logarithm) to stabilize variance.
\end{enumerate}
Each branch is applied to both support (train) and query (test) sets simultaneously, ensuring a consistent mapping.

\subsection{Foundation Model Integration Mechanism}
\label{subsec:foundation_model_integration}

PANDA employs TabPFN as a probabilistic classifier within an integrated framework. This module directly addresses the challenge of training in small, high-dimensional clinical cohorts by reusing structural priors learned from synthetic tasks and producing calibrated probability estimates that can subsequently be adjusted for label imbalance. While TabPFN internally processes features, its role in PANDA is to produce calibrated predictions on adapted tabular data. The integration involves specific in-context serialization and ensemble construction steps.

\subsubsection{In-Context Serialization and Tokenization}
Unlike BERT-style models, which require textual input, TabPFN operates directly on raw numerical and categorical values. The serialization mechanism maps a heterogeneous row $\featurevec \in \mathbb{R}^{d_{\text{num}}} \times \mathbb{Z}^{d_{\text{cat}}}$ into a sequence of continuous embeddings.

For a numerical feature $\featurevec^{(j)}$, the embedding is a linear projection:
\begin{equation}
    \numfeatureembed = \numweightmat \featurevec^{(j)} + \numbiasvec
\end{equation}
For a categorical feature with index $\catindex$, we use a lookup table:
\begin{equation}
    \numfeatureembed = \catelembedmat[\catindex]
\end{equation}
Missing values are handled by a specialized learnable token $\nanembed$. The full sample embedding is the sum of feature embeddings plus a positional encoding:
\begin{equation}
    \samplesembed = \mlp(\concat(\mathbf{e}^{(1)}, \dots, \mathbf{e}^{(\featuredim)})) + \posencoding
\end{equation}
This representation allows the Transformer to attend to distinct patients within the context window.

\subsubsection{Ensemble Construction and Inference}
The final prediction is obtained by averaging over 32 diverse forward passes. Let $\preprocessingbranches = \{P_1, \dots, P_4\}$ denote the set of preprocessing functions and $\randomseeds = \{s_1, \dots, s_8\}$ a set of random seeds that control the subsampling of the context set (the \emph{support set} of labeled examples). The ensemble probability estimate is
\begin{equation}
    \ensembleprob = \frac{1}{32} \sum_{P \in \preprocessingbranches} \sum_{s \in \randomseeds} \activation\left( \frac{\transformerbackbone(P(\querypatient) \mid P(\contextdata))}{\temperature} \right)
\end{equation}
where
\begin{itemize}
    \item $\querypatient$ is the target query (patient),
    \item $\contextdata$ is the subset of training data selected by seed $s$,
    \item $\transformerbackbone$ is the frozen TabPFN Transformer backbone, and
    \item $\temperature=0.9$ is the temperature scaling parameter calibrated for small-sample confidence.
\end{itemize}

Algorithm~\ref{alg:tabpfn_inference} summarizes the inference procedure.

\begin{algorithm}[H]
\caption{PANDA Inference with TabPFN Backbone}
\label{alg:tabpfn_inference}
\begin{algorithmic}[1]
\REQUIRE Query $\querypatient$, Context $\mathcal{D}_{\text{train}}$, Ensemble $N=32$
\ENSURE Malignancy probability $\hat{\labelval}$
\STATE $\text{Logits} \leftarrow []$
\FOR{$i=1$ \TO $N$}
    \STATE Sample preprocessing $P \sim \preprocessingbranches$ and context subset $\mathcal{D}_i \subset \mathcal{D}_{\text{train}}$
    \STATE $\mathbf{x}'_q, \mathcal{D}'_i \leftarrow P(\querypatient), P(\mathcal{D}_i)$ \COMMENT{Apply branch}
    \STATE $\mathbf{E} \leftarrow \text{Serialize}(\mathbf{x}'_q, \mathcal{D}'_i)$ \COMMENT{Tokenize}
    \STATE $\mathbf{z} \leftarrow \text{Transformer}(\mathbf{E})$ \COMMENT{Forward pass}
    \STATE $\ceilogit \leftarrow \text{ClassifierHead}(\mathbf{z})$
    \STATE $\text{Logits}.\text{append}(\ceilogit)$
\ENDFOR
\STATE $\hat{\labelval} \leftarrow \text{Softmax}(\text{Mean}(\text{Logits}) / \temperature)$
\RETURN $\hat{\labelval}$
\end{algorithmic}
\end{algorithm}

\subsubsection{Transfer Component Analysis (TCA)}
\label{subsubsec:tca_implementation}

TCA is applied to the RFE-selected feature space to align the marginal distributions of the source and target domains. This module directly targets the covariate shift and mixed acquisition-protocol challenges highlighted in Table~\ref{tab:challenge_mapping} by enforcing a shared latent representation across hospitals. We implement this alignment via Transfer Component Analysis (TCA), which solves the optimization problem through a generalized eigenvalue decomposition \cite{de2021adapt, noauthor_welcome_nodate}. Algorithm \ref{alg:tca_optimization} outlines the computational procedure.

\begin{algorithm}[H]
\caption{Transfer Component Analysis (TCA) Optimization}
\label{alg:tca_optimization}
\begin{algorithmic}[1]
\REQUIRE Source Features $\sourcedatafeatures$, Target Features $\targetfeatureschema$, Kernel $k(\cdot, \cdot)$, Dim $\tcaprojectdim$, Reg $\regularizationparam$
\ENSURE Projection Matrix $\tcaprojectionmatrix$
\STATE \textbf{Construct Kernel Matrix:}
\STATE Compute blocks $\kernelmatrix_{SS}, \kernelmatrix_{ST}, \kernelmatrix_{TT}$ using $k(\cdot, \cdot)$
\STATE $\kernelmatrix \leftarrow \begin{bmatrix} \kernelmatrix_{SS} & \kernelmatrix_{ST} \\ \kernelmatrix_{ST}^\top & \kernelmatrix_{TT} \end{bmatrix}$
\STATE \textbf{Construct MMD Matrix $\mmdmatrix$:}
\STATE $\mmdmatrix_{ij} \leftarrow \frac{1}{\sourcedatasize^2}$ if $x_i, x_j \in \sourcedata$; $\frac{1}{\targetdatasize^2}$ if $x_i, x_j \in \targetdata$; else $\frac{-1}{\sourcedatasize \targetdatasize}$
\STATE \textbf{Construct Centering Matrix $\centeringmatrix$:}
\STATE $\centeringmatrix \leftarrow \identitymatrix - \frac{1}{\sourcedatasize+\targetdatasize}\onesvec\onesvec^\top$
\STATE \textbf{Solve Generalized Eigenproblem:}
\STATE $\mathbf{A} \leftarrow \identitymatrix + \regularizationparam \kernelmatrix \mmdmatrix \kernelmatrix$
\STATE $\mathbf{B} \leftarrow \kernelmatrix \centeringmatrix \kernelmatrix$
\STATE Compute eigenvectors $\mathbf{V}$ of $\mathbf{A}^{-1}\mathbf{B}$
\STATE $\tcaprojectionmatrix \leftarrow \text{SelectTop}(\mathbf{V}, \tcaprojectdim)$ \COMMENT{Top $m$ eigenvectors}
\RETURN $\tcaprojectionmatrix$
\end{algorithmic}
\end{algorithm}

\paragraph{Mathematical Formulation}
The core optimization problem seeks a projection matrix $\tcaprojectionmatrix \in \mathbb{R}^{(\sourcedatasize+\targetdatasize) \times \tcaprojectdim}$ that maps the kernel matrix $\kernelmatrix$ to a low-dimensional latent space. The objective is to minimize the Maximum Mean Discrepancy (MMD) between domains while preserving data variance.

The kernel matrix $\kernelmatrix \in \mathbb{R}^{(\sourcedatasize+\targetdatasize) \times (\sourcedatasize+\targetdatasize)}$ is constructed as a block matrix:
\begin{equation}
    \kernelmatrix = \begin{bmatrix} \kernelmatrix_{SS} & \kernelmatrix_{ST} \\ \kernelmatrix_{TS} & \kernelmatrix_{TT} \end{bmatrix}
\end{equation}
where $\kernelmatrix_{SS}, \kernelmatrix_{TT}, \kernelmatrix_{ST}$ represent the kernel evaluations within the source domain, within the target domain, and between source and target samples, respectively.

The MMD matrix $\mmdmatrix$ and centering matrix $\centeringmatrix$ are defined as
\begin{equation}
    \mmdmatrix_{ij} = \begin{cases} \frac{1}{\sourcedatasize^2} & x_i, x_j \in \sourcedata \\ \frac{1}{\targetdatasize^2} & x_i, x_j \in \targetdata \\ -\frac{1}{\sourcedatasize \targetdatasize} & \text{otherwise} \end{cases}, \quad
    \centeringmatrix = \identitymatrix - \frac{1}{\sourcedatasize+\targetdatasize}\onesvec\onesvec^\top
\end{equation}

The ADAPT implementation solves for the projection $\tcaprojectionmatrix$ by addressing a generalized eigenvalue problem. Specifically, it computes
\begin{equation}
    \mathbf{A} = \identitymatrix + \regularizationparam \kernelmatrix \mmdmatrix \kernelmatrix, \quad \mathbf{B} = \kernelmatrix \centeringmatrix \kernelmatrix
\end{equation}
and solves for the eigenvectors of $\mathbf{A}^{-1} \mathbf{B}$. The optimal projection matrix $\tcaprojectionmatrix$ consists of the $\tcaprojectdim$ eigenvectors corresponding to the largest eigenvalues of $\mathbf{A}^{-1}\mathbf{B}$, which we denote as $\tcaprojectionmatrix = \texttt{vectors\_}[:\tcaprojectdim]$. This formulation maximizes the ratio of data variance ($\operatorname{tr}(\tcaprojectionmatrix^\top \mathbf{B} \tcaprojectionmatrix)$) to the regularized domain divergence ($\operatorname{tr}(\tcaprojectionmatrix^\top \mathbf{A} \tcaprojectionmatrix)$). The top $\tcaprojectdim$ eigenvectors form the projection matrix $\tcaprojectionmatrix$.

\paragraph{Data Flow and Transformation}
In the \texttt{fit\_transform} phase, we utilize the \textbf{RFE-selected feature vectors} as the input representations for both the source ($\sourcedatafeatures$) and target ($\targetfeatureschema$) domains. These feature matrices are concatenated to compute the kernel matrix. The solver then computes $\tcaprojectionmatrix$ using the top $\tcaprojectdim$ eigenvectors (`vectors\_`) of the matrix product. For a new query sample $\queryvec$, the transformation projects it into the shared subspace by computing the inner product of the query's kernel vector with these eigenvectors:
\begin{equation}
    \mathbf{z}_{\text{new}} = \mathbf{k}_{\text{new}}^\top \tcaprojectionmatrix
\end{equation}
where $\mathbf{k}_{\text{new}} = [k(\queryvec, x_1), \dots, k(\queryvec, x_{n+m})]^\top$ is the kernel vector between the query and all training samples, and $\tcaprojectionmatrix$ contains the learned alignment directions. This mapping allows the model to embed unseen target samples into the aligned space using the learned support vectors.

\paragraph{Hyperparameter Configuration and Kernel Choice}
The behaviour of TCA is governed by the hyperparameters listed in Table~\ref{tab:tca_hyperparams}.

\begin{table}[htbp]
\centering
\caption{TCA hyperparameter configuration in PANDA}
\label{tab:tca_hyperparams}
\begin{tabular}{lp{0.5\textwidth}l}
\toprule
\textbf{Parameter} & \textbf{Description and role} & \textbf{Value} \\ \midrule
\texttt{kernel} & Kernel function type. Controls the implicit feature map $\featuremap(\featurevec)$. & 'linear' \\
\texttt{n\_components} ($\tcaprojectdim$) & Dimensionality of the projected subspace. & 10 \\
\texttt{mu} ($\regularizationparam$) & Regularization parameter. Balances alignment (MMD) against variance preservation. Higher $\regularizationparam$ reduces adaptation. & 1.0 \\
\texttt{gamma} ($\gammaK$) & Kernel coefficient for RBF ($e^{-\gamma \|x-y\|^2}$). Passed via \texttt{kernel\_params}. & N/A \\
\bottomrule
\end{tabular}
\end{table}

We explicitly choose a \textbf{linear kernel} ($\linearK(x, y) = x^\top y$) over the radial basis function (RBF) kernel ($\rbfK(x, y) = \exp(-\gammaK \|x-y\|^2)$) for the following reasons:
\begin{enumerate}
    \item \textbf{Feature disentanglement:} The RFE-selected features already form a robust, low-dimensional subset. A linear alignment of their first-order moments is sufficient and less prone to overfitting than the infinite-dimensional mapping induced by the RBF kernel.
    \item \textbf{Stability on small samples:} RBF kernels require tuning the bandwidth $\gammaK$, which can be unstable on small cohorts ($N \approx 300$). An improper choice of $\gammaK$ can lead to a degenerate Gram matrix.
    \item \textbf{Negative transfer avoidance:} Empirical tests indicated that RBF-TCA often collapsed the TabPFN classifier to the majority class because of noise amplification in the high-dimensional RBF space.
\end{enumerate}
This configuration allows PANDA to benefit from domain alignment without incurring the instability often associated with kernel methods on small datasets.

\subsubsection{Parameter Sensitivity Diagnostics}
\label{sec:param_sensitivity}
To ensure that the chosen defaults are numerically stable and that the TCA hyperparameters do not introduce hidden instabilities or negative transfer, the automated regression test suite exercises the same Adapt wrapper on the Mayo~$\rightarrow$~PKUPH split with stress configurations (letting Adapt infer \texttt{n\_components=None} and shrinking $\mu$ to $0.1$). The test reports $\accuracy$, $\auc$, $\fonescore$, $\precision$, and $\recall$ and asserts that the predicted probabilities remain in $[0,1]$. Because both the production path and the test harness rely on the identical Adapt pipeline, these executions provide our practical parameter-sensitivity verification for PANDA.

\subsection{Experimental Configuration}
\label{subsec:experimental_config}

\subsubsection{Baseline Hyperparameters}
To enable fair comparison, all baseline models were configured with default hyperparameters and essential settings for reproducibility. As shown in Table~\ref{tab:hyperparams}, we focused on consistent random state management, class imbalance handling through balanced class weights, and parallel processing for computational efficiency. This approach ensures that the comparison reflects the models' inherent capabilities rather than extensive hyperparameter optimization, which aligns with our research focus on domain adaptation effectiveness rather than individual model tuning.

\begin{table}[htbp]
\centering
\caption{Configuration for baseline models. Default parameters were used with basic settings for reproducibility and class imbalance handling.}
\label{tab:hyperparams}
\begin{tabular}{lll}
\toprule
\textbf{Model} & \textbf{Parameter} & \textbf{Value} \\ \midrule
\multirow{3}{*}{XGBoost} & Random state & Fixed per experiment \\
 & n\_jobs & -1 (parallel processing) \\
 & eval\_metric & 'logloss' \\ \midrule
\multirow{3}{*}{Random Forest} & Random state & Fixed per experiment \\
 & n\_jobs & -1 (parallel processing) \\
 & Class weight & 'balanced' \\ \midrule
\multirow{3}{*}{SVM} & Random state & Fixed per experiment \\
 & Probability & True (for probability outputs) \\
 & Class weight & 'balanced' \\ \bottomrule
\end{tabular}
\end{table}

\subsubsection{Clinical Scoring Models}
We implemented three established clinical calculators for pulmonary nodule malignancy:
\begin{itemize}
    \item \textbf{Mayo model}: $\text{Prob} = \sigma(-6.83 + 0.039 \cdot \text{Age} + 0.79 \cdot \text{Smoke} + 1.34 \cdot \text{CancerHx} + 0.13 \cdot \text{Diameter} + 1.04 \cdot \text{Spiculation} + 0.78 \cdot \text{UpperLobe})$ \cite{swensen1997chest}.
    \item \textbf{PKUPH model}: A regression model specifically developed for Chinese populations \cite{perandini_solid_2016}: $\text{Prob} = \sigma(-4.50 + 0.07 \cdot \text{Age} + 0.68 \cdot \text{Diameter} + 0.74 \cdot \text{Spiculation} + 1.27 \cdot \text{FamilyHx} - 1.62 \cdot \text{Calcification} - 1.41 \cdot \text{Boundary})$.
    \item \textbf{LASSO Logistic Regression}: A data-driven baseline derived via L1-regularization on the source domain \cite{he2021novel}: $\hat{p} = \activation(-1.14 + 0.036 \cdot \text{Age} + 0.38 \cdot \text{CancerHx} + 0.20 \cdot \text{Diameter} - 0.29 \cdot \text{Calcification} + 0.026 \cdot \text{PleuralStretch} - 0.17 \cdot \text{VC} + 0.05 \cdot \text{DLCO} + 0.018 \cdot \text{CEA} + 0.004 \cdot \text{NSE})$.
\end{itemize}
These models are applied using their published coefficients without re-training and represent the standard of care.

\subsubsection{ML Baseline Models}
We implemented five machine learning baseline models for comprehensive comparison with the PANDA framework. These models were trained and evaluated using 10-fold cross-validation on the target domain with the same feature set and preprocessing pipeline as PANDA:
\begin{itemize}
    \item \textbf{Support Vector Machine (SVM)}: A maximum margin classifier that finds optimal hyperplanes for classification \cite{cortes1995support}. Configuration: probability=True, class\_weight='balanced' for imbalanced data handling.
    \item \textbf{Decision Tree (DT)}: A tree-based classifier that learns decision rules from data features using recursive partitioning \cite{breiman1984classification}. Configuration: default sklearn parameters with reproducibility settings.
    \item \textbf{Random Forest (RF)}: An ensemble method that constructs multiple decision trees and outputs the majority vote through bagging \cite{breiman2001random}. Configuration: class\_weight='balanced', parallel processing enabled.
    \item \textbf{Gradient Boosting Decision Tree (GBDT)}: A boosting ensemble method that builds trees sequentially, each correcting the previous one's errors through gradient descent optimization \cite{friedman2001greedy}. Configuration: default sklearn parameters for gradient boosting.
    \item \textbf{XGBoost}: An optimized gradient boosting framework designed for efficiency and performance with regularized objective function and tree pruning \cite{chen2016xgboost}. Configuration: eval\_metric='logloss', parallel processing enabled.
\end{itemize}
All ML baseline models used default hyperparameters with consistent random state management and class imbalance handling, ensuring comparison reflects inherent model capabilities rather than extensive optimization.

\subsubsection{Computational Framework}
All experiments were conducted on the High Performance Computing platform at the Hong Kong Polytechnic University Department of Computing, equipped with
\begin{itemize}
    \item \textbf{Hardware}: NVIDIA A800-SXM4-80GB GPU (80GB HBM2 memory), AMD EPYC 7742 64-Core Processor (256 threads), NUMA architecture with 512MB L3 cache.
    \item \textbf{Software}: PyTorch 2.7.0 (CUDA 12.2), Scikit-learn 1.6.1, Adapt 0.4.4.
    \item \textbf{System}: Ubuntu 22.04.4 LTS, NVIDIA Driver 535.161.07.
\end{itemize}

\label{sec:meth-end}
