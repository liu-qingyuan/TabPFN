\section{Methods}
\label{sec:methods}
\label{sec:meth-start}

\subsection{Motivating Challenges and Methodological Response}
Cross-hospital malignancy prediction and public-health surveillance generate intertwined constraints: tiny labeled cohorts, label imbalance, feature mismatch, and multiple forms of distribution shift. PANDA is organized around these constraints rather than around model novelty. Table~\ref{tab:challenge_mapping} distills the major obstacles and the mechanisms assigned to them.

\begin{table}[htbp]
  \centering
  \caption{Challenge--mechanism mapping in PANDA. Each component targets a known failure mode, and the same design is reused for pulmonary nodules and the TableShift BRFSS race-shift task.}
  \label{tab:challenge_mapping}
  \begin{tabular}{p{0.22\textwidth}p{0.32\textwidth}p{0.33\textwidth}}
    \toprule
    Challenge & Mechanism & Expected benefit \\ \midrule
    Small $n$ with high-dimensional covariates & TabPFN prior-data fitted network performs in-context learning with frozen weights & Transfers structural priors from millions of synthetic tasks, reducing estimation variance without local fine-tuning \\ 
    Feature heterogeneity across institutions/demographics & Cross-domain RFE surfaces stable subsets (``best7'', ``best8'') definable in every site, plus schema alignment utilities & Removes site-specific artefacts before adaptation and guarantees that downstream models only consume shared attributes \\ 
    Covariate shift and mixed acquisition protocols & TCA applied to TabPFN embeddings realigns marginal distributions before the classifier head & Shrinks the $d_{\mathcal{H}\Delta\mathcal{H}}$ divergence so that context examples remain relevant to target queries \\ 
    Label prevalence drift and class imbalance & Class-balanced sampling, calibrated decision thresholds, and ensemble temperature scaling & Maintains sensitivity for malignant/SPN-positive cohorts and accounts for higher diabetes rates in non-White BRFSS respondents \\ 
    Variance from preprocessing choices & Multi-branch preprocessing (ordering, quantile transforms, ordinal encoding) with ensemble averaging & Injects diversity without retraining new weights and stabilizes predictions under minor data perturbations \\ \bottomrule
  \end{tabular}
\end{table}

This architecture ensures that every component answers a crisp question: why do small-sample medical deployments fail, and what prior or alignment tool counters that failure?

\subsection{Feature Engineering and Selection Implementation}
\label{subsec:feature_engineering}

The feature engineering pipeline in PANDA is designed to handle the heterogeneity of medical data sources while preserving domain-invariant signals. It consists of two distinct stages: global feature selection via Cross-Domain RFE and local feature transformation via TabPFN's internal preprocessing branches.

\subsubsection{Cross-Domain Recursive Feature Elimination (RFE)}
\label{subsubsec:rfe_implementation}
To address the "feature mismatch" challenge, we implement a Cross-Domain Recursive Feature Elimination (RFE) strategy. Unlike standard RFE which optimizes for a single dataset, our approach seeks a feature subset $\mathcal{S}^*$ that maximizes predictive performance on the source domain $\mathcal{D}_s$ while satisfying availability constraints in the target domain $\mathcal{D}_t$.

The process, implemented in \texttt{predict\_healthcare\_RFE.py}, uses a wrapper around the TabPFN classifier to compute permutation importance. We define the importance of feature $j$ as the degradation in AUC when its values are randomly shuffled:
\begin{equation}
    I_j = \text{AUC}(\mathcal{D}_{\text{val}}) - \frac{1}{K} \sum_{k=1}^K \text{AUC}(\mathcal{D}_{\text{val}}^{(j, \text{shuffled})})
\end{equation}
where $K=5$ repeats. Algorithm~\ref{alg:cross_domain_rfe} details the iterative elimination process.

\begin{algorithm}[H]
\caption{Cross-Domain Recursive Feature Elimination (RFE)}
\label{alg:cross_domain_rfe}
\begin{algorithmic}[1]
\REQUIRE Source Data $X_s, y_s$, Target Schema $\mathcal{F}_t$, Target Feature Count $k_{\text{target}}$
\ENSURE Optimal Feature Subset $\mathcal{S}^*$
\STATE \textbf{Initialize:} $\mathcal{S} \leftarrow \text{features}(X_s) \cap \mathcal{F}_t$ \COMMENT{Intersect with target availability}
\WHILE{$|\mathcal{S}| > k_{\text{target}}$}
    \STATE Train TabPFN classifier $\mathcal{M}$ on $X_s[\mathcal{S}], y_s$
    \STATE Compute Permutation Importance vector $\mathbf{I} \in \mathbb{R}^{|\mathcal{S}|}$ using 5 repeats
    \STATE Identify feature with minimum importance: $f_{\text{min}} \leftarrow \arg\min_{f \in \mathcal{S}} \mathbf{I}[f]$
    \STATE $\mathcal{S} \leftarrow \mathcal{S} \setminus \{f_{\text{min}}\}}$ \COMMENT{Eliminate weakest feature}
    \STATE Record performance metric $M_{|\mathcal{S}|}$ (AUC) via 10-fold CV
\ENDWHILE
\STATE \textbf{Select} $\mathcal{S}^*$ based on Cost-Effectiveness Index (CEI):
\STATE $\text{CEI}(k) = \frac{\text{AUC}_k - 0.5}{\text{Cost}_k}$ \COMMENT{Optional cost-aware selection}
\RETURN $\mathcal{S}^*$
\end{algorithmic}
\end{algorithm}

This algorithm produces the standard subsets referenced throughout the study: ``best7'' (Age, Spiculation, etc.) and ``best8''.

\subsubsection{Multi-Branch Preprocessing Strategy}
Once the feature set is fixed, PANDA leverages TabPFN's internal ensemble mechanism to handle distribution shifts in feature scaling and encoding. This is effectively a "test-time augmentation" for tabular data. The \texttt{EnsembleConfig} generates 32 distinct views of the data through four preprocessing pipelines:
\begin{enumerate}
    \item \textbf{No-Op Branch:} Raw features are passed directly, preserving original distributions (useful for tree-based logic).
    \item \textbf{Quantile Branch:} Features are transformed via $F^{-1}(\Phi(x))$, mapping the empirical CDF to a standard Normal $\mathcal{N}(0,1)$. This handles extreme outliers and skewed distributions common in medical markers (e.g., CEA levels).
    \item \textbf{Ordinal Branch:} All unique values are ranked and replaced by their integer rank. This removes magnitude information but preserves order, making the model robust to unit changes (e.g., cm vs mm).
    \item \textbf{Power Transform Branch:} Applies $x \mapsto x^\lambda$ (e.g., square root or log) to stabilize variance.
\end{enumerate}
Each branch is applied to both support (train) and query (test) sets simultaneously, ensuring consistent mapping.

\subsection{Foundation Model Integration Mechanism}
\label{subsec:foundation_model_integration}

PANDA utilizes TabPFN not just as a black-box classifier but as a differentiable feature extractor and probabilistic reasoner. The integration involves specific mathematical serialization and ensemble construction steps.

\subsubsection{In-Context Serialization and Tokenization}
Unlike BERT-style models that require text, TabPFN consumes raw numerical and categorical values. The serialization process, defined in \texttt{src/tabpfn/model/encoders.py}, maps a heterogeneous row $\mathbf{x} \in \mathbb{R}^{d_{\text{num}}} \times \mathbb{Z}^{d_{\text{cat}}}$ into a sequence of continuous embeddings.

For a numerical feature $x^{(j)}$, the embedding is a linear projection:
\begin{equation}
    \mathbf{e}^{(j)} = \mathbf{W}_{\text{num}}^{(j)} x^{(j)} + \mathbf{b}_{\text{num}}^{(j)}
\end{equation}
For a categorical feature with index $c$, we use a lookup table:
\begin{equation}
    \mathbf{e}^{(j)} = \text{EmbeddingMatrix}^{(j)}[c]
\end{equation}
Missing values are handled by a specialized learnable token $\mathbf{e}_{\text{nan}}$. The full sample embedding is the sum of feature embeddings plus a positional encoding:
\begin{equation}
    \mathbf{E}_{\text{sample}} = \text{MLP}(\text{Concat}(\mathbf{e}^{(1)}, \dots, \mathbf{e}^{(d)})) + \mathbf{P}_{\text{pos}}
\end{equation}
This allows the Transformer to attend to "patient A" vs "patient B" distinctively within the context window.

\subsubsection{Ensemble Construction and Inference}
The final prediction is an average over 32 diverse forward passes. Let $\mathcal{B} = \{P_1, \dots, P_4\}$ be the set of preprocessing functions and $\mathcal{S} = \{s_1, \dots, s_8\}$ be a set of random seeds that control the subsampling of the context set (the "support set" of labeled examples). The ensemble probability estimate is:

\begin{equation}
    \hat{P}(y=1|\mathbf{x}_q) = \frac{1}{32} \sum_{P \in \mathcal{B}} \sum_{s \in \mathcal{S}} \sigma\left( \frac{f_\theta(P(\mathbf{x}_q) \mid P(\mathbf{X}_{\text{ctx}}^s))}{T} \right)
\end{equation}

where:
\begin{itemize}
    \item $\mathbf{x}_q$ is the target query (patient).
    \item $\mathbf{X}_{\text{ctx}}^s$ is the subset of training data selected by seed $s$ (typically 1024 samples).
    \item $f_\theta$ is the frozen TabPFN Transformer backbone.
    \item $T=0.9$ is the temperature scaling parameter calibrated for small-sample confidence.
\end{itemize}

Algorithm~\ref{alg:tabpfn_inference} summarizes the inference pass.

\begin{algorithm}[H]
\caption{PANDA Inference with TabPFN Backbone}
\label{alg:tabpfn_inference}
\begin{algorithmic}[1]
\REQUIRE Query $\mathbf{x}_q$, Context $\mathcal{D}_{\text{train}}$, Ensemble $N=32$
\ENSURE Malignancy Probability $\hat{y}$
\STATE $\text{Logits} \leftarrow []$
\FOR{$i=1$ \TO $N$}
    \STATE Sample preprocessing $P \sim \mathcal{B}$ and context subset $\mathcal{D}_i \subset \mathcal{D}_{\text{train}}$
    \STATE $\mathbf{x}'_q, \mathcal{D}'_i \leftarrow P(\mathbf{x}_q), P(\mathcal{D}_i)$ \COMMENT{Apply Branch}
    \STATE $\mathbf{E} \leftarrow \text{Serialize}(\mathbf{x}'_q, \mathcal{D}'_i)$ \COMMENT{Tokenize}
    \STATE $\mathbf{z} \leftarrow \text{Transformer}(\mathbf{E})$ \COMMENT{Forward Pass}
    \STATE $l_i \leftarrow \text{ClassifierHead}(\mathbf{z})$
    \STATE $\text{Logits}.\text{append}(l_i)$
\ENDFOR
\STATE $\hat{y} \leftarrow \text{Softmax}(\text{Mean}(\text{Logits}) / T)$
\RETURN $\hat{y}$
\end{algorithmic}
\end{algorithm}

\subsection{Domain Adaptation Implementation}
\label{subsec:da_implementation}
We utilize the \texttt{adapt} library (v0.4.4) to implement Transfer Component Analysis (TCA) and baselines. The integration is handled by the \texttt{AdaptUDAMethod} wrapper in \texttt{uda/adapt\_methods.py}.

\subsubsection{Transfer Component Analysis (TCA)}
TCA is applied in the latent embedding space of TabPFN. The core optimization problem is finding a projection matrix $\mathbf{W} \in \mathbb{R}^{d \times p}$ that minimizes the Maximum Mean Discrepancy (MMD) between source and target distributions while preserving data variance.
\begin{equation}
    \min_{\mathbf{W}} \text{tr}(\mathbf{W}^\top \mathbf{K} \mathbf{L} \mathbf{K} \mathbf{W}) + \mu \text{tr}(\mathbf{W}^\top \mathbf{W})
\end{equation}
\begin{itemize}
    \item \textbf{Kernel Matrix $\mathbf{K}$}: We employ a linear kernel $\mathbf{K}_{ij} = \mathbf{x}_i^\top \mathbf{x}_j$ on the TabPFN embeddings. Since the Transformer has already performed highly non-linear feature extraction, a linear alignment in the embedding space is sufficient and computationally efficient.
    \item \textbf{MMD Matrix $\mathbf{L}$}: Constructed as $L_{ij} = \frac{1}{n_s^2}$ if $i,j \in \mathcal{D}_s$, $\frac{1}{n_t^2}$ if $i,j \in \mathcal{D}_t$, and $-\frac{1}{n_s n_t}$ otherwise.
    \item \textbf{Regularization $\mu$}: Set to 1.0 based on stability tests (refer to Section~\ref{sec:param_sensitivity}).
\end{itemize}

\subsubsection{Baselines (SA and CORAL)}
For comparative analysis, we implemented:
\begin{itemize}
    \item \textbf{Subspace Alignment (SA)}: Learns a linear mapping function $M$ to align the PCA subspaces of source and target. Implemented via \texttt{adapt.feature\_based.SA}.
    \item \textbf{CORAL}: Minimizes the difference in second-order statistics (covariance matrices) between domains. Implemented via \texttt{adapt.feature\_based.CORAL} with $\lambda=1.0$.
\end{itemize}

\subsection{Experimental Configuration}
\label{subsec:experimental_config}

\subsubsection{Baseline Hyperparameters}
To ensure fair comparison, all baseline models were tuned using grid search within the ranges specified in Table~\ref{tab:hyperparams}. The \texttt{MLBaselineModel} class in \texttt{modeling/ml\_baseline_models.py} manages these configurations.

\begin{table}[htbp]
\centering
\caption{Hyperparameter search space for baseline models. Best parameters were selected via 5-fold CV on the source domain.}
\label{tab:hyperparams}
\begin{tabular}{lll}
\toprule
\textbf{Model} & \textbf{Parameter} & \textbf{Search Space / Value} \\ \midrule
\multirow{3}{*}{XGBoost} & Learning Rate & [0.01, 0.05, 0.1] \\
 & Max Depth & [3, 4, 5, 6] \\
 & N Estimators & [50, 100, 200] \\ \midrule
\multirow{3}{*}{Random Forest} & N Estimators & [100, 200, 500] \\
 & Max Features & ['sqrt', 'log2'] \\
 & Class Weight & 'balanced' \\ \midrule
\multirow{2}{*}{SVM} & C (Regularization) & [0.1, 1, 10, 100] \\
 & Kernel & ['rbf', 'linear'] \\ \midrule
\multirow{1}{*}{Logistic Regression} & Penalty & ['l1', 'l2', 'elasticnet'] \\ \bottomrule
\end{tabular}
\end{table}

\subsubsection{Clinical Scoring Models}
We implemented three established clinical calculators for pulmonary nodule malignancy:
\begin{itemize}
    \item \textbf{Mayo Model}: $P = \sigma(-6.8 + 0.039 \cdot \text{Age} + 0.79 \cdot \text{Smoker} + 1.33 \cdot \text{CancerHx} + \dots)$
    \item \textbf{Brock (PanCan) Model}: Includes spiculation and nodule count.
    \item \textbf{PKUPH Model}: A regression model specifically developed for Chinese populations \cite{perandini_solid_2016}.
\end{itemize}
These models are applied using their published coefficients without re-training, representing the standard of care.

\subsubsection{Computational Framework}
All experiments were conducted on a workstation equipped with:
\begin{itemize}
    \item \textbf{Hardware}: NVIDIA RTX 4090 GPU (24GB VRAM), AMD Ryzen 9 7950X CPU, 64GB DDR5 RAM.
    \item \textbf{Software}: PyTorch 2.1.2 (CUDA 12.1), Scikit-learn 1.3.2, Adapt 0.4.4.
    \item \textbf{Reproducibility}: Random seeds for Numpy, PyTorch, and Scikit-learn were fixed to 42. Code is available at \texttt{https://github.com/PriorLabs/TabPFN}.
\end{itemize}

\label{sec:meth-end}