\section{Methods}
\label{sec:methods}
\label{sec:meth-start}

\subsection{Motivating Challenges and Methodological Response}
Cross-hospital malignancy prediction and public-health surveillance generate intertwined constraints: tiny labeled cohorts, label imbalance, feature mismatch, and multiple forms of distribution shift. PANDA is organized around these constraints rather than around model novelty. Table~\ref{tab:challenge_mapping} distills the major obstacles and the mechanisms assigned to them.

\begin{table}[htbp]
  \centering
  \caption{Challenge--mechanism mapping in PANDA. Each component targets a known failure mode, and the same design is reused for pulmonary nodules and the TableShift BRFSS race-shift task.}
  \label{tab:challenge_mapping}
  \begin{tabular}{p{0.22\textwidth}p{0.32\textwidth}p{0.33\textwidth}}
    \toprule
    Challenge & Mechanism & Expected benefit \\ \midrule
    Small $\sourcedatasize$ with high-dimensional covariates & TabPFN prior-data fitted network performs in-context learning with frozen weights & Transfers structural priors from millions of synthetic tasks, reducing estimation variance without local fine-tuning \\ 
    Feature heterogeneity across institutions/demographics & Cross-domain RFE surfaces stable subsets (``best8'') definable in every site, plus schema alignment utilities & Removes site-specific artefacts before adaptation and guarantees that downstream models only consume shared attributes \\ 
    Covariate shift and mixed acquisition protocols & TCA applied to RFE-selected features realigns marginal distributions before the TabPFN classifier & Shrinks the $\domaindivergence$ divergence so that context examples remain relevant to target queries \\ 
    Label prevalence drift and class imbalance & Class-balanced sampling, calibrated decision thresholds, and ensemble temperature scaling & Maintains sensitivity for malignant/SPN-positive cohorts and accounts for higher diabetes rates in non-White BRFSS respondents \\ 
    Variance from preprocessing choices & Multi-branch preprocessing (ordering, quantile transforms, ordinal encoding) with ensemble averaging & Injects diversity without retraining new weights and stabilizes predictions under minor data perturbations \\ \bottomrule
  \end{tabular}
\end{table}

This architecture ensures that every component answers a crisp question: why do small-sample medical deployments fail, and what prior or alignment tool counters that failure?

\subsection{Feature Engineering and Selection Implementation}
\label{subsec:feature_engineering}

The feature engineering pipeline in PANDA is designed to handle the heterogeneity of medical data sources while preserving domain-invariant signals. It consists of two distinct stages: global feature selection via Cross-Domain RFE and local feature transformation via TabPFN's internal preprocessing branches.

\subsubsection{Cross-Domain Recursive Feature Elimination (RFE)}
\label{subsubsec:rfe_implementation}
To address the "feature mismatch" challenge, we implement a Cross-Domain Recursive Feature Elimination (RFE) strategy. Unlike standard RFE which optimizes for a single dataset, our approach seeks a feature subset $\rfeselectedfeatures$ that maximizes predictive performance on the source domain $\sourcedomaindist$ while satisfying availability constraints in the target domain $\targetdomaindist$.

The process, implemented in \texttt{predict\_healthcare\_RFE.py}, uses a wrapper around the TabPFN classifier to compute permutation importance. We define the importance of feature $j$ as the degradation in \auc when its values are randomly shuffled:
\begin{equation}
    \rfeimportance_j = \lossauc(\mathcal{D}_{\text{val}}) - \frac{1}{\numfolds} \sum_{k=1}^{\numfolds} \lossauc(\mathcal{D}_{\text{val}}^{(j, \text{shuffled})})
\end{equation}
where $\numfolds=5$ repeats. Algorithm~\ref{alg:cross_domain_rfe} details the iterative elimination process.

\begin{algorithm}[H]
\caption{Cross-Domain Recursive Feature Elimination (RFE)}
\label{alg:cross_domain_rfe}
\begin{algorithmic}[1]
\REQUIRE Source Data $\sourcedatafeatures, \sourcedatalabels$, Target Schema $\targetfeatureschema$, Target Feature Count $\targetfeaturecount$
\ENSURE Optimal Feature Subset $\rfeselectedfeatures$
\STATE \textbf{Initialize:} $\mathcal{S} \leftarrow \text{features}(\sourcedatafeatures) \cap \targetfeatureschema$ \COMMENT{Intersect with target availability}
\WHILE{$|\mathcal{S}| > \targetfeaturecount$}
    \STATE Train TabPFN classifier $\mathcal{M}$ on $\sourcedatafeatures[\mathcal{S}], \sourcedatalabels$
    \STATE Compute Permutation Importance vector $\featureimportancevec \in \mathbb{R}^{|\mathcal{S}|}$ using 5 repeats
    \STATE Identify feature with minimum importance: $\minfeature \leftarrow \argmin_{f \in \mathcal{S}} \featureimportancevec[f]$
    \STATE $\mathcal{S} \leftarrow \mathcal{S} \setminus \{\minfeature\}$ \COMMENT{Eliminate weakest feature}
    \STATE Record performance metric $\metrick(|\mathcal{S}|)$ (\auc) via 10-fold CV
\ENDWHILE
\STATE \textbf{Select} $\rfeselectedfeatures$ based on Cost-Effectiveness Index (CEI):
\STATE $\text{CEI}(\rfecurrentdim) = \frac{\auc_{\rfecurrentdim} - 0.5}{\text{Cost}_{\rfecurrentdim}}$ \COMMENT{Optional cost-aware selection}
\RETURN $\rfeselectedfeatures$
\end{algorithmic}
\end{algorithm}

This algorithm produces the standard subsets referenced throughout the study: ``best8''.

\subsubsection{Multi-Branch Preprocessing Strategy}
Once the feature set is fixed, PANDA leverages TabPFN's internal ensemble mechanism to handle distribution shifts in feature scaling and encoding. This is effectively a "test-time augmentation" for tabular data. The \texttt{EnsembleConfig} generates 32 distinct views of the data through four preprocessing pipelines:
\begin{enumerate}
    \item \textbf{No-Op Branch:} Raw features are passed directly, preserving original distributions (useful for tree-based logic).
    \item \textbf{Quantile Branch:} Features are transformed via $F^{-1}(\Phi(\featurevec))$, mapping the empirical CDF to a standard Normal $\mathcal{N}(0,1)$. This handles extreme outliers and skewed distributions common in medical markers (e.g., CEA levels).
    \item \textbf{Ordinal Branch:} All unique values are ranked and replaced by their integer rank. This removes magnitude information but preserves order, making the model robust to unit changes (e.g., cm vs mm).
    \item \textbf{Power Transform Branch:} Applies $\featurevec \mapsto \featurevec^\adaptabilityterm$ (e.g., square root or log) to stabilize variance.
\end{enumerate}
Each branch is applied to both support (train) and query (test) sets simultaneously, ensuring consistent mapping.

\subsection{Foundation Model Integration Mechanism}
\label{subsec:foundation_model_integration}

PANDA utilizes TabPFN as a robust probabilistic classifier within an integrated framework. While TabPFN internally processes features, its role in PANDA is to provide final, confident predictions on adapted tabular data. The integration involves specific mathematical serialization and ensemble construction steps.

\subsubsection{In-Context Serialization and Tokenization}
Unlike BERT-style models that require text, TabPFN consumes raw numerical and categorical values. The serialization process, defined in \texttt{src/tabpfn/model/encoders.py}, maps a heterogeneous row $\featurevec \in \mathbb{R}^{d_{\text{num}}} \times \mathbb{Z}^{d_{\text{cat}}}$ into a sequence of continuous embeddings.

For a numerical feature $\featurevec^{(j)}$, the embedding is a linear projection:
\begin{equation}
    \numfeatureembed = \numweightmat \featurevec^{(j)} + \numbiasvec
\end{equation}
For a categorical feature with index $\catindex$, we use a lookup table:
\begin{equation}
    \numfeatureembed = \catelembedmat[\catindex]
\end{equation}
Missing values are handled by a specialized learnable token $\nanembed$. The full sample embedding is the sum of feature embeddings plus a positional encoding:
\begin{equation}
    \samplesembed = \mlp(\concat(\mathbf{e}^{(1)}, \dots, \mathbf{e}^{(\featuredim)})) + \posencoding
\end{equation}
This allows the Transformer to attend to "patient A" vs "patient B" distinctively within the context window.

\subsubsection{Ensemble Construction and Inference}
The final prediction is an average over 32 diverse forward passes. Let $\preprocessingbranches = \{P_1, \dots, P_4\}$ be the set of preprocessing functions and $\randomseeds = \{s_1, \dots, s_8\}$ be a set of random seeds that control the subsampling of the context set (the "support set" of labeled examples). The ensemble probability estimate is:

\begin{equation}
    \ensembleprob = \frac{1}{32} \sum_{P \in \preprocessingbranches} \sum_{s \in \randomseeds} \activation\left( \frac{\transformerbackbone(P(\querypatient) \mid P(\contextdata))}{\temperature} \right)
\end{equation}

where:
\begin{itemize}
    \item $\querypatient$ is the target query (patient).
    \item $\contextdata$ is the subset of training data selected by seed $s$ (typically 1024 samples).
    \item $\transformerbackbone$ is the frozen TabPFN Transformer backbone.
    \item $\temperature=0.9$ is the temperature scaling parameter calibrated for small-sample confidence.
\end{itemize}

Algorithm~\ref{alg:tabpfn_inference} summarizes the inference pass.

\begin{algorithm}[H]
\caption{PANDA Inference with TabPFN Backbone}
\label{alg:tabpfn_inference}
\begin{algorithmic}[1]
\REQUIRE Query $\querypatient$, Context $\mathcal{D}_{\text{train}}$, Ensemble $N=32$
\ENSURE Malignancy Probability $\hat{\labelval}$
\STATE $\text{Logits} \leftarrow []$
\FOR{$i=1$ \TO $N$}
    \STATE Sample preprocessing $P \sim \preprocessingbranches$ and context subset $\mathcal{D}_i \subset \mathcal{D}_{\text{train}}$
    \STATE $\mathbf{x}'_q, \mathcal{D}'_i \leftarrow P(\querypatient), P(\mathcal{D}_i)$ \COMMENT{Apply Branch}
    \STATE $\mathbf{E} \leftarrow \text{Serialize}(\mathbf{x}'_q, \mathcal{D}'_i)$ \COMMENT{Tokenize}
    \STATE $\mathbf{z} \leftarrow \text{Transformer}(\mathbf{E})$ \COMMENT{Forward Pass}
    \STATE $\ceilogit \leftarrow \text{ClassifierHead}(\mathbf{z})$
    \STATE $\text{Logits}.\text{append}(\ceilogit)$
\ENDFOR
\STATE $\hat{\labelval} \leftarrow \text{Softmax}(\text{Mean}(\text{Logits}) / \temperature)$
\RETURN $\hat{\labelval}$
\end{algorithmic}
\end{algorithm}

\subsubsection{Transfer Component Analysis (TCA)}
\label{subsubsec:tca_implementation}

TCA is applied to the RFE-selected feature space to align the marginal distributions of the source and target domains. We implement this alignment via the \texttt{adapt.feature\_based.TCA} module (specifically \texttt{adapt/adapt/feature\_based/\_tca.py}), which wraps the optimization problem into a scikit-learn compatible estimator.

\paragraph{Mathematical Formulation}
The core optimization problem seeks a projection matrix $\tcaprojectionmatrix \in \mathbb{R}^{(\sourcedatasize+\targetdatasize) \times \tcaprojectdim}$ that maps the kernel matrix $\kernelmatrix$ to a low-dimensional latent space. The objective is to minimize the Maximum Mean Discrepancy (MMD) between domains while preserving the data variance \cite{de2021adapt, noauthor_welcome_nodate}.

The kernel matrix $\kernelmatrix \in \mathbb{R}^{(\sourcedatasize+\targetdatasize) \times (\sourcedatasize+\targetdatasize)}$ is constructed as a block matrix:
\begin{equation}
    \kernelmatrix = \begin{bmatrix} \kernelmatrix_{SS} & \kernelmatrix_{ST} \\ \kernelmatrix_{TS} & \kernelmatrix_{TT} \end{bmatrix}
\end{equation}
where $\kernelmatrix_{SS}, \kernelmatrix_{TT}, \kernelmatrix_{ST}$ represent the kernel evaluations within source, within target, and between source-target samples, respectively.

The MMD matrix $\mmdmatrix$ and Centering matrix $\centeringmatrix$ are defined as:
\begin{equation}
    \mmdmatrix_{ij} = \begin{cases} \frac{1}{\sourcedatasize^2} & x_i, x_j \in \sourcedata \\ \frac{1}{\targetdatasize^2} & x_i, x_j \in \targetdata \\ -\frac{1}{\sourcedatasize \targetdatasize} & \text{otherwise} \end{cases}, \quad
    \centeringmatrix = \identitymatrix - \frac{1}{\sourcedatasize+\targetdatasize}\onesvec\onesvec^\top
\end{equation}

The ADAPT implementation solves for the projection $\tcaprojectionmatrix$ by addressing the generalized eigenvalue problem. Specifically, it computes:
\begin{equation}
    \mathbf{A} = \identitymatrix + \regularizationparam \kernelmatrix \mmdmatrix \kernelmatrix, \quad \mathbf{B} = \kernelmatrix \centeringmatrix \kernelmatrix
\end{equation}
and solves for the eigenvectors of $\mathbf{A}^{-1} \mathbf{B}$. This formulation maximizes the ratio of data variance ($\tr(\tcaprojectionmatrix^\top \mathbf{B} \tcaprojectionmatrix)$) to the regularized domain divergence ($\tr(\tcaprojectionmatrix^\top \mathbf{A} \tcaprojectionmatrix)$). The top $\tcaprojectdim$ eigenvectors form the projection matrix $\tcaprojectionmatrix$.

\paragraph{Data Flow and Transformation}
In the \texttt{fit\_transform} phase, the TabPFN latent embeddings for both source ($\sourcedatafeatures$) and target ($\targetfeatureschema$) are concatenated. The solver computes $\tcaprojectionmatrix$ using the combined kernel matrix.
For a new query sample $\queryvec$, the transformation projects it into the shared subspace via:
\begin{equation}
    \mathbf{z}_{\text{new}} = \mathbf{k}_{\text{new}}^\top \tcaprojectionmatrix
\end{equation}
where $\mathbf{k}_{\text{new}} = [k(\queryvec, x_1), \dots, k(\queryvec, x_{n+m})]^\top$ is the kernel vector between the query and all training samples. This allows the model to map unseen target samples into the aligned space using the learned support vectors.

\paragraph{Hyperparameter Configuration and Kernel Choice}
The behavior of TCA is governed by the hyperparameters listed in Table~\ref{tab:tca_hyperparams}.

\begin{table}[htbp]
\centering
\caption{TCA Hyperparameter Configuration in PANDA}
\label{tab:tca_hyperparams}
\begin{tabular}{lp{0.5\textwidth}l}
\toprule
\textbf{Parameter} & \textbf{Description \& Role} & \textbf{Value} \\ \midrule
\texttt{kernel} & Kernel function type. Controls the implicit feature map $\featuremap(\featurevec)$. & 'linear' \\
\texttt{n\_components} ($\tcaprojectdim$) & Dimensionality of the projected subspace. & 10 \\
\texttt{mu} ($\regularizationparam$) & Regularization parameter. Balances alignment (MMD) vs. variance preservation. Higher $\regularizationparam$ reduces adaptation. & 1.0 \\
\texttt{gamma} ($\gammaK$) & Kernel coefficient for RBF ($e^{-\gamma \|x-y\|^2}$). Passed via \texttt{kernel\_params}. & N/A \\
\bottomrule
\end{tabular}
\end{table}

We explicitly choose a \textbf{Linear Kernel} ($\linearK(x, y) = x^\top y$) over the Radial Basis Function (RBF) kernel ($\rbfK(x, y) = \exp(-\gammaK \|x-y\|^2)$) for the following reasons:
\begin{enumerate}
    \item \textbf{Feature Disentanglement:} The RFE-selected features are already a robust, low-dimensional subset. A linear alignment of their first-order moments is sufficient and less prone to overfitting than the infinite-dimensional mapping of RBF.
    \item \textbf{Stability on Small Samples:} RBF kernels require tuning the bandwidth $\gammaK$, which is unstable on small cohorts ($N \approx 300$). An improper $\gammaK$ can lead to a degenerate Gram matrix.
    \item \textbf{Negative Transfer Avoidance:} Empirical tests showed that RBF-TCA often collapsed the TabPFN classifier to the majority class due to noise amplification in the high-dimensional RBF space.
\end{enumerate}
This ensures that PANDA benefits from domain alignment without succumbing to the instability often associated with kernel methods on small datasets.

\subsubsection{Parameter Sensitivity Diagnostics}
\label{sec:param_sensitivity}
To ensure the chosen defaults are numerically stable, the automated regression test suite exercises the same Adapt wrapper on the Mayo~$\rightarrow$~PKUPH split with stress configurations (letting Adapt infer \texttt{n\_components=None} and shrinking $\mu$ to $0.1$). The test reports $\accuracy$, $\auc$, $\fonescore$, $\precision$, and $\recall$ and asserts that the probabilities remain in $[0,1]$. Because both the production path and the test harness rely on the identical Adapt pipeline, these executions provide our practical parameter-sensitivity verification for PANDA.


\subsection{Experimental Configuration}
\label{subsec:experimental_config}

\subsubsection{Baseline Hyperparameters}
To ensure fair comparison, all baseline models were tuned using grid search within the ranges specified in Table~\ref{tab:hyperparams}. The \texttt{MLBaselineModel} class in \texttt{modeling/ml\_baseline\_models.py} manages these configurations.

\begin{table}[htbp]
\centering
\caption{Hyperparameter search space for baseline models. Best parameters were selected via 5-fold CV on the source domain.}
\label{tab:hyperparams}
\begin{tabular}{lll}
\toprule
\textbf{Model} & \textbf{Parameter} & \textbf{Search Space / Value} \\ \midrule
\multirow{3}{*}{XGBoost} & Learning Rate & [0.01, 0.05, 0.1] \\
 & Max Depth & [3, 4, 5, 6] \\
 & N Estimators & [50, 100, 200] \\ \midrule
\multirow{3}{*}{Random Forest} & N Estimators & [100, 200, 500] \\
 & Max Features & ['sqrt', 'log2'] \\
 & Class Weight & 'balanced' \\ \midrule
\multirow{2}{*}{SVM} & C (Regularization) & [0.1, 1, 10, 100] \\
 & Kernel & ['rbf', 'linear'] \\ \midrule
\multirow{1}{*}{Logistic Regression} & Penalty & ['l1', 'l2', 'elasticnet'] \\ \bottomrule
\end{tabular}
\end{table}

\subsubsection{Clinical Scoring Models}
We implemented three established clinical calculators for pulmonary nodule malignancy:
\begin{itemize}
    \item \textbf{Mayo Model}: $\text{Probability} = \activation(-6.8 + 0.039 \cdot \text{Age} + 0.79 \cdot \text{Smoker} + 1.33 \cdot \text{CancerHx} + \dots)$
    \item \textbf{Brock (PanCan) Model}: Includes spiculation and nodule count.
    \item \textbf{PKUPH Model}: A regression model specifically developed for Chinese populations \cite{perandini_solid_2016}.
\end{itemize}
These models are applied using their published coefficients without re-training, representing the standard of care.

\subsubsection{Computational Framework}
All experiments were conducted on a workstation equipped with:
\begin{itemize}
    \item \textbf{Hardware}: NVIDIA RTX 4090 GPU (24GB VRAM), AMD Ryzen 9 7950X CPU, 64GB DDR5 RAM.
    \item \textbf{Software}: PyTorch 2.1.2 (CUDA 12.1), Scikit-learn 1.3.2, Adapt 0.4.4.
\end{itemize}

\label{sec:meth-end}
