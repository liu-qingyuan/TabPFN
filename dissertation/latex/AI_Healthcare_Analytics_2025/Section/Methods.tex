\section{Methods}
\label{sec:methods}
\label{sec:meth-start}

\subsection{Motivating Challenges and Methodological Response}
Cross-hospital malignancy prediction and public-health surveillance generate intertwined constraints: tiny labeled cohorts, label imbalance, feature mismatch, and multiple forms of distribution shift. PANDA is organized around these constraints rather than around model novelty. Table~\ref{tab:challenge_mapping} distills the major obstacles and the mechanisms assigned to them.

\begin{table}[htbp]
  \centering
  \caption{Challenge--mechanism mapping in PANDA. Each component targets a known failure mode, and the same design is reused for pulmonary nodules and the TableShift BRFSS race-shift task.}
  \label{tab:challenge_mapping}
  \begin{tabular}{p{0.22\textwidth}p{0.32\textwidth}p{0.33\textwidth}}
    \toprule
    Challenge & Mechanism & Expected benefit \\ \midrule
    Small $n$ with high-dimensional covariates & TabPFN prior-data fitted network performs in-context learning with frozen weights & Transfers structural priors from millions of synthetic tasks, reducing estimation variance without local fine-tuning \\ 
    Feature heterogeneity across institutions/demographics & Cross-domain RFE surfaces stable subsets (``best7'', ``best8'') definable in every site, plus schema alignment utilities & Removes site-specific artefacts before adaptation and guarantees that downstream models only consume shared attributes \\ 
    Covariate shift and mixed acquisition protocols & TCA applied to RFE-selected features realigns marginal distributions before the TabPFN classifier & Shrinks the $d_{\mathcal{H}\Delta\mathcal{H}}$ divergence so that context examples remain relevant to target queries \\ 
    Label prevalence drift and class imbalance & Class-balanced sampling, calibrated decision thresholds, and ensemble temperature scaling & Maintains sensitivity for malignant/SPN-positive cohorts and accounts for higher diabetes rates in non-White BRFSS respondents \\ 
    Variance from preprocessing choices & Multi-branch preprocessing (ordering, quantile transforms, ordinal encoding) with ensemble averaging & Injects diversity without retraining new weights and stabilizes predictions under minor data perturbations \\ \bottomrule
  \end{tabular}
\end{table}

This architecture ensures that every component answers a crisp question: why do small-sample medical deployments fail, and what prior or alignment tool counters that failure?

\subsection{Feature Engineering and Selection Implementation}
\label{subsec:feature_engineering}

The feature engineering pipeline in PANDA is designed to handle the heterogeneity of medical data sources while preserving domain-invariant signals. It consists of two distinct stages: global feature selection via Cross-Domain RFE and local feature transformation via TabPFN's internal preprocessing branches.

\subsubsection{Cross-Domain Recursive Feature Elimination (RFE)}
\label{subsubsec:rfe_implementation}
To address the "feature mismatch" challenge, we implement a Cross-Domain Recursive Feature Elimination (RFE) strategy. Unlike standard RFE which optimizes for a single dataset, our approach seeks a feature subset $\mathcal{S}^*$ that maximizes predictive performance on the source domain $\mathcal{D}_s$ while satisfying availability constraints in the target domain $\mathcal{D}_t$.

The process, implemented in \texttt{predict\_healthcare\_RFE.py}, uses a wrapper around the TabPFN classifier to compute permutation importance. We define the importance of feature $j$ as the degradation in AUC when its values are randomly shuffled:
\begin{equation}
    I_j = \text{AUC}(\mathcal{D}_{\text{val}}) - \frac{1}{K} \sum_{k=1}^K \text{AUC}(\mathcal{D}_{\text{val}}^{(j, \text{shuffled})})
\end{equation}
where $K=5$ repeats. Algorithm~\ref{alg:cross_domain_rfe} details the iterative elimination process.

\begin{algorithm}[H]
\caption{Cross-Domain Recursive Feature Elimination (RFE)}
\label{alg:cross_domain_rfe}
\begin{algorithmic}[1]
\REQUIRE Source Data $X_s, y_s$, Target Schema $\mathcal{F}_t$, Target Feature Count $k_{\text{target}}$
\ENSURE Optimal Feature Subset $\mathcal{S}^*$
\STATE \textbf{Initialize:} $\mathcal{S} \leftarrow \text{features}(X_s) \cap \mathcal{F}_t$ \COMMENT{Intersect with target availability}
\WHILE{$|\mathcal{S}| > k_{\text{target}}$}
    \STATE Train TabPFN classifier $\mathcal{M}$ on $X_s[\mathcal{S}], y_s$
    \STATE Compute Permutation Importance vector $\mathbf{I} \in \mathbb{R}^{|\mathcal{S}|}$ using 5 repeats
    \STATE Identify feature with minimum importance: $f_{\text{min}} \leftarrow \arg\min_{f \in \mathcal{S}} \mathbf{I}[f]$
    \STATE $\mathcal{S} \leftarrow \mathcal{S} \setminus \{f_{\text{min}}\}$ \COMMENT{Eliminate weakest feature}
    \STATE Record performance metric $M_{|\mathcal{S}|}$ (AUC) via 10-fold CV
\ENDWHILE
\STATE \textbf{Select} $\mathcal{S}^*$ based on Cost-Effectiveness Index (CEI):
\STATE $\text{CEI}(k) = \frac{\text{AUC}_k - 0.5}{\text{Cost}_k}$ \COMMENT{Optional cost-aware selection}
\RETURN $\mathcal{S}^*$
\end{algorithmic}
\end{algorithm}

This algorithm produces the standard subsets referenced throughout the study: ``best7'' (Age, Spiculation, etc.) and ``best8''.

\subsubsection{Multi-Branch Preprocessing Strategy}
Once the feature set is fixed, PANDA leverages TabPFN's internal ensemble mechanism to handle distribution shifts in feature scaling and encoding. This is effectively a "test-time augmentation" for tabular data. The \texttt{EnsembleConfig} generates 32 distinct views of the data through four preprocessing pipelines:
\begin{enumerate}
    \item \textbf{No-Op Branch:} Raw features are passed directly, preserving original distributions (useful for tree-based logic).
    \item \textbf{Quantile Branch:} Features are transformed via $F^{-1}(\Phi(x))$, mapping the empirical CDF to a standard Normal $\mathcal{N}(0,1)$. This handles extreme outliers and skewed distributions common in medical markers (e.g., CEA levels).
    \item \textbf{Ordinal Branch:} All unique values are ranked and replaced by their integer rank. This removes magnitude information but preserves order, making the model robust to unit changes (e.g., cm vs mm).
    \item \textbf{Power Transform Branch:} Applies $x \mapsto x^\lambda$ (e.g., square root or log) to stabilize variance.
\end{enumerate}
Each branch is applied to both support (train) and query (test) sets simultaneously, ensuring consistent mapping.

\subsection{Foundation Model Integration Mechanism}
\label{subsec:foundation_model_integration}

PANDA utilizes TabPFN as a robust probabilistic classifier within an integrated framework. While TabPFN internally processes features, its role in PANDA is to provide final, confident predictions on adapted tabular data. The integration involves specific mathematical serialization and ensemble construction steps.

\subsubsection{In-Context Serialization and Tokenization}
Unlike BERT-style models that require text, TabPFN consumes raw numerical and categorical values. The serialization process, defined in \texttt{src/tabpfn/model/encoders.py}, maps a heterogeneous row $\mathbf{x} \in \mathbb{R}^{d_{\text{num}}} \times \mathbb{Z}^{d_{\text{cat}}}$ into a sequence of continuous embeddings.

For a numerical feature $x^{(j)}$, the embedding is a linear projection:
\begin{equation}
    \mathbf{e}^{(j)} = \mathbf{W}_{\text{num}}^{(j)} x^{(j)} + \mathbf{b}_{\text{num}}^{(j)}
\end{equation}
For a categorical feature with index $c$, we use a lookup table:
\begin{equation}
    \mathbf{e}^{(j)} = \text{EmbeddingMatrix}^{(j)}[c]
\end{equation}
Missing values are handled by a specialized learnable token $\mathbf{e}_{\text{nan}}$. The full sample embedding is the sum of feature embeddings plus a positional encoding:
\begin{equation}
    \mathbf{E}_{\text{sample}} = \text{MLP}(\text{Concat}(\mathbf{e}^{(1)}, \dots, \mathbf{e}^{(d)})) + \mathbf{P}_{\text{pos}}
\end{equation}
This allows the Transformer to attend to "patient A" vs "patient B" distinctively within the context window.

\subsubsection{Ensemble Construction and Inference}
The final prediction is an average over 32 diverse forward passes. Let $\mathcal{B} = \{P_1, \dots, P_4\}$ be the set of preprocessing functions and $\mathcal{S} = \{s_1, \dots, s_8\}$ be a set of random seeds that control the subsampling of the context set (the "support set" of labeled examples). The ensemble probability estimate is:

\begin{equation}
    \hat{P}(y=1|\mathbf{x}_q) = \frac{1}{32} \sum_{P \in \mathcal{B}} \sum_{s \in \mathcal{S}} \sigma\left( \frac{f_\theta(P(\mathbf{x}_q) \mid P(\mathbf{X}_{\text{ctx}}^s))}{T} \right)
\end{equation}

where:
\begin{itemize}
    \item $\mathbf{x}_q$ is the target query (patient).
    \item $\mathbf{X}_{\text{ctx}}^s$ is the subset of training data selected by seed $s$ (typically 1024 samples).
    \item $f_\theta$ is the frozen TabPFN Transformer backbone.
    \item $T=0.9$ is the temperature scaling parameter calibrated for small-sample confidence.
\end{itemize}

Algorithm~\ref{alg:tabpfn_inference} summarizes the inference pass.

\begin{algorithm}[H]
\caption{PANDA Inference with TabPFN Backbone}
\label{alg:tabpfn_inference}
\begin{algorithmic}[1]
\REQUIRE Query $\mathbf{x}_q$, Context $\mathcal{D}_{\text{train}}$, Ensemble $N=32$
\ENSURE Malignancy Probability $\hat{y}$
\STATE $\text{Logits} \leftarrow []$
\FOR{$i=1$ \TO $N$}
    \STATE Sample preprocessing $P \sim \mathcal{B}$ and context subset $\mathcal{D}_i \subset \mathcal{D}_{\text{train}}$
    \STATE $\mathbf{x}'_q, \mathcal{D}'_i \leftarrow P(\mathbf{x}_q), P(\mathcal{D}_i)$ \COMMENT{Apply Branch}
    \STATE $\mathbf{E} \leftarrow \text{Serialize}(\mathbf{x}'_q, \mathcal{D}'_i)$ \COMMENT{Tokenize}
    \STATE $\mathbf{z} \leftarrow \text{Transformer}(\mathbf{E})$ \COMMENT{Forward Pass}
    \STATE $l_i \leftarrow \text{ClassifierHead}(\mathbf{z})$
    \STATE $\text{Logits}.\text{append}(l_i)$
\ENDFOR
\STATE $\hat{y} \leftarrow \text{Softmax}(\text{Mean}(\text{Logits}) / T)$
\RETURN $\hat{y}$
\end{algorithmic}
\end{algorithm}

\subsection{Domain Adaptation Implementation}
\label{subsec:da_implementation}
We utilize the \texttt{adapt} library (v0.4.4) to implement Transfer Component Analysis (TCA) and baselines. The integration is handled by the \texttt{AdaptUDAMethod} wrapper in \texttt{uda/adapt\_methods.py}.

\subsubsection{Transfer Component Analysis (TCA)}
TCA is applied to the RFE-selected feature space. The core optimization problem is finding a projection matrix $\mathbf{W} \in \mathbb{R}^{k \times m}$ that minimizes the Maximum Mean Discrepancy (MMD) between source and target distributions while preserving data variance, where $k$ is the dimensionality after RFE.

\begin{equation}
    \min_{\mathbf{W}} \text{tr}(\mathbf{W}^\top \mathbf{K} \mathbf{L} \mathbf{K} \mathbf{W}) + \mu \text{tr}(\mathbf{W}^\top \mathbf{W})
\end{equation}
\begin{itemize}
    \item \textbf{Kernel Matrix $\mathbf{K}$}: We employ a linear kernel $\mathbf{K}_{ij} = \langle \mathbf{x}_i, \mathbf{x}_j \rangle$ on the RFE-selected features. Since the RFE process aims to identify a more robust and relevant feature subspace, a linear alignment in this space is often sufficient and computationally efficient.
    \item \textbf{MMD Matrix $\mathbf{L}$}: Constructed as $L_{ij} = \frac{1}{n_s^2}$ if $i,j \in S$, $\frac{1}{n_t^2}$ if $i,j \in T$, and $-\frac{1}{n_s n_t}$ otherwise.
    \item \textbf{Regularization $\mu$}: Fixed to 1.0 in the experiment configuration (refer to Section~\ref{sec:param_sensitivity}).
\end{itemize}

Concretely, the wrapper in \texttt{uda\_medical\_imbalance\_project/uda/adapt\_methods.py} instantiates \texttt{adapt.feature\_based.TCA} with the TabPFN classifier and the parameters defined in \texttt{config/experiment\_config.py}: $n_{\text{components}} = 10$, \(\mu = 1.0\), and a linear kernel. All experiments reported for PANDA reuse this exact instantiation.

 \textbf{Justification for Linear Kernel over RBF:}
We deliberately employ a linear kernel for TCA, defining the similarity between two RFE-selected feature vectors $\mathbf{x}_i, \mathbf{x}_j$ as:
\begin{equation}
    K_{\text{linear}}(\mathbf{x}_i, \mathbf{x}_j) = \mathbf{x}_i^\top \mathbf{x}_j
\end{equation}
This contrasts with the Radial Basis Function (RBF) kernel, which implicitly maps features into an infinite-dimensional space:
\begin{equation}
    K_{\text{RBF}}(\mathbf{x}_i, \mathbf{x}_j) = \exp(-\gamma \|\mathbf{x}_i - \mathbf{x}_j\|^2)
\end{equation}
where $\gamma$ is a critical bandwidth hyperparameter. Our choice of a linear kernel is motivated by several factors:
\begin{itemize}
    \item \textbf{Feature Disentanglement Post-RFE:} After Cross-Domain RFE (Stage 2), the feature space is significantly reduced to a small, clinically relevant, and relatively disentangled subset. In this refined space, a linear transformation is often sufficient to align the first-order moments of the distributions (i.e., mean shifts).
    \item \textbf{Robustness to Small Sample Sizes:} Medical datasets are inherently small ($n \approx 300$). RBF kernels introduce a critical hyperparameter $\gamma$, which is highly sensitive to the scale and distribution of data. Tuning $\gamma$ effectively on small, heterogeneous datasets is challenging and prone to overfitting. An ill-chosen $\gamma$ can lead to unstable Gram matrices (e.g., dominated by nearly zero or saturated entries), causing the TCA projection to become degenerate or to over-emphasize noise.
    \item \textbf{Avoiding Negative Transfer in High-Dimensional Implicit Spaces:} While RBF kernels can capture complex non-linear relationships, projecting small datasets into an implicitly high (or infinite) dimensional RBF kernel space can amplify noise and lead to negative transfer, where domain adaptation actually worsens performance. Empirically, deploying an RBF kernel in the \texttt{AdaptUDAMethod} often resulted in unstable projections, causing the downstream TabPFN classifier to collapse to predicting only the majority class.
    \item \textbf{Computational Efficiency and Interpretability:} Linear kernels are computationally more efficient than RBF kernels, especially for large matrices, which is beneficial for iterative experiments. Furthermore, the resulting linear projections are often more interpretable.
\end{itemize}
Thus, the linear kernel provides a robust, computationally stable, and sufficiently powerful mechanism for aligning marginal feature distributions in our small-sample, cross-hospital context.

\subsubsection{Parameter Sensitivity Diagnostics}
\label{sec:param_sensitivity}
The deployment code that ships with the project fixes the TCA settings through the configuration in \texttt{uda\_medical\_imbalance\_project/config/experiment\_config.py}: we call the Adapt wrapper with $n_{\text{components}}=10$, a linear kernel, and \(\mu=1.0\). These values are injected when the \texttt{AdaptUDAMethod} class instantiates \texttt{adapt.feature\_based.TCA} (see \texttt{uda/adapt\_methods.py}). To make sure the defaults are numerically stable, the automated regression test \texttt{tests/test\_adapt\_methods.py::TestAdaptMethods::test\_tca\_domain\_adaptation} replays the Mayo~$\rightarrow$~PKUPH split with two stress settings: letting Adapt infer the latent dimensionality (\texttt{n\_components=None}) and shrinking \(\mu\) to $0.1$. The test logs accuracy, AUC, F1, precision, and recall, and asserts that the resulting predictions stay in $[0,1]$. Because both the production configuration and the test harness run through the same Adapt pipeline, we treat those executions as the parameter-sensitivity check for PANDA.

\subsubsection{Baselines (SA and CORAL)}
For comparative analysis, we implemented:
\begin{itemize}
    \item \textbf{Subspace Alignment (SA)}: Learns a linear mapping function $M$ to align the PCA subspaces of source and target. Implemented via \texttt{adapt.feature\_based.SA}.
    \item \textbf{CORAL}: Minimizes the difference in second-order statistics (covariance matrices) between domains. Implemented via \texttt{adapt.feature\_based.CORAL} with $\lambda=1.0$.
\end{itemize}

\subsection{Experimental Configuration}
\label{subsec:experimental_config}

\subsubsection{Baseline Hyperparameters}
To ensure fair comparison, all baseline models were tuned using grid search within the ranges specified in Table~\ref{tab:hyperparams}. The \texttt{MLBaselineModel} class in \texttt{modeling/ml\_baseline\_models.py} manages these configurations.

\begin{table}[htbp]
\centering
\caption{Hyperparameter search space for baseline models. Best parameters were selected via 5-fold CV on the source domain.}
\label{tab:hyperparams}
\begin{tabular}{lll}
\toprule
\textbf{Model} & \textbf{Parameter} & \textbf{Search Space / Value} \\ \midrule
\multirow{3}{*}{XGBoost} & Learning Rate & [0.01, 0.05, 0.1] \\
 & Max Depth & [3, 4, 5, 6] \\
 & N Estimators & [50, 100, 200] \\ \midrule
\multirow{3}{*}{Random Forest} & N Estimators & [100, 200, 500] \\
 & Max Features & ['sqrt', 'log2'] \\
 & Class Weight & 'balanced' \\ \midrule
\multirow{2}{*}{SVM} & C (Regularization) & [0.1, 1, 10, 100] \\
 & Kernel & ['rbf', 'linear'] \\ \midrule
\multirow{1}{*}{Logistic Regression} & Penalty & ['l1', 'l2', 'elasticnet'] \\ \bottomrule
\end{tabular}
\end{table}

\subsubsection{Clinical Scoring Models}
We implemented three established clinical calculators for pulmonary nodule malignancy:
\begin{itemize}
    \item \textbf{Mayo Model}: $P = \sigma(-6.8 + 0.039 \cdot \text{Age} + 0.79 \cdot \text{Smoker} + 1.33 \cdot \text{CancerHx} + \dots)$
    \item \textbf{Brock (PanCan) Model}: Includes spiculation and nodule count.
    \item \textbf{PKUPH Model}: A regression model specifically developed for Chinese populations \cite{perandini_solid_2016}.
\end{itemize}
These models are applied using their published coefficients without re-training, representing the standard of care.

\subsubsection{Computational Framework}
All experiments were conducted on a workstation equipped with:
\begin{itemize}
    \item \textbf{Hardware}: NVIDIA RTX 4090 GPU (24GB VRAM), AMD Ryzen 9 7950X CPU, 64GB DDR5 RAM.
    \item \textbf{Software}: PyTorch 2.1.2 (CUDA 12.1), Scikit-learn 1.3.2, Adapt 0.4.4.
    \item \textbf{Reproducibility}: Random seeds for Numpy, PyTorch, and Scikit-learn were fixed to 42. Code is available at \texttt{https://github.com/PriorLabs/TabPFN}.
\end{itemize}

\label{sec:meth-end}
