\section{Problem Formulation}
\label{sec:problem-formulation}

Cross-hospital medical classification mixes distribution shift, sample scarcity, and feature heterogeneity. We cast it as an unsupervised domain adaptation (UDA) problem on structured clinical data: the goal is reliable prediction in a target hospital without target labels. The framing mirrors common deployment constraints in medical AI.

\subsection*{Cross-Domain Learning Setup}

We consider two cohorts from different institutions. The source domain is 
$\mathcal{D}_s=\{(\mathbf{x}_i^s, y_i^s)\}_{i=1}^{n_s}$ with labels; the target domain 
$\mathcal{D}_t=\{\mathbf{x}_j^t\}_{j=1}^{n_t}$ has only unlabeled records. Each sample $\mathbf{x}\in\mathbb{R}^d$ is a tabular feature vector and $y\in\{0,1\}$ denotes malignancy.

Institutional differences in populations and measurement protocols create both marginal and conditional shifts:
\[
P_s(\mathbf{x}) \neq P_t(\mathbf{x}), \qquad 
P_s(y|\mathbf{x}) \neq P_t(y|\mathbf{x}).
\]
Hospitals usually record only partially overlapping feature sets. Let 
$\mathcal{F}_s$ and $\mathcal{F}_t$ be the available indices, and 
$\mathcal{F}=\mathcal{F}_s\cap\mathcal{F}_t$ the shared subset with dimension $d'<d$. We assume the shared features hold enough discriminative information for prediction in the reduced space.

The aim is to learn a classifier $f:\mathcal{X}_{\mathcal{F}}\rightarrow\mathcal{Y}$ using 
$\mathcal{D}_s$ and unlabeled target samples so that the target risk
\[
\mathcal{R}_t(f)=\mathbb{E}_{(\mathbf{x},y)\sim P_t}[\ell(f(\mathbf{x}),y)]
\]
is minimized. This mirrors deployment settings where target labels cannot be shared because of privacy constraints.

\subsection*{Challenges in Cross-Institutional Learning}

Clinical tabular cohorts usually include only a few hundred labeled patients. For hypothesis classes on $d'$ shared features, estimation error scales as $\widetilde{O}(\sqrt{d'/n_s})$, making high-capacity models unreliable once $n_s \le 500$. Many UDA techniques implicitly bank on larger sample sizes than most hospitals can release.

Distributional mismatch compounds the limits. Under the standard domain adaptation bound
\[
\mathcal{R}_t(f) \le \mathcal{R}_s(f) + \frac{1}{2} d_{\mathcal{H}\Delta\mathcal{H}}(P_s,P_t) + \lambda,
\]
the divergence term dominates when variability is substantial--differences in CT scanners, assays, and patient populations. Partial feature overlap means source and target supports only partly coincide, straining assumptions behind kernel alignment and adversarial methods.

Deep neural networks face the same hurdle: effective dimension $d_{\mathrm{eff}}$ yields sample complexity $n_s = \Omega(d_{\mathrm{eff}}/\epsilon^2)$, leaving conventional representation learning under-specified in medical tabular contexts where $d'$ is modest but $n_s$ is tiny.
