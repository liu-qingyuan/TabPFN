\section{Conclusion}
\label{sec:concl-start}

\subsection{Summary of Contributions}

This dissertation introduces PANDA, a framework that connects pre-trained tabular foundation models to the practical constraints of medical tabular data, including small sample sizes, heterogeneous feature schemas, and distribution shifts. Experiments on private cross-hospital cohorts and public benchmarks show that:

\begin{enumerate}
\item \textbf{Foundation Models as Robust Priors}: The pre-trained TabPFN backbone substantially outperforms traditional baselines (Random Forest, XGBoost) on small datasets ($n < 300$) by exploiting priors learned from millions of synthetic tasks. This in-context learning capability provides a strong initialization that is more resistant to overfitting than standard empirical risk minimization.

\item \textbf{Stability via Selection}: The Cross-Domain Recursive Feature Elimination (RFE) protocol is essential for removing site-specific artifacts. By converging on a compact set of eight stable predictors, it reduces the dimensionality of the adaptation problem and enables linear alignment methods to succeed where non-linear approaches fail.

\item \textbf{Latent Space Alignment}: Transfer Component Analysis (TCA) applied in the Transformer embedding space effectively reduces the Maximum Mean Discrepancy (MMD) between domains. This alignment yields a consistent performance gain (AUC +0.007) and, more importantly, improves calibration in the target domain.
\end{enumerate}

\subsection{Limitations}

Although PANDA advances the state of the art, several limitations remain.

\subsubsection{Closed-World Assumption}

PANDA assumes that the source and target domains share a common feature schema given by their intersection. It does not address open-world shifts in which the target domain introduces entirely new, highly predictive features that are absent in the source. For example, if a new hospital collects a molecular biomarker (such as DNA methylation) that is not available in the training cohort, PANDA cannot exploit this information without retraining. This lowest-common-denominator strategy in feature selection promotes stability but may limit performance relative to models trained on richer, site-specific schemas.

\subsubsection{Missing Data Mechanisms}

The current implementation of PANDA uses a complete-case strategy: it removes samples with missing values before downstream preprocessing and modeling. Consequently, the core framework does not rely on explicit imputation. This approach implicitly assumes that the retained cohort remains representative under Missing Completely At Random (MCAR) or, more weakly, Missing At Random (MAR). The \texttt{best8} feature set was selected partly for its high completeness, which reduces the number of excluded cases.

However, clinical data are often Missing Not At Random (MNAR); for instance, a clinician may not order a test because they believe the patient is either too healthy or too sick. Under such informative missingness, complete-case filtering may introduce selection bias and limit the generalizability of the current results. Future extensions of PANDA could incorporate missingness indicators or explicitly model informative missingness to better address MNAR settings.

\subsubsection{Computational Resource Requirements}

In contrast to decision trees, which can run on embedded central processing units, TabPFN requires a graphical processing unit for efficient inference (approximately 20 ms per patient). While this cost is negligible for a cloud-based service, it creates a barrier to deployment on edge devices, such as older hospital workstations without dedicated hardware acceleration. The $O(N^2)$ complexity of the Transformer attention mechanism also limits the context size and necessitates subsampling strategies for larger datasets such as BRFSS.

\subsubsection{Scope of Distribution Shift in the Pulmonary Experiment}

While PANDA is in principle applicable under label shift, our cross-hospital pulmonary nodule experiment is not a canonical low-prevalence screening setting. The internal cohorts are enriched case-control datasets with higher malignancy rates (around 65\%), and the dominant sources of shift are covariate and concept differences between hospitals. Label-shift robustness is instead assessed on the TableShift BRFSS Diabetes benchmark. Future work could incorporate additional screening cohorts with realistic prevalences to further stress-test PANDA under extreme label imbalance.

\subsection{Future Directions}

\subsubsection{Federated Domain Adaptation}

Privacy regulations (such as GDPR and HIPAA) often prevent the centralization of medical data. A natural extension of PANDA is federated domain adaptation, in which the feature extractor (TabPFN) remains frozen and shared, while the alignment matrix (TCA) is learned through secure multi-party computation. Because TCA only requires second-order statistics (covariance matrices), participating hospitals can aggregate these sufficient statistics without sharing patient-level records.

\subsubsection{Multimodal Integration}

Pulmonary nodule diagnosis inherently combines imaging (computed tomography scans) with clinical data. Future work should investigate a multimodal variant of PANDA that aligns tabular embeddings from TabPFN with visual embeddings from a convolutional neural network or Vision Transformer. A cross-attention mechanism could then weight the relative contributions of clinical history and radiological appearance in a domain-aware manner, placing greater emphasis on the modality that remains stable when the other is affected by artifacts.

\subsection{Final Remarks}

The deployment gap in medical AI seldom arises from a lack of sophisticated architectures; it more often results from a failure to accommodate the noisy and shifted nature of real-world data. PANDA provides a pragmatic blueprint for this challenge: \textit{do not learn everything from scratch, select only what is stable, and align what remains}. By treating pre-trained representations as portable priors and statistical alignment as a safety mechanism, this framework moves the field closer to reliable cross-institutional AI systems that can safely scale beyond their initial training sites.

\label{sec:concl-end}
