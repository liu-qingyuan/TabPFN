\section{Solution}
\label{sec:solution}

To bridge the gap between advanced tabular foundation models and the practical constraints outlined in Section~\ref{sec:problem-constraints}---small sample sizes, heterogeneous feature schemas, distribution shifts, and privacy-preserving data silos---we propose PANDA (Pretrained Adaptation Network with Domain Alignment). PANDA is a composite algorithmic framework designed to predict pulmonary nodule malignancy with high stability across heterogeneous clinical environments. It explicitly addresses the tripartite challenge of small-sample scarcity, distribution shift, and feature heterogeneity through a tightly integrated pipeline that combines cross-domain feature selection, schema alignment, latent-space adaptation, and a calibrated foundation-model ensemble.

Formally, PANDA implements a composite mapping

which transforms raw, heterogeneous clinical inputs into a calibrated malignancy probability. Building on the notation introduced in Section~\ref{sec:problem-formulation}, we factorize this mapping as

where $\pi_{\text{RFE}}$ performs cross-domain feature selection, $\pi_{\cap}$ enforces a robust schema intersection across hospitals, $\psi$ denotes latent-space domain adaptation, and $h$ is a calibrated foundation-model classifier.

\subsection{Architectural Overview}
\label{sec:solution-architecture}

The PANDA framework operates as a directed acyclic graph (DAG) of data transformations that progressively refine the representation of each patient from raw features to domain-invariant embeddings and, finally, to a calibrated risk estimate. Table~\ref{tab:data-flow} summarizes this data flow, while Figure~\ref{fig:model_details} provides a comprehensive visual overview of the architecture. Conceptually, the pipeline consists of four sequential stages:

\begin{table}[htbp]
    \centering
    \caption{Data flow and transformations in the PANDA framework. The pipeline progressively refines raw, high-dimensional inputs into low-dimensional, domain-invariant embeddings and, ultimately, a calibrated probability. In the pulmonary nodule experiments, $k = 8$, $d_{\cap} = 8$, and $m = 15$, but these dimensions are dataset-dependent.}
    \label{tab:data-flow}
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{lllll}
            \toprule
            \textbf{Stage} & \textbf{Component} & \textbf{Input Space} & \textbf{Core Operation} & \textbf{Output Space} \\
            \midrule
            1 & Cross-Domain RFE & $\mathbb{R}^{\rawdim}$ & Iterative elimination via $\rfeimportance(\func)$ & $\mathbb{R}^{k}$ ($\rfeselectedfeatures$, $k = |\rfeselectedfeatures|$) \\
            2 & Feature Alignment & $\mathbb{R}^{k}$ & Schema intersection on $\sharedfeatures$ & $\mathbb{R}^{d_{\cap}}$ ($d_{\cap} = |\sharedfeatures|$) \\
            3 & Latent TCA & $\mathbb{R}^{d_{\cap}}$ & Projection $\featurevec' = \tcaprojectionmatrix^\top \featurevec$ & $\mathbb{R}^{m}$ ($m$ = latent dimension) \\
            4 & TabPFN Classifier & $\mathbb{R}^{m}$ & Classification $\tabpfnfunc(\featurevec')$ & $[0, 1]$ (Prob.) \\
            5 & Ensemble & $[0, 1]^{\numpreprocessbranches \times \numrandomseeds}$ & Temperature-scaled averaging & $[0, 1]$ (Final) \\
            \bottomrule
        \end{tabular}%
    }
\end{table}

\begin{enumerate}
\item \textbf{Domain-Aware Feature Selection and Alignment}: PANDA first applies Cross-Domain Recursive Feature Elimination (RFE) to identify a compact, clinically meaningful subset of predictors that are stable across hospitals. It then intersects this subset with the feature schema available at each target site, yielding a site-specific, yet harmonized, feature space. This dual step reduces dimensionality, filters site-specific artifacts, and mitigates ``missingness shift'' by propagating only universally available variables.

\item \textbf{Latent-Space Domain Adaptation}: On the aligned feature space, PANDA applies Transfer Component Analysis (TCA) to project data into a lower-dimensional, domain-invariant latent space. The projection is learned to minimize a Maximum Mean Discrepancy (MMD) objective between source and target distributions, thereby addressing covariate shift while preserving task-relevant structure.

\item \textbf{Foundation-Model Inference}: The TCA-transformed features are then processed by a pre-trained TabPFN classifier. Rather than training a deep network from scratch on small clinical cohorts, PANDA reuses the prior-data-fitted structure of TabPFN, which encodes priors learned from millions of synthetic tasks and can infer complex non-linear decision boundaries without extensive gradient-based fine-tuning.

\item \textbf{Multi-View Ensemble and Calibration}: To further mitigate variance induced by small sample sizes and label shift, PANDA constructs a multi-branch ensemble that exposes the foundation model to diverse yet consistent views of the same patient. Branches differ in preprocessing (e.g., raw, quantile-normalized, ordinal, and power-transformed representations), and multiple random seeds are used to induce rotational invariance in the feature ordering. The resulting ensemble predictions are then temperature-scaled and averaged to yield a final, well-calibrated malignancy probability.

\end{enumerate}

This architectural decomposition provides a clear separation of concerns: RFE and schema intersection handle feature heterogeneity and data silos; TCA focuses on distribution alignment; TabPFN contributes strong priors for small-sample learning; and the multi-view ensemble targets robustness and calibration. The complete end-to-end pipeline, including the multi-branch ensemble configuration and temperature scaling mechanism, is illustrated in Figure~\ref{fig:model_details}.

\subsection{Mapping to the Formal Problem Formulation}
\label{sec:solution-mapping}

The four-stage architecture described above directly instantiates the formal problem setup of Section~\ref{sec:problem-formulation}. Specifically:
\begin{itemize}
\item \textbf{Cross-Domain RFE} implements the operator $\pi_{\text{RFE}}$, reducing the original high-dimensional space $\mathbb{R}^{d_{\text{raw}}}$ to a compact set of clinically actionable features $F^{\ast}$ of size $k = |F^{\ast}|$. The selection objective jointly balances discriminative performance, stability across folds, computational efficiency, and parsimony.
\item \textbf{Feature Alignment} implements $\pi_{\cap}$, mapping site-specific feature sets to a shared schema $F_{\cap}$ of dimension $d_{\cap} = |F_{\cap}|$, thereby ensuring that source and target hospitals operate on a common representation despite differing EHR schemas.
\item \textbf{Latent TCA} implements $\psi$, projecting the aligned features into a latent space $\mathbb{R}^{m}$ in which the empirical MMD between source and target distributions is minimized, directly tackling the covariate-shift component of the generalization bound.
\item \textbf{Foundation-Model Ensemble} implements $h$, mapping latent representations to calibrated probabilities through a TabPFN-based classifier composed with a multi-branch, temperature-scaled ensemble.
\end{itemize}

By making this mapping explicit, PANDA connects the abstract components of the theoretical formulation to concrete algorithmic steps, allowing each design choice to be interpreted in terms of the underlying constraints on sample size, privacy, imbalance, and distribution shift.

\subsection{Pointers to Implementation Details}
\label{sec:solution-pointers}

The subsequent Methods chapter provides the implementation-level details that instantiate each component of the PANDA architecture:

\begin{itemize}
\item Section~\ref{sec:methods-rfe} formalizes the Cross-Domain RFE procedure and the Cost-Effectiveness Index used to select the ``Best-$k$'' feature subset.
\item Section~\ref{sec:methods-tca} details the TCA objective, kernel construction, and choice of regularization for latent-space alignment.
\item Section~\ref{sec:methods-tabpfn} describes how PANDA integrates TabPFN as a probabilistic classifier, including in-context serialization of tabular inputs.
\item Section~\ref{sec:methods-ensemble} specifies the multi-branch preprocessing strategy, ensemble configuration, and temperature-scaling procedure used for final calibration.
\end{itemize}

This separation keeps the Solution chapter focused on the high-level design of PANDA, while deferring technical derivations and algorithmic variants to the dedicated methodological sections.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{img/cross_hospital/Pre-trained Tabular Foundation Mode Pipeline_new.pdf}
    \caption{\textbf{PANDA framework architecture.}
    (a) Compositional pipeline from original tabular data through ensemble training, prediction aggregation, class-imbalance adjustment, and final classification output.
    (b) Multi-branch ensemble with $\numpreprocessbranches=4$ preprocessing strategies, each generating $\numrandomseeds=8$ ensemble members via different random seeds.}
    \label{fig:model_details}
\end{figure}
\label{sec:sol-end}