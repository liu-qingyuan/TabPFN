\documentclass[10pt,aspectratio=169]{beamer}
\usepackage{poly}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{booktabs}

%==============================
% Basic Info
%==============================
\title{Transforming Diagnosis through Advanced Machine Learning and Data Analytics}
\subtitle{PANDA: Domain Adaptation with Pre-trained Tabular Foundation Model and TCA Alignment}
\author{Qingyuan Liu}
\institute[PolyU]{Department of Computing, The Hong Kong Polytechnic University}
\date{December 11, 2025}

\begin{document}

%==============================
% Title
%==============================
\maketitle

%==============================
\section{Background and Motivation}
%==============================

\begin{frame}{Clinical: Pulmonary Nodules}
\begin{itemize}
    \item Low-dose CT (LDCT) lowers lung-cancer mortality in high-risk populations.
    \item Small pulmonary nodules (sPN) are uncertain; \textbf{reliable malignancy risk scores} are needed for decisions.
    \item Existing clinical risk models (Mayo, PKUPH, etc.) are site-dependent:
    \begin{itemize}
        \item Good internal performance at the development site;
        \item Significant drop during cross-hospital external validation.
    \end{itemize}
    \item Deployment challenge: \textbf{cross-hospital distribution shift + few-shot data + feature heterogeneity}.
\end{itemize}
\end{frame}

\begin{frame}{AI: Cross-Hospital/Population}
\begin{itemize}
    \item Medical tabular data often face:
    \begin{itemize}
        \item Limited sample size and class imbalance;
        \item Feature definitions, panels, and units vary across hospitals;
        \item Collection workflow and screening strategy change distributions and priors.
    \end{itemize}
    \item Classical trees and deep tabular models:
    \begin{itemize}
        \item Sensitive to few-shot data and prone to overfitting;
        \item Unstable generalization under domain shift.
    \end{itemize}
    \item Need a \textbf{lightweight, interpretable, reusable} cross-domain tabular diagnosis framework.
\end{itemize}
\end{frame}

%==============================
\section{Problem Definition}
%==============================

\begin{frame}{Problem: Cross-Hospital Prediction}
\begin{itemize}
    \item Goal: predict malignancy risk $Y \in \{0,1\}$.
    \item Source (Hospital A): labeled, few-shot clinical tabular data.
    \item Target (Hospital B): \textbf{unlabeled during training}, used only for alignment.
    \item Key challenges:
    \begin{itemize}
        \item Small sample size and high variance;
        \item Class imbalance;
        \item Feature heterogeneity: $F^S \neq F^T$;
        \item Distribution shift: standards, patient mix, workflows differ.
    \end{itemize}
    \item Viewpoint: \textbf{unsupervised domain adaptation (UDA)} for cross-center risk prediction.
\end{itemize}
\end{frame}

\begin{frame}{Design Principles}
\begin{itemize}
    \item Target-domain error decomposes into:
    \begin{itemize}
        \item Source learnability (source risk);
        \item Cross-domain divergence;
        \item Adaptability/shared structure.
    \end{itemize}
    \item Strategies:
    \begin{itemize}
        \item Use a \textbf{pre-trained tabular foundation model} to stabilize few-shot learning;
        \item Use \textbf{statistical alignment} to shrink domain gaps;
        \item Use \textbf{cross-domain stable feature selection} to reduce negative transfer.
    \end{itemize}
\end{itemize}
\end{frame}

%==============================
\section{Core Idea and Contributions}
%==============================

\begin{frame}{PANDA Core Idea}
\begin{itemize}
    \item PANDA = \textbf{``stable feature selection + distribution alignment + pre-trained model prediction''}.
    \item Build a robust risk mapping in the shared feature space across hospitals.
    \item Lightweight statistical alignment bridges real clinical settings and tabular foundation model capacity.
    \item Designed for deployable cross-center decision support.
\end{itemize}
\end{frame}

\begin{frame}{Main Contributions}
\begin{itemize}
    \item Propose PANDA: a UDA framework combining \textbf{cross-domain RFE, TCA alignment, and TabPFN}.
    \item Design cross-domain stable feature selection to obtain a compact shared feature set.
    \item Validate cross-hospital gains on lung nodule cohorts from two cancer centers.
    \item Validate cross-population robustness on the TableShift BRFSS Diabetes task.
    \item Provide a reusable implementation and analysis recipe linking theory and deployment needs.
\end{itemize}
\end{frame}

%==============================
\section{Method: PANDA Framework}
%==============================

\begin{frame}{PANDA Formulation}
\begin{itemize}
    \item Composite function:
    \[
    f_{\text{PANDA}}(\mathbf{x}) = h \circ \psi \circ \pi_{\cap} \circ \pi_{\text{RFE}}(\mathbf{x})
    \]
    \item $\pi_{\text{RFE}}$: cross-domain RFE selects discriminative subset $\mathcal{F}^\ast$.
    \item $\pi_{\cap}$: enforce source/target schema intersection to ensure usability.
    \item $\psi$: TCA aligns domains and reduces distribution shift.
    \item $h$: TabPFN ensemble + temperature calibration yields robust probabilities.
\end{itemize}
\end{frame}

\begin{frame}{PANDA Pipeline}
\begin{figure}
    \centering
    \includegraphics[width=0.37\linewidth]{img/cross_hospital/Pre-trained Tabular Foundation Mode Pipeline_new.pdf}
    \caption{Pre-trained Tabular Foundation Model pipeline}
    \label{fig:panda-pipeline}
\end{figure}
\end{frame}

\begin{frame}{PANDA Pipeline}
\begin{figure}
    \centering
    \includegraphics[width=0.6\linewidth]{img/cross_hospital/Feature Selection and UDA.pdf}
    \caption{Feature selection and UDA}
    \label{fig:panda-pipeline}
\end{figure}
\end{frame}

\begin{frame}{Stage 1: Cross-Domain RFE ($\pi_{\text{RFE}}$)}
\begin{itemize}
    \item Goal: learn feature subset $\mathcal{F}^\ast$ such that it is
    \begin{itemize}
        \item \textbf{available in the target hospital schema}, and
        \item \textbf{highly discriminative in the source domain}.
    \end{itemize}
    \item TabPFN-based permutation importance scores features via source cross-validation.
    \begin{itemize}
        \item Candidate subset size $k \in [k_{\min}, k_{\max}]$;
        \item \textbf{Composite Evaluation Index (CEI)} balances discriminativeness, compute, fold stability, and sparsity; CEI is to prevent overfitting to AUC in the small-sample unstable regime, not to complicate the selection;
        \item Choose $k^\ast$ maximizing CEI to obtain $\mathcal{F}^\ast$ (here $|\mathcal{F}^\ast|=9$).
    \end{itemize}
    \item Implementation details and CEI components in paper Section 5.2.1.
\end{itemize}
\end{frame}

\begin{frame}{Stage 1: CEI Illustration}
\begin{figure}
    \centering
    \includegraphics[width=0.45\linewidth]{img/cross_hospital/feature_performance_comparison_comprehensive.pdf}
    \caption{CEI balances discriminativeness, compute, stability, and sparsity to avoid overfitting to AUC in the small-sample regime.}
\end{figure}
\end{frame}

\begin{frame}{Stage 2: Feature Alignment ($\pi_{\cap}$)}
\begin{itemize}
    \item RFE yields $|\mathcal{F}^\ast| = 9$, but target lacks one feature:
    \[
        \mathcal{F}_{\cap} = \mathcal{F}^\ast \cap \mathcal{F}^T
    \]
    \item Dimensionality shrinks from 9 to 8, explicitly handling biomarkers absent at the target site.
    \item Ensures alignment and classification operate on the \textbf{clinically available shared subspace}.
\end{itemize}
\end{frame}

\begin{frame}{Stage 3: Domain Mapping ($\psi$, TCA)}
\begin{itemize}
    \item Aligned features $\mathcal{F}_{\cap}$ are fed to TCA to learn a linear map:
    \[
        \mathbf{x}' = \psi(\mathbf{x}; \mathcal{F}_{\cap}) = \mathbf{W}^\top \mathbf{x}
    \]
    \item Minimize MMD between source/target in a linear-kernel RKHS, \textbf{reducing $\mathcal{H}\Delta\mathcal{H}$-divergence}.
    \begin{itemize}
    \item \textbf{RKHS}: feature space defined by a kernel, turning nonlinear relations into high-dimensional linear separability.
    \item \textbf{MMD}: statistical distance comparing mean embeddings of source and target in RKHS.
    \item \textbf{$\mathcal{H}\Delta\mathcal{H}$-divergence}: separability measure in domain adaptation, capturing how easily hypotheses distinguish domains.
    \item Intuition: \textbf{smaller MMD} $\Rightarrow$ closer representations, \textbf{helping reduce domain separability} and \textbf{mitigating} $\mathcal{H}\Delta\mathcal{H}$-divergence.
    \item $\mathbf{W}$ is optimized with variance preservation constraints;
    \item Unlabeled target data participates in alignment, matching privacy/label-scarce settings.
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Stage 4: Classification and Ensemble ($h$, TabPFN)}
\begin{itemize}
    \item Adapted features $\mathbf{x}'$ are classified via TabPFN ensemble:
    \[
        h(\mathbf{x}') = \frac{1}{N} \sum_{i=1}^{N} \sigma\!\left(\frac{f_i^{\text{TabPFN}}(\mathbf{x}')}{\tau}\right)
    \]
    \item Temperature $\tau$ calibrates prevalence differences between hospitals.
    \item Ensembling smooths uncertainty and improves robustness to covariate/concept shift.
    \item PANDA is evaluated on:
    \begin{itemize}
        \item Lung nodules: primarily covariate and concept shift;
        \item TableShift Diabetes: explicit label shift/prevalence differences.
    \end{itemize}
\end{itemize}
\end{frame}

%==============================
\section{Datasets and Experimental Setup}
%==============================

\begin{frame}{Dataset 1: Cross-Hospital Lung Nodule Cohort}
\begin{itemize}
    \item Task: predict lung nodule malignancy risk (structured clinical tables).
    \item Source Hospital A vs target Hospital B.
    \item Features:
    \begin{itemize}
        \item Demographics, labs, semantic imaging/curated clinical features;
        \item Missingness and panel differences require the shared schema.
    \end{itemize}
    \item Sample size and class ratio: \textbf{see paper tables}.
\end{itemize}

% Insert cohort summary table if needed
% \includegraphics[width=0.8\textwidth]{tab_cohort_summary.pdf}
\end{frame}

\begin{frame}{Dataset 1: Cohort Summary}
\begingroup
\scriptsize
\setlength{\tabcolsep}{3pt}
\renewcommand{\arraystretch}{0.85}
\begin{table}[htbp]
\centering
\caption{Training (Cohort A) and testing (Cohort B).}
\label{tab:cohort_summary}
\resizebox{0.9\linewidth}{!}{%
\begin{tabular}{p{0.42\linewidth}p{0.25\linewidth}p{0.25\linewidth}}
\toprule
\textbf{Characteristic} & \textbf{Cohort A (n = 295)} & \textbf{Cohort B (n = 190)} \\
\midrule
Upper lobe & & \\
\quad Yes/Positive & 121 (41.0\%) & 98 (51.6\%) \\
\quad No/Negative & 174 (59.0\%) & 92 (48.4\%) \\
Age (years) & 56.95 $\pm$ 11.03 & 58.26 $\pm$ 9.57 \\
Lobe location (upper) & & \\
\quad Category 1 & 161 (54.6\%) & 98 (51.6\%) \\
\quad Category 2 & 29 (9.8\%) & 18 (9.5\%) \\
\quad Category 3 & 105 (35.6\%) & 74 (38.9\%) \\
DLCO1 & 5.90 $\pm$ 2.89 & 6.31 $\pm$ 1.55 \\
VC & 3.33 $\pm$ 0.80 & 2.92 $\pm$ 0.73 \\
CEA & 4.23 $\pm$ 6.90 & 4.15 $\pm$ 10.61 \\
Outcome (Malignant) & & \\
\quad Yes/Positive & 189 (64.1\%) & 125 (65.8\%) \\
\quad No/Negative & 106 (35.9\%) & 65 (34.2\%) \\
\bottomrule
\end{tabular}}
\end{table}
\endgroup
\end{frame}

\begin{frame}{Dataset 2: TableShift BRFSS Diabetes}
\begin{itemize}
    \item Public benchmark: BRFSS Diabetes (TableShift).
    \item Train/test split:
    \begin{itemize}
        \item ID: White respondents;
        \item OOD: non-White respondents.
    \end{itemize}
    \item Shift type: \textbf{race-driven population shift}.
    \item Goal: test PANDA robustness under \textbf{cross-population} shifts.
\end{itemize}

% Insert task illustration table/figure if needed
\end{frame}

\begin{frame}{Dataset 2: Cohort Summary}
\begin{table}[htbp]
\centering
\scriptsize
\caption{Source (ID) vs target (OOD) cohorts for the BRFSS Diabetes race shift.}
\label{tab:tableshift_cohort_summary}
\resizebox{\linewidth}{!}{%
\begin{tabular}{p{0.33\linewidth}p{0.29\linewidth}p{0.29\linewidth}}
\toprule
\textbf{Characteristic} & \textbf{Source / ID (PRACE1 = 1)} & \textbf{Target / OOD (PRACE1 $\in \{2,\dots,6\}$)} \\
\midrule
Sample size (full) & Train 969{,}229; Val 121{,}154; Test 121{,}154 & Val 23{,}264; Test 209{,}375 \\
Diabetes positive rate & 12.5\% (train) & 17.4\% (ood\_test) \\
Years & 2015: 245{,}675; 2016: 5{,}789; 2017: 244{,}996; 2018: 6{,}403; 2019: 221{,}847; 2020: 9{,}630; 2021: 223{,}088; 2022: 11{,}801 & 2015: 49{,}216; 2016: 1{,}507; 2017: 52{,}150; 2018: 1{,}424; 2019: 48{,}012; 2020: 3{,}147; 2021: 50{,}595; 2022: 3{,}324 \\
Domain shift variable & PRACE1 = 1 (non-Hispanic White) & PRACE1 $\in \{2,3,4,5,6\}$ (other races) \\
Modeling sample (seed 42) & 1{,}024 sampled for training & 2{,}048 sampled for evaluation \\
Sampled diabetes rate & 13.2\% & 17.3\% \\
Sampled pos / neg counts & 135 / 889 & 355 / 1{,}693 \\
Sampled years (seed 42) & 2015: 245; 2016: 8; 2017: 278; 2018: 2; 2019: 232; 2020: 7; 2021: 241; 2022: 11 & 2015: 497; 2016: 17; 2017: 488; 2018: 17; 2019: 445; 2020: 30; 2021: 525; 2022: 29 \\
\bottomrule
\end{tabular}}
\end{table}
\end{frame}

\begin{frame}{Protocol and Implementation Highlights}
\begin{itemize}
    \item Source domain: cross-validation for internal performance.
    \item Target domain:
    \begin{itemize}
        \item Unlabeled during training (UDA setup);
        \item Used for external/OOD evaluation at test time.
    \end{itemize}
    \item Key modules:
    \begin{itemize}
        \item Stability-aware RFE;
        \item Kernel-space alignment via TCA;
        \item TabPFN ensemble prediction and calibration.
    \end{itemize}
\end{itemize}
\end{frame}

%==============================
\section{Baselines and Metrics}
%==============================

\begin{frame}{Baselines}
\begin{itemize}
    \item Clinical scores:
    \begin{itemize}
        \item Mayo, PKUPH, and other traditional risk models.
    \end{itemize}
    \item Classical machine learning:
    \begin{itemize}
        \item Logistic/LASSO, SVM;
        \item Random Forest, GBDT, XGBoost, and other tree ensembles.
    \end{itemize}
    \item PANDA variants:
    \begin{itemize}
        \item TabPFN-only (with RFE, without TCA alignment);
        \item PANDA (RFE + TCA + TabPFN, full pipeline).
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Evaluation Metrics}
\begin{itemize}
    \item Classification and clinical metrics:
    \[
        \text{Accuracy} = \frac{TP + TN}{TP+TN+FP+FN},\quad
        \text{Precision} = \frac{TP}{TP+FP}
    \]
    \[
        \text{Recall} = \frac{TP}{TP+FN},\quad
        \text{F1} = \frac{2 \cdot \text{Prec} \cdot \text{Rec}}
        {\text{Prec} + \text{Rec}}
    \]
    \item AUC:
    \[
        \text{AUC} = \int_{0}^{1} \text{TPR}(\tau)\, d\,\text{FPR}(\tau),
        \quad \text{TPR}=\tfrac{TP}{TP+FN},\ \text{FPR}=\tfrac{FP}{FP+TN}
    \]
\end{itemize}
\end{frame}

\begin{frame}{Calibration and Decision Curves}
\begin{itemize}
    \item Calibration: binning $\hat{p}$ vs. observed frequency; closer to diagonal implies better probability reliability; deviation means over/under-estimation.
    \item DCA: net benefit
    \[
        \text{NB}(\tau) = \frac{TP(\tau)}{n} - \frac{FP(\tau)}{n} \cdot \frac{\tau}{1-\tau}
    \]
    \item Reference: Treat-all $\text{NB}_{\text{all}}(\tau)$ and treat-none (0); higher curves over wider thresholds imply better clinical utility.
    \item Reading guide: calibration focuses on diagonal closeness; DCA on area/height above baselines; choose thresholds prioritizing external sensitivity.
\end{itemize}
\end{frame}

%==============================
\section{Results}
%==============================

\begin{frame}{Experiment 1: Lung Nodules (Cross-Hospital UDA)}
\begin{itemize}
    \item Cross-hospital UDA (Cohort A $\rightarrow$ Cohort B) with feature heterogeneity and shift.
    \item PANDA (RFE+TCA+TabPFN): external AUC 0.7046, Recall 0.9440; internal 10-fold AUC 0.8287.
    \item TabPFN-only (with RFE, without TCA): external AUC 0.6980, Recall 0.8880.
    \item Clinical/tree baselines mostly have cross-domain AUC < 0.65 with large recall drop.
\end{itemize}
\end{frame}

\begin{frame}{Experiment 1: Aggregate Analysis}
\begin{figure}
    \centering
    \includegraphics[width=0.42\linewidth]{img/cross_hospital/combined_analysis_figure.pdf}
    \caption{\textbf{Performance and utility across source/target.} \textbf{a,b} ROC (Cohort A/B); \textbf{c,d} calibration; \textbf{e,f} decision curves highlighting TCA gains in external sensitivity and net benefit.}
\end{figure}
\end{frame}

\begin{frame}{Experiment 1: Heatmaps}
\begin{figure}
    \centering
    \includegraphics[width=0.35\linewidth]{img/cross_hospital/combined_heatmaps_nature.pdf}
    \caption{\textbf{Performance comparison across domains.} \textbf{a} Source 10-fold heatmap; \textbf{b} external validation heatmap showing PANDA+TCA leading on AUC/Recall.}
\end{figure}
\end{frame}

\begin{frame}{Experiment 2: TableShift BRFSS Diabetes (Cross-Population OOD)}
\begin{itemize}
    \item Cross-population OOD (White $\rightarrow$ Non-White).
    \item PANDA + TCA: OOD AUC 0.804, nearly matching ID AUC 0.802.
    \item TabPFN-only remains stable; classical trees drop more on OOD.
    \item Shows PANDA is \textbf{transferable and reproducible} on a public benchmark.
\end{itemize}
\end{frame}

\begin{frame}{Experiment 2: ROC/Calibration/Decision Curves}
    \begin{figure}
        \centering
        \includegraphics[width=0.42\linewidth]{img/tableshift/combined_analysis_figure.pdf}
        \caption{\textbf{TableShift BRFSS Diabetes analysis.} \textbf{a,b} ROC; \textbf{c,d} calibration; \textbf{e,f} decision curves showing robustness under race-driven shifts.}
    \end{figure}
    \end{frame}

\begin{frame}{Experiment 2: Heatmaps}
\begin{figure}
    \centering
    \includegraphics[width=0.35\linewidth]{img/tableshift/combined_heatmaps_nature.pdf}
    \caption{\textbf{Performance comparison on TableShift.} Multi-metric heatmaps across train/race splits, with PANDA+TCA staying stable.}
\end{figure}
\end{frame}

%==============================
\section{Discussion and Conclusion}
%==============================

\begin{frame}{Discussion: Strengths and Limitations}
\begin{itemize}
    \item Strengths:
    \begin{itemize}
        \item \textbf{Pre-trained TabPFN as a robust prior}: in our $n<300$ setting it is more stable and less tuning-heavy than trees.
        \item \textbf{Cross-domain RFE}: converges to 8 stable features, reducing dimension and site-specific noise.
        \item \textbf{TCA alignment}: lowers MMD, improves external calibration/recall/net benefit with only a modest AUC gain ($\sim$0.007), emphasizing decision stability over numeric uplift.
    \end{itemize}
    \item Limitations:
    \begin{itemize}
        \item \textbf{Closed feature intersection}: cannot exploit strong predictors only collected at the target.
        \item \textbf{MNAR unmodeled}: complete-case strategy assumes MCAR/MAR; MNAR may induce selection bias.
        \item \textbf{Resource constraints}: TabPFN runs on CPU but slower; GPU $\sim$20ms/sample, $O(N^2)$ attention limits large $N$; lung nodule setting is not a low-prevalence label-shift case.
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Key Takeaways}
\begin{itemize}
    \item PANDA = \textbf{pre-trained prior + stable features + linear alignment}.
    \item Lung nodules (A$\rightarrow$B): internal AUC 0.8287; external AUC 0.7046, Recall 0.944, beating clinical scores/trees.
    \item TableShift Diabetes: OOD AUC 0.804, close to ID AUC 0.802.
    \item Provides a reusable, lightweight UDA template for cross-hospital/population tabular prediction.
\end{itemize}
\end{frame}

\begin{frame}{Future Work}
\begin{itemize}
    \item \textbf{Federated/collaborative alignment}: share only second-order statistics for TCA to preserve privacy.
    \item \textbf{Multimodal PANDA}: fuse CT imaging with tables and align across modalities.
    \item \textbf{Low-prevalence/real screening} cohort validation to better handle label shift.
    \item \textbf{Resource optimization}: lightweight inference and sparse attention for edge deployment.
\end{itemize}
\end{frame}

%==============================
\section{Acknowledgments}
%==============================

\begin{frame}{Acknowledgments}
\begin{itemize}
    \item Thanks to advisor Prof. Wenqi Fan for guidance and support.
    \item Thanks to partner hospitals and clinical teams for data and expertise.
    \item Thanks to lab mates and friends for discussions and help.
    \item Thanks to PolyU COMP and related projects/resources for support.
\end{itemize}
\end{frame}

\begin{frame}{Thank You!}
\begin{center}
\LARGE Thank you for listening \\
\vspace{1em}
\Large Questions are welcome
\end{center}
\end{frame}

\end{document}
