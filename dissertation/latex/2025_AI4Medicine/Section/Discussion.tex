Predicting Malignancy of Pulmonary Nodules Across Hospitals Using Transferable Machine Learning on Small and Imbalanced Datasets
PANDA: A Robust Tool for Predicting Malignant Pulmonary Nodules Using Transferable Machine Learning Approach with Clinical, Radiological, Hematological Laboratory, and Pulmonary Function Multimodal Data
PANDA: A Reliable Machine Learning Tool for Predicting Malignant Pulmonary Nodules Using Clinical, Radiological, Hematological Laboratory, and Pulmonary Function Multimodal Data.
An Artificial Intelligence-Based Model for Assessing Malignancy of Solitary Pulmonary Nodules Incorporating Clinical, Radiological, Hematological Laboratory, and Pulmonary Function Multimodal Data
PANDA: A Robust Transferable Machine Learning Tool for Malignant Pulmonary Nodule Prediction Using Clinical, Radiological, Hematological, and Pulmonary Function Multimodal Data

Hao Chen 1\#, Qingyuan Liu2\#, Ning Xue3\#,      Shulin Chen1*, Wenqi Fan2,*
1.Department of Clinical Laboratory, State Key Laboratory of Oncology in South China, Collaborative Innovation Center for Cancer Medicine, Guangdong Provincial Clinical Research Center for Cancer, Sun Yat-sen University Cancer Center, Guangzhou, Guangdong, China
2. Department of Computing, The Hong Kong Polytechnic University, Hong Kong SAR, China
3.Department of Clinical Laboratory, Affiliated Cancer Hospital of Zhengzhou University, Zhengzhou Key Laboratory of Digestive Tumor Markers, Zhengzhou, Henan, People’s Republic of China

\# These authors made equal contributions to this work.
* Corresponding author.

Abstract
Medical AI systems face persistent challenges due to limited data, class imbalance, and inter-institutional heterogeneity. In particular, small sample sizes and skewed class distributions are common in clinical datasets, often introducing biases and undermining model reliability. Furthermore, models trained in one hospital or cohort frequently underperform when deployed at a different site, as differences in equipment, protocols, and patient demographics lead to domain shift. To address these issues, we propose a novel cross-domain adaptation framework that integrates a pre-trained Transformer-based foundation model with a classic domain alignment technique, Transfer Component Analysis (TCA). This approach leverages the rich representational power of Transformer models (pre-trained on large tabular data) and the distribution-matching capability of TCA to improve generalization under small-sample conditions. We validated our method on structured clinical datasets from two independent hospitals (295 patients in Hospital A for training, 190 patients in Hospital B for testing), focusing on malignant vs. benign pulmonary nodule classification. Our model achieved high area under the ROC curve (AUC) along with improved sensitivity and specificity on the external test set, outperforming several conventional domain adaptation baselines. These results demonstrate that the proposed framework achieves robust cross-domain prediction by aligning feature distributions and learning generalizable classification functions over structured clinical data. Interpretation: By effectively combating data scarcity and shift, the model exhibits strong generalizability and shows potential for reliable deployment in multi-center medical settings.


Introduction
Lung cancer is the most common and deadliest cancer in China. (PMID: 39654104) Early and accurate identification of benign versus malignant pulmonary nodules is vital but challenging in clinical radiology. To enhance diagnosis, predictive models like the Mayo Clinic (MC), Department of Veterans Affairs (VA), Peking University People’s Hospital (PKUPH), Shanghai, and Bayesian Inference Malignancy Calculator (BIMC) models have been developed, using clinical, radiological, or Hematological data. Despite this, their predictive performance, such as the MC model's AUC of only 0.67, (PMID: 39069970) and their generalization across different datasets, particularly internationally, require improvement. (PMID: 39705824, PMID: 34364866)
CT, pulmonary function, and Hematological Laboratory tests are typically part of routine physical exams but are seldom used together to assess pulmonary nodules. In particular, a broad spectrum of laboratory tests (such as albumin concentration and platelet-to-lymphocyte ratio), have been validated to be relevant to diagnostic and prognostic significance in cancer. These biomarkers are advantageous due to their low cost, easy accessibility, high consistency, and wide applicability in primary healthcare. Previously, we developed a predictive model for identifying MSPNs in patients with sPNs, incorporating clinical, CT, and laboratory data (including blood tests and pulmonary function tests). Our model (AUC=0.718) outperformed the PKUPH (AUC=0.674), Shanghai (AUC=0.632), and Mayo (AUC=0.562) models. However, our previous model only relied on traditional LASSO logistic regression for indicator selection and model development. In contrast, artificial intelligence (AI) offers significant advantages in integrating diverse test data, particularly laboratory results, to enhance clinical diagnosis and accurately characterize disease features.
 Meanwhile, implementing AI models in various clinical centers is highly challenging due to the diverse and limited nature of real-world medical data, which significantly affects the models' performance and fairness. In practical applications, different hospital cohorts may adopt unique clinical instruments, and the patient populations they serve also differ. Consequently, a model trained on one institution's data may show a significantly higher error rate when used at another institution. Unlike natural image tasks with millions of samples, clinical model datasets are usually small and often have significant class imbalances, such as fewer malignant cases compared to benign ones. In summary, data heterogeneity, small sample size, and imbalanced class distribution form a "triple barrier" that impedes the generalization of medical AI models and can lead to diagnostic errors and inconsistent performance across patient subgroups.\cite{guan2021domain}\cite{hellin2024unraveling}.
To mitigate data limitations, researchers are addressing data limitations by using pre-trained foundation models and transfer learning. Transformer-based architectures, initially successful in NLP and vision, are now being applied to tabular clinical data. These models, pre-trained on large structured datasets, excel at extracting features for various tasks. Notably, the TabPFN model has surpassed traditional methods on small datasets, achieving high accuracy quickly. This highlights Transformers' potential in small medical datasets by utilizing prior knowledge. Additionally, domain adaptation techniques like Transfer Component Analysis (TCA) help align data distributions between training and application domains. \cite{pan2010domain}. TCA operates in a reproducing kernel Hilbert space to find latent features that minimize domain divergence, enabling reliable model performance on target data after re-training. \cite{pan2010domain} This method has been effectively used in medical studies for domain adaptation, such as aligning mammography image features to improve breast cancer classification across databases.\cite{guan2021domain} Inspired by these successes, we propose integrating Transformer-based tabular modeling with TCA for enhanced representation learning and cross-domain generalization.
Pre-trained tabular Transformers offer a strong baseline, but fine-tuning them on a small clinical dataset often fails to ensure good performance in a different domain due to domain shift. Large models may fit source hospital data well but struggle with different target hospital data distributions\cite{guan2021domain}. Unsupervised Domain Adaptation (UDA) methods, which don't need target labels, can help but often become unstable with limited data. When target data is extremely scarce, aligning distributions is statistically challenging and prone to overfitting\cite{guan2021domain}. Recent studies indicate that a one-step adaptation may not work well in such cases; an intermediate fine-tuning on a related large dataset can enhance stability. Additionally, severe domain shift and class imbalance in medical data can cause models to memorize majority class features while ignoring minority patterns, leading to unstable training and misleading accuracy. This is problematic in clinical settings, as it can result in poor sensitivity for rare classes, like missing malignant nodules. Our goal is to create a framework that improves out-of-domain robustness, stabilizes adaptation on small samples, and reduces bias from imbalanced data. This involves integrating foundational model knowledge with a domain adaptation mechanism resilient to limited data and skewed distributions, ensuring reliable predictive performance across all classes and hospital settings.
This study presents PANDA (Pretrained Adaptation Network with Domain Alignment), a domain-adaptive framework aimed at improving malignant solitary pulmonary nodules (MSPN) prediction by utilizing clinical, radiological, laboratory, and pulmonary function data from two hospitals. PANDA integrates a pre-trained Transformer model with Transfer Component Analysis to tackle feature representation and distribution shifts in small-sample scenarios. It excels in cross-institutional pulmonary nodule cohorts, demonstrating improved generalization with limited data. PANDA is benchmarked against traditional machine learning models and clinical scoring systems, showcasing its stability and practical utility in real-world multi-center applications.

Methods
Study design and participants
This retrospective multicenter study included a training cohort of 295 patients with SPNs recruited from Sun Yat-sen University Cancer Center (Guangzhou, China) between January 2011 and December 2016, and an external validation cohort of 190 patients with SPNs recruited from Henan Tumor Hospital (Zhengzhou, China) between January 2013 and June 2018.The inclusion criteria were as follows: 1.SPN Detection: All patients were identified through chest CT scans showing solitary pulmonary nodules (SPNs), with final diagnoses confirmed via histopathologic examination of tissue obtained through CT-guided transthoracic needle biopsy, bronchoscopy, thoracoscopy, or surgical resection. 2. Nodule Size: Solitary pulmonary nodule lesions $\\leq$3 cm in diameter.3.Exclusion of Extrapulmonary Malignancy: No evidence of extrapulmonary malignancy. 4.Data Completeness: Availability of complete clinical, CT imaging, and laboratory data, collected from electronic medical records within 14 days prior to any anti-tumor treatment initiation.

Data preprocessing
A total of 62 universally applicable features from routine clinical practice were gathered, encompassing four categories: clinical features (age, sex, body mass index, smoking history, family history of cancer, Past History of Tumor, and symptoms (fever, cough, hemoptysis, sputum, chest pain)), radiologic characteristics (anatomical location, nodule diameter and area, presence of calcification, cavity, spiculation, pleural thickening, and adhesion.), lung function parameters (Vital Capacity (VC),	Forced Expiratory Volume in 1 Second(FEV1), Forced Expiratory Volume in 1 Second Percentage Predicted (FEV1\%), Ratio of Forced Expiratory Volume in 1 Second to Forced Vital Capacity (FEV1/FVC), Ratio of Residual Volume to Total Lung Capacity (RV/TLC), Diffusing Capacity of the Lung for Carbon Monoxide (DLCO1), Diffusing Capacity of the Lung for Carbon Monoxide Percentage Predicted (DLCO\%)), and blood-based biomarkers (white blood cell count (WBC), neutrophil-to-lymphocyte ratio (NLR), platelet-to-lymphocyte ratio (PLR), albumin/globulin ratio (AGR), liver and renal function markers, and tumor biomarkers including CEA, Cyfra21-1, and NSE).
Raw clinical data from both development (Cohort A) and validation (Cohort B) cohorts undergo systematic curation. Records containing missing values are excluded to ensure data quality, followed by recursive feature elimination to identify the most discriminative variables.

PANDA prediction model
As illustrated in Figure 1, PANDA operates through a three-stage pipeline: data preprocessing, training on source domain data, and domain-adaptive testing on target domain data.
Data Preprocessing Stage (Figure 1a): Raw clinical data from both development (Cohort A) and validation (Cohort B) cohorts undergo systematic curation. Records containing missing values are excluded to ensure data quality, followed by recursive feature elimination to identify the most discriminative variables. This preprocessing yields structured tabular datasets optimized for cross-domain learning while maintaining clinical interpretability.
Training Phase (Figure 1b): The curated source domain data (Cohort A) is fed into a pretrained tabular foundation model that leverages large-scale pretraining on diverse tabular datasets.
The model employs a 32 member ensemble architecture where each variant applies unique data trans-formation pipelines including feature permutation, quantile normalization, and categorical encoding strategies to enhance robustness and mitigate overfitting. The ensemble outputs classification probabilities through weighted aggregation, with inverse-frequency reweighting to address class imbalance inherent in medical datasets.
Testing Phase (Figure 1c): To handle distribution mismatch between institutions, PANDA incorporates Transfer Component Analysis (TCA) for unsupervised domain adaptation. TCA learns a shared latent representation where source and target domain distributions are statistically aligned using maximum mean discrepancy minimization. The domain-aligned features from both cohorts are then processed through the same pre-trained foundation model to generate predictions on the target domain without requiring labeled data from the validation cohort.

Feature Selection
To identify the most discriminative variables while mitigating the risk of overfitting, we employed recursive feature elimination (RFE) with the Pre-trained Tabular Foundation Model serving as the base estimator. As a wrapper-based feature selection strategy, RFE iteratively removes the least important features, ultimately generating a compact feature subset. This subset is not only optimized for downstream classification tasks but also ensures cross-domain consistency (Figure 6a). We initiated the process using the original Cohort A, which contained 63 features, and applied RFE to identify the most discriminative variables within this cohort. However, for ensuring robust cross-institutional model deployment, it is necessary to address the variability in feature availability across different clinical sites. As demonstrated in the "Select Overlapping Features" step, we intersected the top-ranked features derived from Cohort A with the available feature set of Cohort B. This intersection step ensured that only features consistently available across both institutions were retained for the final modeling process.

Statistical analysis
To assess the generalization of standard supervised learners, we implemented several representative classifiers: Support Vector Machine (SVM) using an RBF kernel, with hyperparameters tuned via grid search on the source domain. Decision Tree (DT) and Random Forest (RF) models using Gini impurity for splitting and evaluated under varying maximum depths and tree counts. Gradient Boosted Decision Tree (GBDT) and XGBoost, optimized with respect to learning rate, number of estimators, maximum tree depth, and subsample ratio. All models were trained on the source domain and tested directly on the target domain. For the conventional clinical risk models included in the comparative analysis, we incorporated several widely used clinical prediction models, namely the PKUPH model, the Mayo Clinic model, and Paper LR model (a previously published logistic regression model).
To comprehensively evaluate the performance of our proposed framework, we constructed a multidimensional evaluation protocol encompassing classification metrics, statistical confidence estimation, visualization-based analysis, and domain alignment assessment. 
Classification performance was assessed using five standard metrics widely adopted in clinical machine learning: area under the receiver operating characteristic curve (AUC), accuracy, F1-score, sensitivity (recall), and specificity (precision). All performance indicators were averaged over 10-fold cross-validation to ensure robustness and reproducibility. To quantify uncertainty in performance estimates, 95\% confidence intervals (CIs) for AUC were calculated via 1000-round bootstrap resampling. This provides a statistical measure of model stability and offers meaningful interpretability for clinical application. We also employed visualization-based assessments, including ROC curves, calibration plots, and decision curve analysis (DCA), to examine model reliability and potential clinical benefit under varying decision thresholds. 

Ethical statement
This study was approved by the ethics committees of two hospitals and followed the Declaration of Helsinki of 1975. All case data were anonymised, and the Institutional Review Board waived the requirement for written informed consent. The key raw data supporting the findings of this study have been deposited on the Research Data Deposit public platform (www.researchdata.org.cn) under approval number xxxxxxx.

Acknowledgments
This work is financially supported by Guang Dong Basic and Applied Basic Research Foundation (2024A1515011958),

Declaration of competing interest
The authors declare no conflict of interest.

Data availability
Data will be made available on request.

Role of the funding source
The funders of the study had no role in the study design, data collection, data analysis, data interpretation, or writing of the report.

Results
Between January 2011 and June 2018, a total of 485 individuals who met the inclusion criteria were enrolled in this study. Among them, cohort A (which served as the training set) comprised 295 participants, including 189 in the MSNP group and 106 in the pulmonary benign nodule control group. Cohort B, designated as the external validation set, consisted of 190 participants, with 125 in the MSNP group and 65 in the pulmonary benign nodule control group. In the training stage, Cohort A first undergoes feature selection to identify a stable and domain-relevant subset, followed by imputation, categorical processing, and class imbalance adjustment. Cohort A contained 63 structured features covering demographics, vital signs, biochemistry, tumor markers, and imaging descriptors. To ensure domain consistency, we applied recursive feature elimination (RFE) on the source cohort and selected the top 9 predictive features. One feature (CYSC) was unavailable in Cohort B and excluded from final modeling. The remaining 8 features were used consistently across both domains and formed the basis for domain-adaptive learning. The selected features include anatomical location, pulmonary function measurements, and key serum biomarkers such as CEA, CRE, and NSE, all of which are clinically relevant for distinguishing malignant lesions. The processed data is then passed into a pre-trained tabular foundation model configured as a 32-member ensemble. Each ensemble member applies distinct transformation pipelines to promote diversity and enhance structural robustness. 

The PANDA framework addresses key challenges in real-world medical tabular data, including small sample sizes, heterogeneous features, and domain shift. As shown in Fig. 1, it operates in two stages: model training on a labeled source domain and testing on an unlabeled target domain after domain alignment. To mitigate distribution mismatch, PANDA incorporates TCA during testing, projecting source and target samples into a shared latent space with better-aligned marginal distributions. Aligned target data undergoes the same ensemble processing, with final predictions obtained by aggregating weighted outputs across all members to address class imbalance.

We evaluated TCA's effectiveness in reducing domain shift using qualitative and quantitative analyses. Four standard distributional discrepancy metrics showed consistent post-adaptation improvements (all significant), confirming effective alignment. After TCA transformation, source-target normalized linear discrepancy decreased by 0.070 (indicating improved latent space alignment), normalized Frechét distance by 0.018, Wasserstein distance by 0.006, and symmetric KL divergence by 0.022. These results consistently demonstrate TCA's ability to mitigate inter-domain statistical divergence across multiple metrics.

Model generalization was assessed on Cohort A (source) and Cohort B (target; Fig. B) using AUC, accuracy, F1-score, precision, and recall. On Cohort A, our pre-trained tabular foundation model outperformed all comparators (AUC 0.826, accuracy 0.743, F1-score 0.807, precision 0.786, recall 0.841). Traditional models showed moderate performance (Random Forest AUC 0.752, XGBoost AUC 0.742), while GBDT/SVM/DT had lower metrics (limiting utility for high-dimensional data) and clinical scoring systems performed poorest (MC model: no predictive capacity with F1-score/precision/recall 0.000; PKUPH model: consistent underperformance). On Cohort B, our TCA-enhanced model achieved the highest external validation performance (AUC 0.709, F1-score 0.811, recall 0.944), significantly outperforming its non-adaptive version (AUC 0.698).

Model discrimination, calibration, and clinical utility were also evaluated. For discrimination, ROC analysis showed that our pre-trained model had the highest  AUC (0.820), outperforming SVM (0.717), XGBoost (0.734) and random forest (0.752) in Cohort A. The TCA-enhanced version maintained the top target-domain AUC (0.709), while its non-adaptive counterpart declined (AUC 0.698), confirming domain shift. For calibration (Fig. 5), our model aligned closer to the ideal probability-event rate line than traditional models on the source domain; TCA-based UDA further improved target-domain calibration by reducing over/underestimation. For clinical value (DCA, Fig. 5), our model delivered higher net benefits than baselines on the source domain, with TCA adaptation further boosting target-domain net benefits—underscoring its importance for cross-domain use.

Discussion

Currently, low-dose computed tomography (LDCT) is the only globally recognized screening method proven to reduce lung cancer mortality in high-risk groups. A pulmonary nodule is a small ($<$3 cm), well-defined radiographic opacity surrounded by normal lung tissue, seen in chest CT scans. The main objectives in managing these nodules are to minimize diagnostic-related harm while quickly assessing and treating potential lung cancer. The malignancy risk in small pulmonary nodules (sPNs) depends on size, smoking history, and other clinical factors, with imaging features being crucial. Although CT parameters help assess lung cancer invasiveness, measuring values in sPNs is difficult due to their irregular shape, risking inaccuracies. Recent models for predicting the nature of pulmonary nodules using imaging or biological characteristics, like ctDNA with imaging, DNA methylation, tsRNA, and Imaging omics, have limitations due to their reliance on single features, leading to high false-positive rates. (PMID: 39363284) A comprehensive approach considering factors like gender, smoking history, underlying diseases, tumor history, comorbidities, lab parameters, and CT imaging is necessary. In this multicenter retrospective study, we identified 8 features including anatomical location, pulmonary function, and serum biomarkers (CEA, CRE, NSE) from 63 clinical, radiological, laboratory, and pulmonary function metrics to develop the PANDA (or CRLP) model for accurately identifying patients with MSPN. As recommended by the American Thoracic Society (ATS), a biomarker for early lung cancer detection “should be used in clinical practice only if it reliably adds to a clinician’s judgment, resulting in a more favorable clinical outcome for the target population." (PMID: 28960111) Aligning with this guideline, all indicators incorporated into our model possess key attributes that support practical clinical application: they are not only readily accessible in routine clinical settings but also classified as mandatory items in regular physical examinations. Importantly, this design eliminates the need for additional testing or data collection, thus imposing no incremental economic burden on patients—addressing a critical barrier to the real-world translation of predictive models.
To our knowledge, this is the first study that leverages a comprehensive dataset—encompassing clinical, radiological, laboratory, and pulmonary function data—and integrates a pretrained Transformer model with Transfer Component Analysis (TCA), applying this combined framework as a stratification tool for clinical data in a real-world patient population.
Building multi-center medical models is challenging due to varied clinical features, equipment differences, and patient diversity, along with the imbalance in medical datasets where pathological cases are less common. This feature mismatch hinders the development of models that perform consistently across different clinical settings and are suitable for large-scale use. Current AI approaches in medicine usually focus on either improving model architecture or addressing domain shifts, but not both. Additionally, these methods often depend on large datasets, which is impractical in many medical situations where data is inherently limited.
To tackle challenges in cross-institutional medical AI, we propose PANDA, a framework with five innovations. Firstly, we create a recursive feature elimination strategy for multi-institutional contexts, reducing 63 clinical variables to 8 while maintaining predictive performance and clinical interpretability. Secondly, we apply pretrained transformer architectures to medical prediction, using a 32-member ensemble with domain-specific adaptations, enhancing generalization for small, imbalanced datasets. Thirdly, we integrate TCA with foundation model representations for domain adaptation, aligning statistical distributions across institutions while preserving discriminative information.
The PANDA framework overcomes key limitations in current medical AI by enabling effective cross-institutional deployment with a minimal, informative feature set. Achieving a high sensitivity of 94.4\%, it is well-suited for medical screenings where missing positive cases is critical. Using only 8 selected features, PANDA supports clinical integration and cost-efficiency, reducing reliance on extensive lab tests or specialized biomarkers. This approach promotes equitable AI-assisted diagnosis across various healthcare environments, from advanced academic centers to resource-limited community hospitals. The integration of foundation model capabilities with domain adaptation principles establishes a new paradigm for medical AI development, where models can leverage large-scale pretraining benefits while adapting to the specific challenges of medical deployment scenarios. This approach has broad implications beyond pulmonary nodule classification, potentially transforming how AI systems are developed and deployed across various medical specialties and clinical applications.
To handle distribution mismatch between institutions, PANDA incorporates Transfer Component Analysis (TCA) for unsupervised domain adaptation. TCA learns a shared latent representation where source and target domain distributions are statistically aligned using maximum mean discrepancy minimization. The domain-aligned features from both cohorts are then processed through the same pre-trained foundation model to generate predictions on the target domain without requiring labeled data from the validation cohort.
This end-to-end design enables robust cross-institutional generalization by combining the representational power of foundation models with principled domain adaptation. The framework is particularly suited for medical applications where training data is scarce, class distributions are imbalanced, and deployment across different clinical sites is required.
To evaluate our framework, we compared the TCA-integrated model against classical machine learning algorithms and clinical scoring systems. The results showed that our model consistently outperformed these baselines in key metrics, demonstrating strong external generalization. This confirms the effectiveness of TCA for domain alignment and highlights the model's potential for reliable use in diverse clinical settings.

