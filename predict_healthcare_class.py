import warnings
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

import pandas as pd
import matplotlib.pyplot as plt
import time
import os
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix
from tabpfn import TabPFNClassifier
from typing import Dict, Tuple, Any
import numpy as np

def analyze_cancer_prediction_performance(
    device: str = 'cuda',
    n_estimators: int = 32,
    softmax_temperature: float = 0.9,
    balance_probabilities: bool = False,
    average_before_softmax: bool = False,
    ignore_pretraining_limits: bool = True,
    random_state: int = 42,
    base_path: str = './results'
) -> Tuple[pd.DataFrame, Dict[str, Any]]:
    """
    åˆ†æTabPFNå¯¹ä¸åŒç™Œç—‡ç±»å‹çš„é¢„æµ‹å‡†ç¡®æ€§
    æ³¨æ„ï¼šåªæœ‰Label=1çš„æ ·æœ¬æ‰æœ‰ç™Œç—‡ç±»å‹ä¿¡æ¯ï¼ŒLabel=0çš„æ ·æœ¬ä»£è¡¨å¥åº·/é˜´æ€§
    """
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs(base_path, exist_ok=True)
    
    # ==============================
    # 1. è¯»å–æ•°æ®
    # ==============================
    print("åŠ è½½æ²³å—ç™Œç—‡åŒ»é™¢æ•°æ®...")
    df = pd.read_excel("data/HenanCancerHospital_translated_english.xlsx")
    
    # é€‰æ‹©ç‰¹å¾åˆ—
    features = [c for c in df.columns if c.startswith("Feature")]
    X = df[features].copy()
    y = df["Label"].copy()
    
    print(f"æ•°æ®å½¢çŠ¶: {X.shape}")
    print(f"æ ‡ç­¾åˆ†å¸ƒ: é˜³æ€§(ç™Œç—‡)={y.sum()}, é˜´æ€§(å¥åº·)={len(y)-y.sum()}")
    
    # åªæœ‰Label=1çš„æ ·æœ¬æ‰æœ‰ç™Œç—‡ç±»å‹ä¿¡æ¯
    positive_samples = df[df['Label'] == 1]
    print(f"é˜³æ€§æ ·æœ¬ç™Œç—‡ç±»å‹åˆ†å¸ƒ:\n{positive_samples['Type_Raw_English'].value_counts()}")
    
    # ==============================
    # 2. 10æŠ˜äº¤å‰éªŒè¯è·å–é¢„æµ‹ç»“æœ
    # ==============================
    print("\n" + "="*50)
    print("10æŠ˜äº¤å‰éªŒè¯è·å–é¢„æµ‹ç»“æœ")
    print("="*50)
    
    kf = KFold(n_splits=10, shuffle=True, random_state=42)
    
    # å­˜å‚¨æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœ
    all_predictions = []
    all_probabilities = []
    all_true_labels = []
    all_indices = []
    
    overall_scores = []
    
    for fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):
        print(f"å¤„ç† Fold {fold}...")
        
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
        
        # è®­ç»ƒæ¨¡å‹
        clf = TabPFNClassifier(
            device=device,
            n_estimators=n_estimators,
            softmax_temperature=softmax_temperature,
            balance_probabilities=balance_probabilities,
            average_before_softmax=average_before_softmax,
            ignore_pretraining_limits=ignore_pretraining_limits,
            random_state=random_state
        )
        clf.fit(X_train, y_train)
        
        # é¢„æµ‹
        y_pred = clf.predict(X_test)
        y_pred_proba = clf.predict_proba(X_test)
        
        # ä¿å­˜é¢„æµ‹ç»“æœ
        all_predictions.extend(y_pred)
        all_probabilities.extend(y_pred_proba[:, 1])  # æ¶æ€§æ¦‚ç‡
        all_true_labels.extend(y_test.values)
        all_indices.extend(test_idx)
        
        # è®¡ç®—foldæ€§èƒ½
        acc = accuracy_score(y_test, y_pred)
        auc = roc_auc_score(y_test, y_pred_proba[:, 1])
        f1 = f1_score(y_test, y_pred)
        
        overall_scores.append({
            'fold': fold,
            'accuracy': acc,
            'auc': auc,
            'f1': f1
        })
        
        print(f"  AUC: {auc:.4f}, ACC: {acc:.4f}, F1: {f1:.4f}")
    
    # ==============================
    # 3. åˆ›å»ºå®Œæ•´çš„é¢„æµ‹ç»“æœDataFrame
    # ==============================
    print("\nåˆ›å»ºé¢„æµ‹ç»“æœåˆ†æ...")
    
    # é‡æ–°æ’åºä»¥åŒ¹é…åŸå§‹æ•°æ®é¡ºåº
    prediction_results = pd.DataFrame({
        'Original_Index': all_indices,
        'True_Label': all_true_labels,
        'Predicted_Label': all_predictions,
        'Malignant_Probability': all_probabilities
    })
    
    # æŒ‰åŸå§‹ç´¢å¼•æ’åº
    prediction_results = prediction_results.sort_values('Original_Index').reset_index(drop=True)
    
    # æ·»åŠ ç™Œç—‡ç›¸å…³ä¿¡æ¯ï¼ˆåªå¯¹Label=1çš„æ ·æœ¬æœ‰æ•ˆï¼‰
    prediction_results['Cancer_Type'] = df.loc[prediction_results['Original_Index'], 'Type_Raw_English'].values
    prediction_results['T_Stage'] = df.loc[prediction_results['Original_Index'], 'T_stage'].values
    prediction_results['N_Stage'] = df.loc[prediction_results['Original_Index'], 'N_stage'].values
    prediction_results['Stage_Raw'] = df.loc[prediction_results['Original_Index'], 'Stage_Raw'].values
    
    # è®¡ç®—é¢„æµ‹å‡†ç¡®æ€§
    prediction_results['Correct_Prediction'] = (prediction_results['True_Label'] == prediction_results['Predicted_Label'])
    
    # ==============================
    # 4. æ•´ä½“é¢„æµ‹æ€§èƒ½åˆ†æ
    # ==============================
    print("\n" + "="*50)
    print("æ•´ä½“é¢„æµ‹æ€§èƒ½åˆ†æ")
    print("="*50)
    
    # è®¡ç®—æ··æ·†çŸ©é˜µ
    conf_matrix = confusion_matrix(prediction_results['True_Label'], prediction_results['Predicted_Label'])
    
    # çœŸå®é˜³æ€§æ ·æœ¬æ•°é‡
    true_positive_samples = prediction_results[prediction_results['True_Label'] == 1]
    true_negative_samples = prediction_results[prediction_results['True_Label'] == 0]
    
    # é¢„æµ‹ç»“æœç»Ÿè®¡
    print(f"çœŸå®é˜³æ€§æ ·æœ¬: {len(true_positive_samples)}")
    print(f"çœŸå®é˜´æ€§æ ·æœ¬: {len(true_negative_samples)}")
    print(f"é¢„æµ‹ä¸ºé˜³æ€§çš„æ ·æœ¬: {prediction_results['Predicted_Label'].sum()}")
    print(f"é¢„æµ‹ä¸ºé˜´æ€§çš„æ ·æœ¬: {len(prediction_results) - prediction_results['Predicted_Label'].sum()}")
    
    print(f"\næ··æ·†çŸ©é˜µ:")
    print(f"çœŸé˜´æ€§(TN): {conf_matrix[0,0]}, å‡é˜³æ€§(FP): {conf_matrix[0,1]}")
    print(f"å‡é˜´æ€§(FN): {conf_matrix[1,0]}, çœŸé˜³æ€§(TP): {conf_matrix[1,1]}")
    
    # è®¡ç®—å„ç±»å‡†ç¡®ç‡
    tn, fp, fn, tp = conf_matrix.ravel()
    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0  # çœŸé˜³æ€§ç‡ï¼ˆæ•æ„Ÿåº¦ï¼‰
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # çœŸé˜´æ€§ç‡ï¼ˆç‰¹å¼‚åº¦ï¼‰
    
    print(f"\næ•æ„Ÿåº¦(Sensitivity): {sensitivity:.3f} - æ­£ç¡®è¯†åˆ«ç™Œç—‡çš„æ¯”ä¾‹")
    print(f"ç‰¹å¼‚åº¦(Specificity): {specificity:.3f} - æ­£ç¡®è¯†åˆ«å¥åº·çš„æ¯”ä¾‹")
    
    # ==============================
    # 5. åˆ†æçœŸå®é˜³æ€§æ ·æœ¬ä¸­ä¸åŒç™Œç—‡ç±»å‹çš„é¢„æµ‹å‡†ç¡®æ€§
    # ==============================
    print("\n" + "="*50)
    print("ä¸åŒç™Œç—‡ç±»å‹é¢„æµ‹å‡†ç¡®æ€§åˆ†æï¼ˆä»…çœŸå®é˜³æ€§æ ·æœ¬ï¼‰")
    print("="*50)
    
    cancer_analysis = []
    
    # åªåˆ†æçœŸå®çš„é˜³æ€§æ ·æœ¬ï¼ˆæœ‰ç™Œç—‡ç±»å‹ä¿¡æ¯ï¼‰
    positive_results = prediction_results[prediction_results['True_Label'] == 1].copy()
    
    # è·å–æ‰€æœ‰ç™Œç—‡ç±»å‹
    cancer_counts = positive_results['Cancer_Type'].value_counts()
    all_cancer_types = cancer_counts.index.tolist()
    
    for cancer_type in all_cancer_types:
        subset = positive_results[positive_results['Cancer_Type'] == cancer_type]
        
        total_samples = len(subset)
        correct_predictions = subset['Correct_Prediction'].sum()  # è¢«æ­£ç¡®é¢„æµ‹ä¸ºé˜³æ€§çš„
        wrong_predictions = total_samples - correct_predictions   # è¢«é”™è¯¯é¢„æµ‹ä¸ºé˜´æ€§çš„
        accuracy = correct_predictions / total_samples
        
        # è·å–è¯¥ç™Œç—‡ç±»å‹æ ·æœ¬çš„å¹³å‡é¢„æµ‹æ¦‚ç‡
        avg_malignant_prob = subset['Malignant_Probability'].mean()
        
        cancer_analysis.append({
            'Cancer_Type': cancer_type,
            'Total_Samples': total_samples,
            'Correctly_Predicted_as_Positive': correct_predictions,
            'Wrongly_Predicted_as_Negative': wrong_predictions,
            'Detection_Rate': accuracy,  # æ£€å‡ºç‡
            'Avg_Malignant_Probability': avg_malignant_prob
        })
        
        print(f"\n{cancer_type}:")
        print(f"  æ€»æ ·æœ¬: {total_samples}")
        print(f"  æ­£ç¡®è¯†åˆ«ä¸ºç™Œç—‡: {correct_predictions} ({accuracy:.3f})")
        print(f"  é”™è¯¯åˆ¤æ–­ä¸ºå¥åº·: {wrong_predictions}")
        print(f"  å¹³å‡æ¶æ€§æ¦‚ç‡: {avg_malignant_prob:.3f}")
        if accuracy < 0.8:
            print(f"  âš ï¸  è¯¥ç™Œç—‡ç±»å‹æ£€å‡ºç‡è¾ƒä½ï¼")
        elif accuracy > 0.95:
            print(f"  âœ… è¯¥ç™Œç—‡ç±»å‹æ£€å‡ºç‡å¾ˆé«˜")
    
    # ==============================
    # 6. åˆ†æä¸åŒåˆ†æœŸçš„é¢„æµ‹å‡†ç¡®æ€§
    # ==============================
    print("\n" + "="*50)
    print("ä¸åŒåˆ†æœŸé¢„æµ‹å‡†ç¡®æ€§åˆ†æï¼ˆä»…çœŸå®é˜³æ€§æ ·æœ¬ï¼‰")
    print("="*50)
    
    # Tåˆ†æœŸåˆ†æ
    print("\nTåˆ†æœŸæ£€å‡ºç‡:")
    t_stage_analysis = positive_results.groupby('T_Stage').agg({
        'Correct_Prediction': ['count', 'sum', 'mean'],
        'Malignant_Probability': 'mean'
    }).round(3)
    t_stage_analysis.columns = ['Total_Count', 'Detected_Count', 'Detection_Rate', 'Avg_Probability']
    print(t_stage_analysis)
    
    # ç»¼åˆåˆ†æœŸåˆ†æ
    print("\nä¸»è¦ç»¼åˆåˆ†æœŸæ£€å‡ºç‡:")
    stage_counts = positive_results['Stage_Raw'].value_counts()
    major_stages = stage_counts[stage_counts >= 3].index.tolist()  # è‡³å°‘3ä¸ªæ ·æœ¬
    
    stage_analysis = []
    for stage in major_stages:
        subset = positive_results[positive_results['Stage_Raw'] == stage]
        detection_rate = subset['Correct_Prediction'].mean()
        avg_prob = subset['Malignant_Probability'].mean()
        stage_analysis.append({
            'Stage': stage,
            'Count': len(subset),
            'Detection_Rate': detection_rate,
            'Avg_Probability': avg_prob
        })
        print(f"  {stage}: {len(subset)}ä¸ªæ ·æœ¬, æ£€å‡ºç‡: {detection_rate:.3f}, å¹³å‡æ¦‚ç‡: {avg_prob:.3f}")
    
    # ==============================
    # 7. åˆ†æè¢«é”™è¯¯é¢„æµ‹çš„ç™Œç—‡æ ·æœ¬
    # ==============================
    print("\n" + "="*50)
    print("è¢«é”™è¯¯é¢„æµ‹ä¸ºå¥åº·çš„ç™Œç—‡æ ·æœ¬åˆ†æ")
    print("="*50)
    
    false_negative_samples = positive_results[positive_results['Correct_Prediction'] == False]
    
    if len(false_negative_samples) > 0:
        print(f"æ€»å…±æœ‰ {len(false_negative_samples)} ä¸ªç™Œç—‡æ ·æœ¬è¢«é”™è¯¯é¢„æµ‹ä¸ºå¥åº·:")
        
        fn_cancer_types = false_negative_samples['Cancer_Type'].value_counts()
        for cancer_type, count in fn_cancer_types.items():
            total_of_this_type = len(positive_results[positive_results['Cancer_Type'] == cancer_type])
            miss_rate = count / total_of_this_type
            print(f"  {cancer_type}: {count}ä¸ª (å è¯¥ç±»å‹çš„{miss_rate:.1%})")
        
        print(f"\nè¿™äº›æ ·æœ¬çš„å¹³å‡æ¶æ€§æ¦‚ç‡: {false_negative_samples['Malignant_Probability'].mean():.3f}")
        print(f"æœ€ä½æ¶æ€§æ¦‚ç‡: {false_negative_samples['Malignant_Probability'].min():.3f}")
        print(f"æœ€é«˜æ¶æ€§æ¦‚ç‡: {false_negative_samples['Malignant_Probability'].max():.3f}")
    else:
        print("æ‰€æœ‰ç™Œç—‡æ ·æœ¬éƒ½è¢«æ­£ç¡®è¯†åˆ«ï¼")
    
    # ==============================
    # 8. ä¿å­˜ç»“æœ
    # ==============================
    
    # ä¿å­˜æ•´ä½“CVç»“æœ
    overall_df = pd.DataFrame(overall_scores)
    print(f"\næ•´ä½“CVç»“æœ:")
    print(f"AUC: {overall_df['auc'].mean():.4f} Â± {overall_df['auc'].std():.4f}")
    print(f"ACC: {overall_df['accuracy'].mean():.4f} Â± {overall_df['accuracy'].std():.4f}")
    print(f"F1: {overall_df['f1'].mean():.4f} Â± {overall_df['f1'].std():.4f}")
    
    overall_df.to_csv(f'{base_path}/HenanCancer_Overall_CV_Results.csv', index=False)
    
    # ä¿å­˜è¯¦ç»†é¢„æµ‹ç»“æœ
    prediction_results.to_csv(f'{base_path}/HenanCancer_Detailed_Predictions.csv', index=False)
    
    # ä¿å­˜ç™Œç—‡ç±»å‹åˆ†æ
    cancer_analysis_df = pd.DataFrame(cancer_analysis)
    cancer_analysis_df.to_csv(f'{base_path}/HenanCancer_CancerType_Detection_Analysis.csv', index=False)
    
    # ä¿å­˜å‡é˜´æ€§æ ·æœ¬åˆ†æ
    if len(false_negative_samples) > 0:
        false_negative_samples.to_csv(f'{base_path}/HenanCancer_False_Negative_Samples.csv', index=False)
    
    # ä¿å­˜åˆ†æœŸåˆ†æ
    t_stage_analysis.to_csv(f'{base_path}/HenanCancer_T_Stage_Detection.csv')
    stage_analysis_df = pd.DataFrame(stage_analysis)
    stage_analysis_df.to_csv(f'{base_path}/HenanCancer_Combined_Stage_Detection.csv', index=False)
    
    # ==============================
    # 9. åˆ›å»ºå¯è§†åŒ–
    # ==============================
    
    if len(cancer_analysis) > 0:
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        cancer_analysis_df = pd.DataFrame(cancer_analysis)
        
        # å­å›¾1: ä¸åŒç™Œç—‡ç±»å‹çš„æ£€å‡ºç‡
        axes[0,0].bar(range(len(cancer_analysis_df)), cancer_analysis_df['Detection_Rate'])
        axes[0,0].set_title('Cancer Detection Rate by Type')
        axes[0,0].set_ylabel('Detection Rate')
        axes[0,0].set_xticks(range(len(cancer_analysis_df)))
        axes[0,0].set_xticklabels([ct[:15] + '...' if len(ct) > 15 else ct for ct in cancer_analysis_df['Cancer_Type']], rotation=45)
        axes[0,0].axhline(y=0.8, color='r', linestyle='--', alpha=0.5, label='80% threshold')
        axes[0,0].legend()
        
        # å­å›¾2: å¹³å‡æ¶æ€§æ¦‚ç‡
        axes[0,1].bar(range(len(cancer_analysis_df)), cancer_analysis_df['Avg_Malignant_Probability'])
        axes[0,1].set_title('Average Malignant Probability by Cancer Type')
        axes[0,1].set_ylabel('Probability')
        axes[0,1].set_xticks(range(len(cancer_analysis_df)))
        axes[0,1].set_xticklabels([ct[:10] + '...' if len(ct) > 10 else ct for ct in cancer_analysis_df['Cancer_Type']], rotation=45)
        axes[0,1].axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='Decision threshold')
        axes[0,1].legend()
        
        # å­å›¾3: æ ·æœ¬æ•°é‡åˆ†å¸ƒ
        axes[0,2].bar(range(len(cancer_analysis_df)), cancer_analysis_df['Total_Samples'])
        axes[0,2].set_title('Sample Count by Cancer Type')
        axes[0,2].set_ylabel('Sample Count')
        axes[0,2].set_xticks(range(len(cancer_analysis_df)))
        axes[0,2].set_xticklabels([ct[:10] + '...' if len(ct) > 10 else ct for ct in cancer_analysis_df['Cancer_Type']], rotation=45)
        
        # å­å›¾4: æ­£ç¡®vsé”™è¯¯é¢„æµ‹
        correct_counts = cancer_analysis_df['Correctly_Predicted_as_Positive']
        wrong_counts = cancer_analysis_df['Wrongly_Predicted_as_Negative']
        
        x = np.arange(len(cancer_analysis_df))
        width = 0.35
        axes[1,0].bar(x - width/2, correct_counts, width, label='Correctly Detected', alpha=0.8, color='green')
        axes[1,0].bar(x + width/2, wrong_counts, width, label='Missed (False Negative)', alpha=0.8, color='red')
        axes[1,0].set_title('Detection Results by Cancer Type')
        axes[1,0].set_ylabel('Sample Count')
        axes[1,0].set_xticks(x)
        axes[1,0].set_xticklabels([ct[:10] + '...' if len(ct) > 10 else ct for ct in cancer_analysis_df['Cancer_Type']], rotation=45)
        axes[1,0].legend()
        
        # å­å›¾5: Tåˆ†æœŸæ£€å‡ºç‡
        if len(t_stage_analysis) > 0:
            axes[1,1].bar(range(len(t_stage_analysis)), t_stage_analysis['Detection_Rate'])
            axes[1,1].set_title('Detection Rate by T Stage')
            axes[1,1].set_ylabel('Detection Rate')
            axes[1,1].set_xticks(range(len(t_stage_analysis)))
            axes[1,1].set_xticklabels(t_stage_analysis.index, rotation=45)
            axes[1,1].axhline(y=0.8, color='r', linestyle='--', alpha=0.5)
        
        # å­å›¾6: æ•´ä½“æ··æ·†çŸ©é˜µ
        axes[1,2].imshow(conf_matrix, cmap='Blues', alpha=0.7)
        for i in range(2):
            for j in range(2):
                axes[1,2].text(j, i, conf_matrix[i, j], ha='center', va='center', fontsize=20)
        axes[1,2].set_title('Confusion Matrix')
        axes[1,2].set_xlabel('Predicted')
        axes[1,2].set_ylabel('Actual')
        axes[1,2].set_xticks([0, 1])
        axes[1,2].set_yticks([0, 1])
        axes[1,2].set_xticklabels(['Negative', 'Positive'])
        axes[1,2].set_yticklabels(['Negative', 'Positive'])
        
        plt.tight_layout()
        plt.savefig(f'{base_path}/HenanCancer_Detection_Analysis_Plots.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    return overall_df, {
        'cancer_analysis': cancer_analysis,
        'prediction_results': prediction_results,
        'stage_analysis': stage_analysis,
        'false_negative_samples': false_negative_samples,
        'confusion_matrix': conf_matrix
    }

# ==============================
# è¿è¡Œåˆ†æ
# ==============================
if __name__ == "__main__":
    print("TabPFNæ²³å—ç™Œç—‡åŒ»é™¢é¢„æµ‹å‡†ç¡®æ€§åˆ†æ")
    print("="*50)
    
    # è¿è¡Œåˆ†æ
    results, analysis_data = analyze_cancer_prediction_performance(
        device='cuda',
        n_estimators=32,
        softmax_temperature=0.9,
        balance_probabilities=False,
        average_before_softmax=False,
        ignore_pretraining_limits=True,
        random_state=42,
        base_path='./results/HenanCancer_Detection_Analysis'
    )
    
    print("\nåˆ†æå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° ./results/HenanCancer_Detection_Analysis/")
    
    # è¾“å‡ºæ€»ç»“
    cancer_analysis = analysis_data['cancer_analysis']
    if cancer_analysis:
        print("\n" + "="*50)
        print("ç™Œç—‡ç±»å‹æ£€å‡ºç‡æ€»ç»“")
        print("="*50)
        for analysis in cancer_analysis:
            status = "âš ï¸ è¾ƒä½" if analysis['Detection_Rate'] < 0.8 else "âœ… è‰¯å¥½" if analysis['Detection_Rate'] > 0.95 else "ğŸ”¶ ä¸­ç­‰"
            print(f"{analysis['Cancer_Type']}: {analysis['Detection_Rate']:.3f} ({analysis['Total_Samples']}ä¸ªæ ·æœ¬) {status}")
        
        # æ€»ä½“ç»Ÿè®¡
        total_cancer_samples = sum([a['Total_Samples'] for a in cancer_analysis])
        total_detected = sum([a['Correctly_Predicted_as_Positive'] for a in cancer_analysis])
        overall_detection_rate = total_detected / total_cancer_samples
        print(f"\næ•´ä½“ç™Œç—‡æ£€å‡ºç‡: {overall_detection_rate:.3f} ({total_detected}/{total_cancer_samples})") 