# TabPFN æ•°æ®é¢„å¤„ç†æµç¨‹è¯¦è§£

## ğŸ“‹ æ¦‚è¿°

TabPFNï¼ˆTabular Prior-data Fitted Networksï¼‰ä½œä¸ºä¸€ä¸ªä¸“é—¨é’ˆå¯¹è¡¨æ ¼æ•°æ®çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå…·æœ‰ç‹¬ç‰¹è€Œå¤æ‚çš„æ•°æ®é¢„å¤„ç†æµç¨‹ã€‚æœ¬æ–‡æ¡£è¯¦ç»†åˆ†æäº†TabPFNåœ¨è®­ç»ƒï¼ˆfitï¼‰å’Œé¢„æµ‹ï¼ˆpredictï¼‰è¿‡ç¨‹ä¸­çš„å®Œæ•´æ•°æ®é¢„å¤„ç†æ­¥éª¤ï¼ŒåŒ…æ‹¬å…­ä¸ªä¸»è¦é˜¶æ®µçš„æ·±åº¦è§£æã€25ç§æ•°å€¼å˜æ¢æ–¹æ³•ã€å¤šæ ·åŒ–é›†æˆç­–ç•¥ã€éšæœºç§å­åˆ†é…æœºåˆ¶ä»¥åŠpreprocessing.pyæ–‡ä»¶çš„æ ¸å¿ƒåŠŸèƒ½ã€‚

## ğŸ“š æ–‡æ¡£ç»“æ„

### ğŸ¯ æ ¸å¿ƒæµç¨‹åˆ†æ
- **å®Œæ•´æ•°æ®å¤„ç†å’Œé¢„æµ‹æµç¨‹**: Mermaidæµç¨‹å›¾ + è¯¦ç»†æ­¥éª¤è¡¨
- **å…­é˜¶æ®µæ·±åº¦è§£æ**: ä»æ•°æ®éªŒè¯åˆ°é¢„æµ‹æ‰§è¡Œçš„å®Œæ•´åˆ†æ
- **å…³é”®æ£€æŸ¥ç‚¹**: æ•°æ®éªŒè¯ã€ç±»åˆ«ç‰¹å¾æ¨æ–­ã€é¢„è®­ç»ƒé™åˆ¶æ£€æŸ¥

### ğŸ”§ æŠ€æœ¯ç»†èŠ‚æ·±å…¥
- **25ç§æ•°å€¼å˜æ¢æ–¹æ³•**: å®Œæ•´åˆ—è¡¨åŠé»˜è®¤ç­–ç•¥åˆ†æ
- **å¤šæ ·åŒ–æ•°æ®å¤„ç†ç­–ç•¥**: äº”å¤§éšæœºåŒ–ç»´åº¦è¯¦è§£
- **éšæœºç§å­åˆ†é…æœºåˆ¶**: å››å±‚ç§å­ä½“ç³»åŠé…ç½®ç”Ÿæˆè¿‡ç¨‹
- **preprocessing.pyåŠŸèƒ½è§£æ**: æ ¸å¿ƒé…ç½®ç®¡ç†å’Œé›†æˆå¼•æ“

### ğŸš¨ å®ç”¨æŒ‡å—
- **å¸¸è§é—®é¢˜å’Œè°ƒè¯•ç‚¹**: 4ä¸ªå…¸å‹é—®é¢˜çš„è§£å†³æ–¹æ¡ˆ
- **æ€§èƒ½ä¼˜åŒ–å»ºè®®**: æ•°æ®å‡†å¤‡ã€é…ç½®ä¼˜åŒ–ã€å†…å­˜ç®¡ç†
- **ä½¿ç”¨ç¤ºä¾‹å’ŒéªŒè¯**: åŸºæœ¬æµç¨‹å’Œè°ƒè¯•è¦ç‚¹

## ğŸ”„ å®Œæ•´æ•°æ®å¤„ç†å’Œé¢„æµ‹æµç¨‹

### æµç¨‹å›¾æ¦‚è§ˆ

```mermaid
graph TD
    A[åŸå§‹æ•°æ® X, y] --> B[åˆå§‹åŒ–TabPFNClassifier]
    B --> C[è°ƒç”¨ fit æ–¹æ³•]
    
    C --> D[æ­¥éª¤1: éšæœºç§å­è®¾ç½®]
    D --> E[æ­¥éª¤2: æ¨¡å‹å’Œé…ç½®åŠ è½½]
    E --> F[æ­¥éª¤3: è®¾å¤‡å’Œç²¾åº¦ç¡®å®š]
    F --> G[æ­¥éª¤4: æ¥å£é…ç½®æ„å»º]
    G --> H[æ­¥éª¤5: è¾“å…¥æ•°æ®éªŒè¯]
    H --> I[æ­¥éª¤6: ç›®æ ‡å˜é‡å¤„ç†]
    I --> J[æ­¥éª¤7: æ•°æ®ç±»å‹ä¿®å¤]
    J --> K[æ­¥éª¤8: åºæ•°ç¼–ç å™¨åˆ›å»º]
    K --> L[æ­¥éª¤9: ç±»åˆ«ç‰¹å¾æ¨æ–­]
    L --> M[æ­¥éª¤10: é›†æˆé…ç½®ç”Ÿæˆ]
    M --> N[æ­¥éª¤11: æ¨ç†å¼•æ“åˆ›å»º]
    
    N --> O[æ¨¡å‹è®­ç»ƒå®Œæˆ]
    
    O --> P[æ–°æ•°æ® X_test]
    P --> Q[è°ƒç”¨ predict_proba æ–¹æ³•]
    
    Q --> R[é¢„æµ‹æ­¥éª¤1: æ¨¡å‹çŠ¶æ€æ£€æŸ¥]
    R --> S[é¢„æµ‹æ­¥éª¤2: è¾“å…¥éªŒè¯]
    S --> T[é¢„æµ‹æ­¥éª¤3: æ•°æ®ç±»å‹ä¿®å¤]
    T --> U[é¢„æµ‹æ­¥éª¤4: åºæ•°ç¼–ç åº”ç”¨]
    U --> V[é¢„æµ‹æ­¥éª¤5: æ¨¡å‹æ¨ç†]
    V --> W[é¢„æµ‹æ­¥éª¤6: åå¤„ç†]
    W --> X[é¢„æµ‹ç»“æœè¾“å‡º]
```

### è¯¦ç»†æµç¨‹æ­¥éª¤

#### ğŸ—ï¸ è®­ç»ƒé˜¶æ®µ (fitæ–¹æ³•)

**å…¥å£æ–‡ä»¶**: `src/tabpfn/classifier.py:379-535`

| æ­¥éª¤ | åŠŸèƒ½æè¿° | æºæ–‡ä»¶ä½ç½® | å…³é”®å‡½æ•°/ç±» | å…·ä½“æ‰§è¡Œå†…å®¹ |
|------|----------|------------|-------------|-------------|
| **1** | **éšæœºç§å­è®¾ç½®** | `src/tabpfn/utils.py:547-565` | `infer_random_state()` | ç”Ÿæˆé™æ€ç§å­å’Œéšæœºæ•°ç”Ÿæˆå™¨ |
| | â””â”€ ç§å­éªŒè¯å’Œè½¬æ¢ | | | éªŒè¯ç”¨æˆ·è¾“å…¥çš„random_stateç±»å‹ |
| | â””â”€ é™æ€ç§å­ç”Ÿæˆ | | | ç”Ÿæˆå›ºå®šç§å­ç”¨äºå…³é”®ç»„ä»¶ |
| | â””â”€ éšæœºæ•°ç”Ÿæˆå™¨åˆ›å»º | | | åˆ›å»ºnumpy.random.Generatorå¯¹è±¡ |
| **2** | **æ¨¡å‹å’Œé…ç½®åŠ è½½** | `src/tabpfn/base.py:42-89` | `initialize_tabpfn_model()` | åŠ è½½é¢„è®­ç»ƒæ¨¡å‹æƒé‡å’Œé…ç½® |
| | â””â”€ æ¨¡å‹è·¯å¾„è§£æ | | | è§£ææ¨¡å‹æ–‡ä»¶è·¯å¾„å’Œç‰ˆæœ¬ä¿¡æ¯ |
| | â””â”€ æƒé‡æ–‡ä»¶åŠ è½½ | | | åŠ è½½PyTorchæ¨¡å‹æƒé‡(.ptæ–‡ä»¶) |
| | â””â”€ é…ç½®æ–‡ä»¶è§£æ | | | è¯»å–æ¨¡å‹é…ç½®(JSON/YAMLæ ¼å¼) |
| | â””â”€ æ¨¡å‹æ¶æ„æ„å»º | | | æ ¹æ®é…ç½®æ„å»ºTransformeræ¨¡å‹æ¶æ„ |
| **3** | **è®¾å¤‡å’Œç²¾åº¦ç¡®å®š** | `src/tabpfn/base.py:92-152` | `infer_device_and_type()`, `determine_precision()` | ç¡®å®šè®¡ç®—è®¾å¤‡(CPU/GPU)å’Œæ•°å€¼ç²¾åº¦ |
| | â””â”€ è®¾å¤‡è‡ªåŠ¨æ£€æµ‹ | | | æ£€æµ‹å¯ç”¨GPUè®¾å¤‡å’ŒCUDAç‰ˆæœ¬ |
| | â””â”€ å†…å­˜å®¹é‡è¯„ä¼° | | | è¯„ä¼°GPUå†…å­˜å®¹é‡å’Œå¯ç”¨æ€§ |
| | â””â”€ ç²¾åº¦æ¨¡å¼é€‰æ‹© | | | é€‰æ‹©16ä½æˆ–32ä½æµ®ç‚¹ç²¾åº¦ |
| | â””â”€ è‡ªåŠ¨æ··åˆç²¾åº¦é…ç½® | | | é…ç½®autocastå’ŒGradScaler |
| **4** | **æ¥å£é…ç½®æ„å»º** | `src/tabpfn/config.py:14-131` | `ModelInterfaceConfig.from_user_input()` | æ„å»ºæ¨¡å‹æ¥å£é…ç½®å‚æ•° |
| | â””â”€ ç”¨æˆ·å‚æ•°è§£æ | | | è§£æç”¨æˆ·ä¼ å…¥çš„é…ç½®å‚æ•° |
| | â””â”€ é»˜è®¤å€¼å¡«å…… | | | ä¸ºæœªæŒ‡å®šå‚æ•°è®¾ç½®é»˜è®¤å€¼ |
| | â””â”€ å‚æ•°éªŒè¯ | | | éªŒè¯å‚æ•°èŒƒå›´å’Œå…¼å®¹æ€§ |
| | â””â”€ é…ç½®å¯¹è±¡åˆ›å»º | | | åˆ›å»ºModelInterfaceConfigå®ä¾‹ |
| **5** | **è¾“å…¥æ•°æ®éªŒè¯** | `src/tabpfn/utils.py:338-436` | `validate_Xy_fit()` | éªŒè¯è¾“å…¥æ•°æ®æ ¼å¼ã€å¤§å°é™åˆ¶ç­‰ |
| **5.1** | â””â”€ åŸºç¡€æ•°æ®éªŒè¯ | `src/tabpfn/misc/_sklearn_compat.py` | `validate_data()` | sklearnå…¼å®¹æ€§éªŒè¯ |
| | â””â”€ æ•°æ®ç±»å‹æ£€æŸ¥ | | | æ£€æŸ¥Xå’Œyçš„æ•°æ®ç±»å‹ |
| | â””â”€ å½¢çŠ¶ä¸€è‡´æ€§éªŒè¯ | | | éªŒè¯Xå’Œyçš„æ ·æœ¬æ•°é‡ä¸€è‡´ |
| | â””â”€ ç¨€ç–çŸ©é˜µå¤„ç† | | | å¤„ç†ç¨€ç–çŸ©é˜µ(ä¸æ”¯æŒæ—¶è½¬æ¢) |
| | â””â”€ ç¼ºå¤±å€¼æ£€æŸ¥ | | | æ£€æŸ¥å’Œå¤„ç†NaN/infå€¼ |
| **5.2** | â””â”€ é¢„è®­ç»ƒé™åˆ¶æ£€æŸ¥ | `src/tabpfn/utils.py:363-396` | æ ·æœ¬æ•°ã€ç‰¹å¾æ•°ã€ç±»åˆ«æ•°æ£€æŸ¥ | æ£€æŸ¥æ•°æ®è§„æ¨¡æ˜¯å¦è¶…å‡ºé¢„è®­ç»ƒé™åˆ¶ |
| | â””â”€ æ ·æœ¬æ•°é‡æ£€æŸ¥ | | | æ£€æŸ¥æ ·æœ¬æ•°æ˜¯å¦â‰¤10,000 |
| | â””â”€ ç‰¹å¾æ•°é‡æ£€æŸ¥ | | | æ£€æŸ¥ç‰¹å¾æ•°æ˜¯å¦â‰¤500 |
| | â””â”€ ç±»åˆ«æ•°é‡æ£€æŸ¥ | | | æ£€æŸ¥ç±»åˆ«æ•°æ˜¯å¦â‰¤10(åˆ†ç±»ä»»åŠ¡) |
| | â””â”€ é™åˆ¶å¤„ç†ç­–ç•¥ | | | æ ¹æ®ignore_pretraining_limitså†³å®šå¤„ç†æ–¹å¼ |
| **6** | **ç›®æ ‡å˜é‡å¤„ç†** | `src/tabpfn/classifier.py:437-456` | `LabelEncoder` | æ ‡ç­¾ç¼–ç å’Œç±»åˆ«ç»Ÿè®¡ |
| | â””â”€ ç±»åˆ«ç»Ÿè®¡ | | | ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡ |
| | â””â”€ æ ‡ç­¾ç¼–ç  | | | å°†å­—ç¬¦ä¸²/æ•°å€¼æ ‡ç­¾è½¬æ¢ä¸ºè¿ç»­æ•´æ•° |
| | â””â”€ ç±»åˆ«æ˜ å°„ä¿å­˜ | | | ä¿å­˜åŸå§‹æ ‡ç­¾åˆ°ç¼–ç çš„æ˜ å°„å…³ç³» |
| | â””â”€ ç±»åˆ«ä¸å¹³è¡¡æ£€æŸ¥ | | | æ£€æŸ¥ç±»åˆ«åˆ†å¸ƒæ˜¯å¦ä¸¥é‡ä¸å¹³è¡¡ |
| **7** | **æ•°æ®ç±»å‹ä¿®å¤** | `src/tabpfn/utils.py:246-316` | `_fix_dtypes()` | å¤„ç†pandas/numpyå…¼å®¹æ€§å’Œç±»å‹è½¬æ¢ |
| **7.1** | â””â”€ è¾“å…¥ç±»å‹æ£€æŸ¥ | `src/tabpfn/utils.py:250-268` | DataFrame/ndarrayå¤„ç† | è¯†åˆ«è¾“å…¥æ•°æ®ç±»å‹å¹¶è¿›è¡Œç›¸åº”å¤„ç† |
| | â””â”€ DataFrameå¤„ç† | | | ç›´æ¥ä½¿ç”¨pandas DataFrame |
| | â””â”€ æ•°å€¼æ•°ç»„å¤„ç† | | | å°†numpyæ•°ç»„è½¬æ¢ä¸ºDataFrame |
| | â””â”€ å¯¹è±¡æ•°ç»„å¤„ç† | | | å¤„ç†æ··åˆç±»å‹çš„å¯¹è±¡æ•°ç»„ |
| | â””â”€ å­—ç¬¦ä¸²æ•°ç»„æ£€æŸ¥ | | | æ£€æµ‹å¹¶æ‹’ç»å­—ç¬¦ä¸²dtypeæ•°ç»„ |
| **7.2** | â””â”€ ç±»åˆ«ç‰¹å¾æ ‡è®° | `src/tabpfn/utils.py:270-284` | ç´¢å¼•vsåˆ—åå…¼å®¹æ€§ | å¤„ç†ç±»åˆ«ç‰¹å¾ç´¢å¼•çš„å…¼å®¹æ€§é—®é¢˜ |
| | â””â”€ ç´¢å¼•ç±»å‹æ£€æŸ¥ | | | æ£€æŸ¥æ˜¯æ•°å€¼ç´¢å¼•è¿˜æ˜¯åˆ—åç´¢å¼• |
| | â””â”€ åˆ—åç±»å‹æ£€æŸ¥ | | | æ£€æŸ¥DataFrameåˆ—åç±»å‹ |
| | â””â”€ å…¼å®¹æ€§å¤„ç† | | | å¤„ç†ç´¢å¼•å’Œåˆ—åçš„å…¼å®¹æ€§ |
| | â””â”€ ç±»åˆ«ç‰¹å¾æ ‡è®° | | | å°†æŒ‡å®šåˆ—æ ‡è®°ä¸ºcategoryç±»å‹ |
| **7.3** | â””â”€ æ™ºèƒ½ç±»å‹æ¨æ–­ | `src/tabpfn/utils.py:300-316` | `convert_dtypes()` | pandasæ™ºèƒ½ç±»å‹æ¨æ–­å’Œè½¬æ¢ |
| | â””â”€ è‡ªåŠ¨ç±»å‹æ¨æ–­ | | | ä½¿ç”¨pandasçš„convert_dtypes() |
| | â””â”€ æ•°å€¼ç±»å‹ç»Ÿä¸€ | | | å°†æ•°å€¼åˆ—è½¬æ¢ä¸ºæŒ‡å®šç²¾åº¦ |
| | â””â”€ ç±»åˆ«ç±»å‹ä¿æŒ | | | ä¿æŒå·²æ ‡è®°çš„ç±»åˆ«ç‰¹å¾ç±»å‹ |
| **8** | **åºæ•°ç¼–ç å™¨åˆ›å»º** | `src/tabpfn/utils.py:318-336` | `_get_ordinal_encoder()` | åˆ›å»ºç±»åˆ«ç‰¹å¾ç¼–ç å™¨ |
| **8.1** | â””â”€ ç¼–ç å™¨é…ç½® | `src/tabpfn/utils.py:320-327` | `OrdinalEncoder` | é…ç½®åºæ•°ç¼–ç å™¨å‚æ•° |
| | â””â”€ ç±»åˆ«è‡ªåŠ¨æ¨æ–­ | | | è®¾ç½®categories="auto" |
| | â””â”€ æœªçŸ¥å€¼å¤„ç† | | | è®¾ç½®handle_unknown="use_encoded_value" |
| | â””â”€ æœªçŸ¥å€¼ç¼–ç  | | | è®¾ç½®unknown_value=-1 |
| | â””â”€ ç¼ºå¤±å€¼å¤„ç† | | | è®¾ç½®encoded_missing_value=np.nan |
| **8.2** | â””â”€ åˆ—å˜æ¢å™¨æ„å»º | `src/tabpfn/utils.py:329-336` | `ColumnTransformer` | æ„å»ºåˆ—å˜æ¢å™¨ |
| | â””â”€ å˜æ¢å™¨é…ç½® | | | é…ç½®åºæ•°ç¼–ç å™¨ä½œä¸ºå˜æ¢å™¨ |
| | â””â”€ åˆ—é€‰æ‹©å™¨ | | | ä½¿ç”¨make_column_selectoré€‰æ‹©ç±»åˆ«åˆ— |
| | â””â”€ å‰©ä½™åˆ—å¤„ç† | | | è®¾ç½®remainder=FunctionTransformer() |
| | â””â”€ è¾“å‡ºæ ¼å¼é…ç½® | | | è®¾ç½®ç¨€ç–çŸ©é˜µå’Œç‰¹å¾åé€‰é¡¹ |
| **8.3** | â””â”€ æ–‡æœ¬å’Œç¼ºå¤±å€¼å¤„ç† | `src/tabpfn/utils.py:517-545` | `_process_text_na_dataframe()` | å¤„ç†æ–‡æœ¬å’Œç¼ºå¤±å€¼ |
| | â””â”€ å­—ç¬¦ä¸²åˆ—è¯†åˆ« | | | è¯†åˆ«å­—ç¬¦ä¸²å’Œå¯¹è±¡ç±»å‹åˆ— |
| | â””â”€ ç¼ºå¤±å€¼å¡«å…… | | | ç”¨å ä½ç¬¦å¡«å……å­—ç¬¦ä¸²åˆ—çš„ç¼ºå¤±å€¼ |
| | â””â”€ åºæ•°ç¼–ç åº”ç”¨ | | | åº”ç”¨åºæ•°ç¼–ç å™¨ |
| | â””â”€ å ä½ç¬¦æ¢å¤ | | | å°†å ä½ç¬¦æ¢å¤ä¸ºNaN |
| **9** | **ç±»åˆ«ç‰¹å¾æ¨æ–­** | `src/tabpfn/utils.py:438-488` | `infer_categorical_features()` | è‡ªåŠ¨æ¨æ–­å“ªäº›ç‰¹å¾åº”è¯¥è¢«è§†ä¸ºç±»åˆ«ç‰¹å¾ |
| | â””â”€ ç”¨æˆ·æŒ‡å®šæ£€æŸ¥ | | | æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æŒ‡å®šäº†ç±»åˆ«ç‰¹å¾ |
| | â””â”€ æ ·æœ¬æ•°é‡æ£€æŸ¥ | | | æ£€æŸ¥æ ·æœ¬æ•°æ˜¯å¦è¶³å¤Ÿè¿›è¡Œæ¨æ–­ |
| | â””â”€ å”¯ä¸€å€¼ç»Ÿè®¡ | | | ç»Ÿè®¡æ¯ä¸ªç‰¹å¾çš„å”¯ä¸€å€¼æ•°é‡ |
| | â””â”€ æ¨æ–­è§„åˆ™åº”ç”¨ | | | åº”ç”¨ç±»åˆ«ç‰¹å¾æ¨æ–­è§„åˆ™ |
| | â””â”€ æ¨æ–­ç»“æœè®°å½• | | | è®°å½•æ¨æ–­å‡ºçš„ç±»åˆ«ç‰¹å¾ç´¢å¼• |
| **10** | **é›†æˆé…ç½®ç”Ÿæˆ** | `src/tabpfn/preprocessing.py:300-400` | `EnsembleConfig.generate_for_classification()` | ç”Ÿæˆå¤šä¸ªé›†æˆæˆå‘˜çš„é…ç½® |
| **10.1** | â””â”€ é¢„å¤„ç†é…ç½® | `src/tabpfn/preprocessing.py:570-590` | `default_classifier_preprocessor_configs()` | è·å–é»˜è®¤é¢„å¤„ç†é…ç½® |
| | â””â”€ é…ç½®1ç”Ÿæˆ | | | é‡åŒ–å˜æ¢+SVD+ç±»åˆ«ç¼–ç é…ç½® |
| | â””â”€ é…ç½®2ç”Ÿæˆ | | | æ— å˜æ¢+æ•°å€¼åŒ–ç±»åˆ«é…ç½® |
| | â””â”€ é…ç½®å‡è¡¡åˆ†é… | | | å°†é…ç½®å‡åŒ€åˆ†é…ç»™é›†æˆæˆå‘˜ |
| **10.2** | â””â”€ ç‰¹å¾å˜æ¢é…ç½® | `src/tabpfn/model/preprocessing.py:579-822` | `ReshapeFeatureDistributionsStep` | é…ç½®ç‰¹å¾åˆ†å¸ƒé‡å¡‘ |
| | â””â”€ å˜æ¢æ–¹æ³•é€‰æ‹© | | | é€‰æ‹©æ•°å€¼ç‰¹å¾å˜æ¢æ–¹æ³• |
| | â””â”€ å˜æ¢å‚æ•°é…ç½® | | | é…ç½®å˜æ¢çš„å…·ä½“å‚æ•° |
| | â””â”€ å…¨å±€å˜æ¢é…ç½® | | | é…ç½®SVDç­‰å…¨å±€å˜æ¢å™¨ |
| **11** | **æ¨ç†å¼•æ“åˆ›å»º** | `src/tabpfn/base.py:154-230` | `create_inference_engine()` | æ ¹æ®fit_modeåˆ›å»ºç›¸åº”çš„æ¨ç†å¼•æ“ |
| | â””â”€ å¼•æ“ç±»å‹é€‰æ‹© | | | æ ¹æ®fit_modeé€‰æ‹©å¼•æ“ç±»å‹ |
| | â””â”€ ä½å†…å­˜å¼•æ“ | | | åˆ›å»ºInferenceEngineOnDemand |
| | â””â”€ é¢„å¤„ç†ç¼“å­˜å¼•æ“ | | | åˆ›å»ºInferenceEngineCachePreprocessing |
| | â””â”€ å®Œå…¨ç¼“å­˜å¼•æ“ | | | åˆ›å»ºInferenceEngineCacheKV |
| | â””â”€ å¼•æ“å‚æ•°é…ç½® | | | é…ç½®å¼•æ“çš„å…·ä½“å‚æ•° |

#### ğŸ”® é¢„æµ‹é˜¶æ®µ (predict_probaæ–¹æ³•)

**å…¥å£æ–‡ä»¶**: `src/tabpfn/classifier.py:536-614`

| æ­¥éª¤ | åŠŸèƒ½æè¿° | æºæ–‡ä»¶ä½ç½® | å…³é”®å‡½æ•°/ç±» | å…·ä½“æ‰§è¡Œå†…å®¹ |
|------|----------|------------|-------------|-------------|
| **1** | **æ¨¡å‹çŠ¶æ€æ£€æŸ¥** | `sklearn.base` | `check_is_fitted()` | ç¡®è®¤æ¨¡å‹å·²ç»è®­ç»ƒ |
| | â””â”€ æ‹ŸåˆçŠ¶æ€éªŒè¯ | | | æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²è°ƒç”¨fitæ–¹æ³• |
| | â””â”€ å¿…è¦å±æ€§æ£€æŸ¥ | | | éªŒè¯è®­ç»ƒåçš„å…³é”®å±æ€§å­˜åœ¨ |
| | â””â”€ ç¼–ç å™¨çŠ¶æ€æ£€æŸ¥ | | | æ£€æŸ¥æ ‡ç­¾ç¼–ç å™¨å’Œé¢„å¤„ç†å™¨çŠ¶æ€ |
| **2** | **è¾“å…¥éªŒè¯** | `src/tabpfn/utils.py:439-448` | `validate_X_predict()` | éªŒè¯é¢„æµ‹æ•°æ®æ ¼å¼ |
| | â””â”€ æ•°æ®ç±»å‹éªŒè¯ | | | éªŒè¯è¾“å…¥æ•°æ®ç±»å‹ |
| | â””â”€ ç‰¹å¾æ•°é‡æ£€æŸ¥ | | | æ£€æŸ¥ç‰¹å¾æ•°æ˜¯å¦ä¸è®­ç»ƒæ—¶ä¸€è‡´ |
| | â””â”€ æ•°æ®å½¢çŠ¶éªŒè¯ | | | éªŒè¯æ•°æ®å½¢çŠ¶çš„åˆç†æ€§ |
| | â””â”€ ç¼ºå¤±å€¼æ£€æŸ¥ | | | æ£€æŸ¥ç¼ºå¤±å€¼æ¨¡å¼ |
| **3** | **æ•°æ®ç±»å‹ä¿®å¤** | `src/tabpfn/utils.py:246-316` | `_fix_dtypes()` | åº”ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„ç±»å‹ä¿®å¤ |
| | â””â”€ ç±»å‹ä¸€è‡´æ€§ä¿è¯ | | | ç¡®ä¿ä¸è®­ç»ƒæ—¶æ•°æ®ç±»å‹ä¸€è‡´ |
| | â””â”€ ç±»åˆ«ç‰¹å¾æ ‡è®° | | | åº”ç”¨è®­ç»ƒæ—¶çš„ç±»åˆ«ç‰¹å¾æ ‡è®° |
| | â””â”€ æ•°å€¼ç²¾åº¦ç»Ÿä¸€ | | | ç»Ÿä¸€æ•°å€¼ç‰¹å¾çš„ç²¾åº¦ |
| **4** | **åºæ•°ç¼–ç åº”ç”¨** | `src/tabpfn/utils.py:517-545` | `_process_text_na_dataframe()` | ä½¿ç”¨å·²è®­ç»ƒçš„ç¼–ç å™¨å˜æ¢æ•°æ® |
| | â””â”€ ç¼–ç å™¨åº”ç”¨ | | | åº”ç”¨è®­ç»ƒæ—¶æ‹Ÿåˆçš„åºæ•°ç¼–ç å™¨ |
| | â””â”€ æœªçŸ¥ç±»åˆ«å¤„ç† | | | å¤„ç†è®­ç»ƒæ—¶æœªè§è¿‡çš„ç±»åˆ«å€¼ |
| | â””â”€ ç¼ºå¤±å€¼å¤„ç† | | | å¤„ç†é¢„æµ‹æ•°æ®ä¸­çš„ç¼ºå¤±å€¼ |
| | â””â”€ æ•°æ®ç±»å‹è½¬æ¢ | | | è½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„æ•°æ®ç±»å‹ |
| **5** | **æ¨¡å‹æ¨ç†** | `src/tabpfn/inference.py` | `executor_.iter_outputs()` | æ‰§è¡Œå®é™…çš„æ¨¡å‹æ¨ç† |
| **5.1** | â””â”€ é›†æˆæˆå‘˜æ¨ç† | | | éå†æ‰€æœ‰é›†æˆé…ç½®è¿›è¡Œæ¨ç† |
| | â””â”€ é…ç½®å¾ªç¯ | | | å¯¹æ¯ä¸ªé›†æˆé…ç½®æ‰§è¡Œæ¨ç† |
| | â””â”€ é¢„å¤„ç†åº”ç”¨ | | | åº”ç”¨é…ç½®ç‰¹å®šçš„é¢„å¤„ç† |
| | â””â”€ æ¨¡å‹å‰å‘ä¼ æ’­ | | | æ‰§è¡ŒTransformeræ¨¡å‹æ¨ç† |
| | â””â”€ è¾“å‡ºæ”¶é›† | | | æ”¶é›†æ¯ä¸ªæˆå‘˜çš„è¾“å‡º |
| **5.2** | â””â”€ Softmaxæ¸©åº¦åº”ç”¨ | `src/tabpfn/classifier.py:562-566` | æ¸©åº¦ç¼©æ”¾ | åº”ç”¨softmaxæ¸©åº¦ç¼©æ”¾ |
| | â””â”€ æ¸©åº¦æ£€æŸ¥ | | | æ£€æŸ¥æ˜¯å¦éœ€è¦åº”ç”¨æ¸©åº¦ç¼©æ”¾ |
| | â””â”€ æ¸©åº¦ç¼©æ”¾è®¡ç®— | | | æ‰§è¡Œoutput/temperatureè®¡ç®— |
| | â””â”€ ç²¾åº¦è½¬æ¢ | | | è½¬æ¢ä¸ºfloatç±»å‹è¿›è¡Œè®¡ç®— |
| **5.3** | â””â”€ ç±»åˆ«æ’åˆ—é€†è½¬ | `src/tabpfn/classifier.py:568-571` | æ¢å¤åŸå§‹ç±»åˆ«é¡ºåº | æ¢å¤åŸå§‹ç±»åˆ«é¡ºåº |
| | â””â”€ æ’åˆ—æ£€æŸ¥ | | | æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç±»åˆ«æ’åˆ— |
| | â””â”€ é€†æ’åˆ—è®¡ç®— | | | è®¡ç®—æ’åˆ—çš„é€†å˜æ¢ |
| | â””â”€ è¾“å‡ºé‡æ’ | | | é‡æ–°æ’åˆ—è¾“å‡ºç»´åº¦ |
| **6** | **åå¤„ç†** | `src/tabpfn/classifier.py:573-614` | æ¦‚ç‡èšåˆå’Œæ ‡å‡†åŒ– | èšåˆé›†æˆç»“æœå¹¶è¿›è¡Œåå¤„ç† |
| **6.1** | â””â”€ æ¦‚ç‡èšåˆ | `src/tabpfn/classifier.py:573-580` | `average_before_softmax`å¤„ç† | èšåˆå¤šä¸ªé›†æˆæˆå‘˜çš„è¾“å‡º |
| | â””â”€ èšåˆç­–ç•¥é€‰æ‹© | | | é€‰æ‹©softmaxå‰æˆ–åèšåˆ |
| | â””â”€ å¼ é‡å †å  | | | å°†å¤šä¸ªè¾“å‡ºå †å ä¸ºå¼ é‡ |
| | â””â”€ å¹³å‡è®¡ç®— | | | è®¡ç®—é›†æˆæˆå‘˜çš„å¹³å‡è¾“å‡º |
| | â””â”€ Softmaxåº”ç”¨ | | | åº”ç”¨softmaxå‡½æ•° |
| **6.2** | â””â”€ æ¦‚ç‡å¹³è¡¡ | `src/tabpfn/classifier.py:582-585` | `balance_probabilities`å¤„ç† | å¹³è¡¡æ¦‚ç‡åˆ†å¸ƒ |
| | â””â”€ å¹³è¡¡æ£€æŸ¥ | | | æ£€æŸ¥æ˜¯å¦éœ€è¦æ¦‚ç‡å¹³è¡¡ |
| | â””â”€ å¹³è¡¡ç®—æ³•åº”ç”¨ | | | åº”ç”¨æ¦‚ç‡å¹³è¡¡ç®—æ³• |
| | â””â”€ åˆ†å¸ƒè°ƒæ•´ | | | è°ƒæ•´æ¦‚ç‡åˆ†å¸ƒ |
| **6.3** | â””â”€ ç²¾åº¦å¤„ç† | `src/tabpfn/classifier.py:590-594` | 16ä½ç²¾åº¦å¤„ç† | å¤„ç†æ•°å€¼ç²¾åº¦ |
| | â””â”€ ç²¾åº¦æ£€æŸ¥ | | | æ£€æŸ¥æ˜¯å¦éœ€è¦16ä½ç²¾åº¦ |
| | â””â”€ ç²¾åº¦è½¬æ¢ | | | è½¬æ¢ä¸ºåŠç²¾åº¦æµ®ç‚¹æ•° |
| | â””â”€ ç²¾åº¦éªŒè¯ | | | éªŒè¯ç²¾åº¦è½¬æ¢ç»“æœ |
| **6.4** | â””â”€ æ¦‚ç‡æ ‡å‡†åŒ– | `src/tabpfn/classifier.py:597` | ç¡®ä¿æ¦‚ç‡å’Œä¸º1 | æœ€ç»ˆæ¦‚ç‡æ ‡å‡†åŒ– |
| | â””â”€ æ¦‚ç‡å’Œè®¡ç®— | | | è®¡ç®—æ¯è¡Œæ¦‚ç‡çš„å’Œ |
| | â””â”€ æ ‡å‡†åŒ–è®¡ç®— | | | é™¤ä»¥æ¦‚ç‡å’Œè¿›è¡Œæ ‡å‡†åŒ– |
| | â””â”€ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥ | | | æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§ |
| | â””â”€ ç»“æœè½¬æ¢ | | | è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶è¿”å› |

#### ğŸ”§ å†…éƒ¨é¢„å¤„ç†æ¨¡å—è¯¦è§£

**æ ¸å¿ƒé¢„å¤„ç†æ­¥éª¤** (`src/tabpfn/model/preprocessing.py`)

| æ¨¡å— | åŠŸèƒ½ | æ–‡ä»¶ä½ç½® | å…³é”®æ–¹æ³• | å…·ä½“å®ç°ç»†èŠ‚ |
|------|------|----------|----------|-------------|
| **RemoveConstantFeaturesStep** | ç§»é™¤å¸¸é‡ç‰¹å¾ | `src/tabpfn/model/preprocessing.py:441-471` | `_fit()`, `_transform()` | æ£€æµ‹å¹¶ç§»é™¤æ‰€æœ‰å€¼ç›¸åŒçš„ç‰¹å¾ |
| | â””â”€ å¸¸é‡æ£€æµ‹ | | | æ£€æŸ¥æ¯ä¸ªç‰¹å¾æ˜¯å¦æ‰€æœ‰å€¼ç›¸åŒ |
| | â””â”€ ç‰¹å¾é€‰æ‹© | | | é€‰æ‹©éå¸¸é‡ç‰¹å¾çš„ç´¢å¼• |
| | â””â”€ å˜æ¢åº”ç”¨ | | | åº”ç”¨ç‰¹å¾é€‰æ‹©åˆ°æ–°æ•°æ® |
| **EncodeCategoricalFeaturesStep** | ç±»åˆ«ç‰¹å¾ç¼–ç  | `src/tabpfn/model/preprocessing.py:998-1176` | `_fit_transform()` | å¯¹ç±»åˆ«ç‰¹å¾è¿›è¡Œç¼–ç  |
| | â””â”€ ç¼–ç æ–¹æ³•é€‰æ‹© | | | æ ¹æ®é…ç½®é€‰æ‹©ç¼–ç æ–¹æ³• |
| | â””â”€ åºæ•°ç¼–ç  | | | åº”ç”¨åºæ•°ç¼–ç å™¨ |
| | â””â”€ ç‹¬çƒ­ç¼–ç  | | | åº”ç”¨ç‹¬çƒ­ç¼–ç å™¨(æœ‰é™åˆ¶) |
| | â””â”€ æ•°å€¼åŒ–å¤„ç† | | | å°†ç±»åˆ«ç‰¹å¾å½“ä½œæ•°å€¼å¤„ç† |
| **InputNormalizationEncoderStep** | è¾“å…¥æ ‡å‡†åŒ– | `src/tabpfn/model/encoders.py:676-800` | `_fit()`, `_transform()` | å¯¹è¾“å…¥æ•°æ®è¿›è¡Œæ ‡å‡†åŒ– |
| | â””â”€ å¼‚å¸¸å€¼æ£€æµ‹ | | | æ£€æµ‹å’Œç§»é™¤å¼‚å¸¸å€¼ |
| | â””â”€ æ ‡å‡†åŒ–è®¡ç®— | | | è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·® |
| | â””â”€ æ ‡å‡†åŒ–åº”ç”¨ | | | åº”ç”¨z-scoreæ ‡å‡†åŒ– |
| **ReshapeFeatureDistributionsStep** | ç‰¹å¾åˆ†å¸ƒé‡å¡‘ | `src/tabpfn/model/preprocessing.py:579-822` | `get_adaptive_preprocessors()` | é‡å¡‘ç‰¹å¾åˆ†å¸ƒ |
| | â””â”€ å˜æ¢æ–¹æ³•é€‰æ‹© | | | é€‰æ‹©åˆé€‚çš„åˆ†å¸ƒå˜æ¢æ–¹æ³• |
| | â””â”€ åˆ†ä½æ•°å˜æ¢ | | | åº”ç”¨åˆ†ä½æ•°å˜æ¢ |
| | â””â”€ å¹‚å˜æ¢ | | | åº”ç”¨Box-Coxç­‰å¹‚å˜æ¢ |
| | â””â”€ KDIå˜æ¢ | | | åº”ç”¨æ ¸å¯†åº¦ä¼°è®¡å˜æ¢ |

#### ğŸ“Š é…ç½®å’Œå¸¸é‡è¯¦è§£

**å…³é”®é…ç½®æ–‡ä»¶**:
- **ModelInterfaceConfig**: `src/tabpfn/config.py:14-131`
  - æœ€å¤§æ ·æœ¬æ•°é™åˆ¶: 10,000
  - æœ€å¤§ç‰¹å¾æ•°é™åˆ¶: 500
  - æœ€å¤§ç±»åˆ«æ•°é™åˆ¶: 10
  - ç±»åˆ«ç‰¹å¾æ¨æ–­é˜ˆå€¼é…ç½®
- **é¢„å¤„ç†å¸¸é‡**: `src/tabpfn/constants.py`
  - æ•°æ®ç±»å‹å¸¸é‡
  - ç¼ºå¤±å€¼å ä½ç¬¦
  - ç‰¹å¾å˜æ¢å‚æ•°
- **é»˜è®¤é…ç½®**: `src/tabpfn/preprocessing.py:570-590`
  - åˆ†ç±»å™¨é»˜è®¤é¢„å¤„ç†é…ç½®
  - å›å½’å™¨é»˜è®¤é¢„å¤„ç†é…ç½®
  - é›†æˆé…ç½®ç”Ÿæˆå‚æ•°

#### ğŸ¯ æ‰§è¡Œæµç¨‹çš„å…³é”®æ£€æŸ¥ç‚¹

**æ•°æ®éªŒè¯æ£€æŸ¥ç‚¹**:
```python
# æ–‡ä»¶: src/tabpfn/utils.py:338-436
def validate_Xy_fit():
    # 1. åŸºç¡€éªŒè¯
    X, y = validate_data(estimator, X=X, y=y, 
                        accept_sparse=False,           # ä¸æ¥å—ç¨€ç–çŸ©é˜µ
                        ensure_all_finite="allow-nan", # å…è®¸NaNå€¼
                        ensure_min_samples=2,          # è‡³å°‘2ä¸ªæ ·æœ¬
                        ensure_min_features=1,         # è‡³å°‘1ä¸ªç‰¹å¾
                        multi_output=False,            # ä¸æ”¯æŒå¤šè¾“å‡º
                        y_numeric=False)               # yå¯ä»¥æ˜¯å­—ç¬¦ä¸²
    
    # 2. ç‰¹å¾æ•°é‡æ£€æŸ¥
    if X.shape[1] > max_num_features:
        if ignore_pretraining_limits:
            warnings.warn(f"ç‰¹å¾æ•° {X.shape[1]} è¶…å‡ºé¢„è®­ç»ƒé™åˆ¶ {max_num_features}")
        else:
            raise ValueError(f"ç‰¹å¾æ•°è¶…é™ï¼Œè¯·è®¾ç½® ignore_pretraining_limits=True")
    
    # 3. æ ·æœ¬æ•°é‡æ£€æŸ¥  
    if X.shape[0] > max_num_samples:
        if ignore_pretraining_limits:
            warnings.warn(f"æ ·æœ¬æ•° {X.shape[0]} è¶…å‡ºé¢„è®­ç»ƒé™åˆ¶ {max_num_samples}")
        else:
            raise ValueError(f"æ ·æœ¬æ•°è¶…é™ï¼Œè¯·è®¾ç½® ignore_pretraining_limits=True")
    
    # 4. åˆ†ç±»ç›®æ ‡æ£€æŸ¥
    if is_classifier(estimator):
        check_classification_targets(y)
        unique_classes = len(np.unique(y))
        if unique_classes > MAX_NUMBER_OF_CLASSES:
            raise ValueError(f"ç±»åˆ«æ•° {unique_classes} è¶…å‡ºé™åˆ¶ {MAX_NUMBER_OF_CLASSES}")
```

**ç±»åˆ«ç‰¹å¾æ¨æ–­æ£€æŸ¥ç‚¹**:
```python
# æ–‡ä»¶: src/tabpfn/utils.py:438-488
def infer_categorical_features():
    maybe_categoricals = () if provided is None else provided
    large_enough_x_to_infer_categorical = X.shape[0] > min_samples_for_inference
    indices = []
    
    for ix, col in enumerate(X.T):
        unique_values = len(np.unique(col[~pd.isna(col)]))  # æ’é™¤NaNè®¡ç®—å”¯ä¸€å€¼
        
        if ix in maybe_categoricals:
            # ç”¨æˆ·æŒ‡å®šæ£€æŸ¥
            if unique_values <= max_unique_for_category:
                indices.append(ix)
                print(f"ç‰¹å¾ {ix}: ç”¨æˆ·æŒ‡å®šä¸ºç±»åˆ«ç‰¹å¾ï¼Œå”¯ä¸€å€¼æ•°={unique_values}")
            else:
                print(f"ç‰¹å¾ {ix}: ç”¨æˆ·æŒ‡å®šä¸ºç±»åˆ«ç‰¹å¾ä½†å”¯ä¸€å€¼è¿‡å¤š({unique_values})")
        elif (large_enough_x_to_infer_categorical and 
              unique_values < min_unique_for_numerical):
            # è‡ªåŠ¨æ¨æ–­æ£€æŸ¥
            indices.append(ix)
            print(f"ç‰¹å¾ {ix}: è‡ªåŠ¨æ¨æ–­ä¸ºç±»åˆ«ç‰¹å¾ï¼Œå”¯ä¸€å€¼æ•°={unique_values}")
        else:
            print(f"ç‰¹å¾ {ix}: åˆ¤æ–­ä¸ºæ•°å€¼ç‰¹å¾ï¼Œå”¯ä¸€å€¼æ•°={unique_values}")
    
    return indices
```

**é¢„è®­ç»ƒé™åˆ¶æ£€æŸ¥ç‚¹**:
```python
# æ–‡ä»¶: src/tabpfn/config.py:14-131
# ç¡¬ç¼–ç çš„é¢„è®­ç»ƒé™åˆ¶
MAX_NUMBER_OF_SAMPLES = 10_000      # æ ·æœ¬æ•°é™åˆ¶
MAX_NUMBER_OF_FEATURES = 500        # ç‰¹å¾æ•°é™åˆ¶  
MAX_NUMBER_OF_CLASSES = 10          # ç±»åˆ«æ•°é™åˆ¶

# ç±»åˆ«ç‰¹å¾æ¨æ–­å‚æ•°
MIN_NUMBER_SAMPLES_FOR_CATEGORICAL_INFERENCE = 100  # æ¨æ–­æ‰€éœ€æœ€å°æ ·æœ¬æ•°
MAX_UNIQUE_FOR_CATEGORICAL_FEATURES = 20           # ç±»åˆ«ç‰¹å¾æœ€å¤§å”¯ä¸€å€¼æ•°
MIN_UNIQUE_FOR_NUMERICAL_FEATURES = 3             # æ•°å€¼ç‰¹å¾æœ€å°å”¯ä¸€å€¼æ•°

# å¼‚å¸¸å€¼å¤„ç†å‚æ•°
OUTLIER_REMOVAL_STD = "auto"        # å¼‚å¸¸å€¼ç§»é™¤æ ‡å‡†å·®å€æ•°
POLYNOMIAL_FEATURES = "no"          # å¤šé¡¹å¼ç‰¹å¾ç”Ÿæˆ
SUBSAMPLE_SAMPLES = None            # å­é‡‡æ ·è®¾ç½®
FINGERPRINT_FEATURE = False         # æ˜¯å¦æ·»åŠ æŒ‡çº¹ç‰¹å¾
```

#### ğŸš¨ å¸¸è§é—®é¢˜å’Œè°ƒè¯•ç‚¹

**1. æ•°æ®æ ¼å¼é—®é¢˜**
- **æ£€æŸ¥ä½ç½®**: `src/tabpfn/utils.py:246-316` (`_fix_dtypes`)
- **å¸¸è§é”™è¯¯**: 
  - å­—ç¬¦ä¸²dtypeçš„numpyæ•°ç»„
  - æ··åˆæ•°æ®ç±»å‹çš„DataFrame
  - ä¸ä¸€è‡´çš„åˆ—åç±»å‹
- **è§£å†³æ–¹æ¡ˆ**: 
  - è½¬æ¢ä¸ºpandas DataFrame
  - ç»Ÿä¸€æ•°æ®ç±»å‹
  - è§„èŒƒåŒ–åˆ—å

**2. é¢„è®­ç»ƒé™åˆ¶è¶…å‡º**
- **æ£€æŸ¥ä½ç½®**: `src/tabpfn/utils.py:363-396`
- **å¸¸è§é”™è¯¯**:
  - æ ·æœ¬æ•°è¶…è¿‡10,000
  - ç‰¹å¾æ•°è¶…è¿‡500
  - ç±»åˆ«æ•°è¶…è¿‡10
- **è§£å†³æ–¹æ¡ˆ**: 
  - è®¾ç½® `ignore_pretraining_limits=True`
  - æ•°æ®é™ç»´æˆ–é‡‡æ ·
  - ç‰¹å¾é€‰æ‹©

**3. ç±»åˆ«ç‰¹å¾è¯†åˆ«é”™è¯¯**
- **æ£€æŸ¥ä½ç½®**: `src/tabpfn/utils.py:438-488`
- **å¸¸è§é”™è¯¯**:
  - æ•°å€¼ç‰¹å¾è¢«è¯¯åˆ¤ä¸ºç±»åˆ«ç‰¹å¾
  - ç±»åˆ«ç‰¹å¾æœªè¢«è¯†åˆ«
  - å”¯ä¸€å€¼é˜ˆå€¼è®¾ç½®ä¸å½“
- **è§£å†³æ–¹æ¡ˆ**: 
  - æ‰‹åŠ¨æŒ‡å®š `categorical_features_indices`
  - è°ƒæ•´æ¨æ–­é˜ˆå€¼å‚æ•°
  - æ£€æŸ¥æ•°æ®è´¨é‡

**4. å†…å­˜ä¸è¶³**
- **æ£€æŸ¥ä½ç½®**: `src/tabpfn/base.py:154-230`
- **å¸¸è§é”™è¯¯**:
  - GPUå†…å­˜ä¸è¶³
  - é›†æˆæˆå‘˜è¿‡å¤š
  - ç¼“å­˜æ¨¡å¼ä¸å½“
- **è§£å†³æ–¹æ¡ˆ**: 
  - è°ƒæ•´ `fit_mode` ä¸º "low_memory"
  - å‡å°‘ `n_estimators`
  - å¯ç”¨ `memory_saving_mode`

#### ğŸ“ ä½¿ç”¨ç¤ºä¾‹å’ŒéªŒè¯

**åŸºæœ¬ä½¿ç”¨æµç¨‹**:
```python
# 1. å¯¼å…¥å’Œåˆå§‹åŒ–
from tabpfn import TabPFNClassifier
model = TabPFNClassifier(
    n_estimators=4,                              # é›†æˆæˆå‘˜æ•°é‡
    categorical_features_indices=None,           # è‡ªåŠ¨æ¨æ–­ç±»åˆ«ç‰¹å¾
    device="auto",                              # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
    fit_mode="fit_preprocessors",               # é¢„å¤„ç†ç¼“å­˜æ¨¡å¼
    random_state=42,                            # éšæœºç§å­
    ignore_pretraining_limits=False,            # ä¸å¿½ç•¥é¢„è®­ç»ƒé™åˆ¶
    softmax_temperature=1.0,                    # softmaxæ¸©åº¦
    inference_precision="32",                   # æ¨ç†ç²¾åº¦
    memory_saving_mode="auto",                  # å†…å­˜èŠ‚çœæ¨¡å¼
    balance_probabilities=False,                # ä¸å¹³è¡¡æ¦‚ç‡
    average_before_softmax=False                # softmaxåå¹³å‡
)

# 2. è®­ç»ƒ (è§¦å‘å®Œæ•´é¢„å¤„ç†æµç¨‹)
print("å¼€å§‹è®­ç»ƒ...")
model.fit(X_train, y_train)
print("è®­ç»ƒå®Œæˆ")

# 3. é¢„æµ‹ (åº”ç”¨å·²å­¦ä¹ çš„é¢„å¤„ç†)
print("å¼€å§‹é¢„æµ‹...")
predictions = model.predict_proba(X_test)
print(f"é¢„æµ‹å®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {predictions.shape}")
```

**è°ƒè¯•å’ŒéªŒè¯è¦ç‚¹**:
```python
# æ£€æŸ¥æ¨æ–­çš„ç±»åˆ«ç‰¹å¾
print("æ¨æ–­çš„ç±»åˆ«ç‰¹å¾ç´¢å¼•:", model.inferred_categorical_indices_)
print("ç±»åˆ«ç‰¹å¾æ•°é‡:", len(model.inferred_categorical_indices_))

# æ£€æŸ¥ç±»åˆ«åˆ†å¸ƒ
print("ç±»åˆ«æ•°é‡:", model.n_classes_)
print("ç±»åˆ«æ ‡ç­¾:", model.classes_)
print("ç±»åˆ«åˆ†å¸ƒ:", model.class_counts_)

# æ£€æŸ¥ç‰¹å¾ä¿¡æ¯
print("ç‰¹å¾æ•°é‡:", model.n_features_in_)
print("ç‰¹å¾åç§°:", getattr(model, 'feature_names_in_', None))

# æ£€æŸ¥è®¾å¤‡å’Œç²¾åº¦
print("è®¡ç®—è®¾å¤‡:", model.device_)
print("ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦:", model.use_autocast_)
print("æ¨ç†ç²¾åº¦:", model.inference_precision)

# æ£€æŸ¥é›†æˆé…ç½®
print("é›†æˆæˆå‘˜æ•°é‡:", model.n_estimators)
print("é›†æˆé…ç½®æ•°é‡:", len(model.ensemble_configs_))

# æ£€æŸ¥é¢„å¤„ç†å™¨çŠ¶æ€
print("é¢„å¤„ç†å™¨ç±»å‹:", type(model.preprocessor_))
print("æ ‡ç­¾ç¼–ç å™¨:", type(model.label_encoder_))

# æ€§èƒ½ç›‘æ§
import time
start_time = time.time()
predictions = model.predict_proba(X_test)
end_time = time.time()
print(f"é¢„æµ‹æ—¶é—´: {end_time - start_time:.4f} ç§’")
print(f"æ¯æ ·æœ¬é¢„æµ‹æ—¶é—´: {(end_time - start_time) / len(X_test):.6f} ç§’")
```

**é«˜çº§è°ƒè¯•æŠ€å·§**:
```python
# 1. å•æ­¥è°ƒè¯•é¢„å¤„ç†æµç¨‹
import pandas as pd
import numpy as np

# æ¨¡æ‹Ÿæ•°æ®ç±»å‹ä¿®å¤
X_fixed = model._fix_dtypes(X_test, cat_indices=model.categorical_features_indices)
print("æ•°æ®ç±»å‹ä¿®å¤å:", X_fixed.dtypes)

# æ¨¡æ‹Ÿåºæ•°ç¼–ç 
X_encoded = model._process_text_na_dataframe(X_fixed, ord_encoder=model.preprocessor_)
print("åºæ•°ç¼–ç åå½¢çŠ¶:", X_encoded.shape)

# 2. æ£€æŸ¥é›†æˆé…ç½®è¯¦æƒ…
for i, config in enumerate(model.ensemble_configs_):
    print(f"é…ç½® {i}:")
    print(f"  é¢„å¤„ç†æ–¹æ³•: {config.preprocess_config.name}")
    print(f"  ç±»åˆ«ç¼–ç : {config.preprocess_config.categorical_name}")
    print(f"  ç‰¹å¾ä½ç§»: {config.feature_shift_count}")
    print(f"  ç±»åˆ«æ’åˆ—: {config.class_permutation}")
    print(f"  å­é‡‡æ ·: {config.subsample_ix is not None}")

# 3. å†…å­˜ä½¿ç”¨ç›‘æ§
import psutil
import torch

def check_memory():
    # CPUå†…å­˜
    cpu_memory = psutil.virtual_memory()
    print(f"CPUå†…å­˜ä½¿ç”¨: {cpu_memory.percent}%")
    
    # GPUå†…å­˜
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.memory_allocated() / 1024**3
        gpu_memory_max = torch.cuda.max_memory_allocated() / 1024**3
        print(f"GPUå†…å­˜ä½¿ç”¨: {gpu_memory:.2f} GB")
        print(f"GPUå†…å­˜å³°å€¼: {gpu_memory_max:.2f} GB")

# è®­ç»ƒå‰åå†…å­˜æ£€æŸ¥
print("è®­ç»ƒå‰:")
check_memory()
model.fit(X_train, y_train)
print("è®­ç»ƒå:")
check_memory()
predictions = model.predict_proba(X_test)
print("é¢„æµ‹å:")
check_memory()
```

---

## ğŸ—ï¸ é¢„å¤„ç†æµç¨‹æ¶æ„

TabPFNçš„æ•°æ®é¢„å¤„ç†å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š

```
åŸå§‹æ•°æ® â†’ è¾“å…¥éªŒè¯ â†’ æ•°æ®ç±»å‹ä¿®å¤ â†’ ç±»åˆ«ç‰¹å¾æ¨æ–­ â†’ åºæ•°ç¼–ç  â†’ é›†æˆé…ç½®ç”Ÿæˆ â†’ æ¨ç†å¼•æ“
```

## ğŸ”§ è¯¦ç»†é¢„å¤„ç†æ­¥éª¤

### 1. è¾“å…¥æ•°æ®éªŒè¯ (`validate_Xy_fit`)

#### 1.1 åŸºæœ¬éªŒè¯
```python
def validate_Xy_fit(X, y, estimator, *, max_num_features, max_num_samples, 
                   ensure_y_numeric=False, ignore_pretraining_limits=False):
```

**åŠŸèƒ½**ï¼š
- ä½¿ç”¨sklearnçš„`validate_data()`è¿›è¡ŒåŸºç¡€éªŒè¯
- æ£€æŸ¥æ•°æ®ç»´åº¦å’Œç±»å‹
- éªŒè¯é¢„è®­ç»ƒé™åˆ¶

**å…³é”®å‚æ•°**ï¼š
- `accept_sparse=False`ï¼šä¸æ¥å—ç¨€ç–çŸ©é˜µ
- `ensure_all_finite="allow-nan"`ï¼šå…è®¸NaNå€¼å­˜åœ¨
- `ensure_min_samples=2`ï¼šè‡³å°‘éœ€è¦2ä¸ªæ ·æœ¬
- `ensure_min_features=1`ï¼šè‡³å°‘éœ€è¦1ä¸ªç‰¹å¾

#### 1.2 é¢„è®­ç»ƒé™åˆ¶æ£€æŸ¥
```python
# é»˜è®¤é™åˆ¶
MAX_NUMBER_OF_SAMPLES = 10_000     # æœ€å¤§æ ·æœ¬æ•°
MAX_NUMBER_OF_FEATURES = 500       # æœ€å¤§ç‰¹å¾æ•°
MAX_NUMBER_OF_CLASSES = 10         # æœ€å¤§ç±»åˆ«æ•°ï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰
```

**è¡Œä¸º**ï¼š
- å¦‚æœè¶…å‡ºé™åˆ¶ä¸”`ignore_pretraining_limits=False`ï¼ŒæŠ›å‡ºé”™è¯¯
- å¦‚æœè¶…å‡ºé™åˆ¶ä¸”`ignore_pretraining_limits=True`ï¼Œå‘å‡ºè­¦å‘Šä½†ç»§ç»­æ‰§è¡Œ

### 2. ç›®æ ‡å˜é‡å¤„ç†ï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰

#### 2.1 æ ‡ç­¾ç¼–ç 
```python
# ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
_, counts = np.unique(y, return_counts=True)
self.class_counts_ = counts

# ä½¿ç”¨LabelEncoderè¿›è¡Œåºæ•°ç¼–ç 
self.label_encoder_ = LabelEncoder()
y = self.label_encoder_.fit_transform(y)
self.classes_ = self.label_encoder_.classes_
self.n_classes_ = len(self.classes_)
```

#### 2.2 ç±»åˆ«æ•°é‡é™åˆ¶
```python
if self.n_classes_ > self.interface_config_.MAX_NUMBER_OF_CLASSES:
    raise ValueError(f"Number of classes {self.n_classes_} exceeds the maximal number")
```

### 3. æ•°æ®ç±»å‹ä¿®å¤ (`_fix_dtypes`)

#### 3.1 è¾“å…¥ç±»å‹å¤„ç†
```python
def _fix_dtypes(X, cat_indices, numeric_dtype="float64"):
```

**æ”¯æŒçš„è¾“å…¥ç±»å‹**ï¼š
- **pandas.DataFrame**ï¼šç›´æ¥å¤„ç†ï¼Œå¯ç”¨ç±»å‹æ¨æ–­
- **numpy.ndarrayï¼ˆæ•°å€¼å‹ï¼‰**ï¼šåŒ…è£…ä¸ºDataFrameï¼ŒæŒ‡å®šæ•°å€¼ç±»å‹
- **numpy.ndarrayï¼ˆå¯¹è±¡å‹ï¼‰**ï¼šåŒ…è£…ä¸ºDataFrameï¼Œå¯ç”¨ç±»å‹æ¨æ–­
- **numpy.ndarrayï¼ˆå­—ç¬¦ä¸²å‹ï¼‰**ï¼šæŠ›å‡ºé”™è¯¯ï¼ˆä¸æ”¯æŒï¼‰

#### 3.2 ç±»åˆ«ç‰¹å¾æ ‡è®°
```python
if cat_indices is not None:
    # å¤„ç†æ•°å€¼ç´¢å¼• vs å­—ç¬¦ä¸²åˆ—åçš„å…¼å®¹æ€§
    is_numeric_indices = all(isinstance(i, (int, np.integer)) for i in cat_indices)
    columns_are_numeric = all(isinstance(col, (int, np.integer)) for col in X.columns)
    use_iloc = is_numeric_indices and not columns_are_numeric
    
    if use_iloc:
        X.iloc[:, cat_indices] = X.iloc[:, cat_indices].astype("category")
    else:
        X[cat_indices] = X[cat_indices].astype("category")
```

#### 3.3 æ•°æ®ç±»å‹è½¬æ¢
```python
# å¯ç”¨pandasçš„æ™ºèƒ½ç±»å‹æ¨æ–­
if convert_dtype:
    X = X.convert_dtypes()

# å°†æ•°å€¼åˆ—è½¬æ¢ä¸ºæŒ‡å®šçš„æµ®ç‚¹ç±»å‹
integer_columns = X.select_dtypes(include=["number"]).columns
if len(integer_columns) > 0:
    X[integer_columns] = X[integer_columns].astype(numeric_dtype)
```

### 4. åºæ•°ç¼–ç  (`_get_ordinal_encoder`)

#### 4.1 ç¼–ç å™¨é…ç½®
```python
def _get_ordinal_encoder(*, numpy_dtype=DEFAULT_NUMPY_PREPROCESSING_DTYPE):
    oe = OrdinalEncoder(
        categories="auto",                    # è‡ªåŠ¨æ¨æ–­ç±»åˆ«
        dtype=numpy_dtype,                   # è¾“å‡ºæ•°æ®ç±»å‹
        handle_unknown="use_encoded_value",   # å¤„ç†æœªçŸ¥ç±»åˆ«
        unknown_value=-1,                    # æœªçŸ¥ç±»åˆ«çš„ç¼–ç å€¼
        encoded_missing_value=np.nan,        # ç¼ºå¤±å€¼ä¿æŒä¸ºNaN
    )
```

#### 4.2 åˆ—å˜æ¢å™¨
```python
# é€‰æ‹©éœ€è¦ç¼–ç çš„åˆ—ç±»å‹
to_convert = ["category", "string"]
return ColumnTransformer(
    transformers=[("encoder", oe, make_column_selector(dtype_include=to_convert))],
    remainder=FunctionTransformer(),  # å…¶ä»–åˆ—ä¿æŒä¸å˜
    sparse_threshold=0.0,            # ä¸ä½¿ç”¨ç¨€ç–çŸ©é˜µ
    verbose_feature_names_out=False  # ä¸ä½¿ç”¨è¯¦ç»†ç‰¹å¾å
)
```

#### 4.3 æ–‡æœ¬å’Œç¼ºå¤±å€¼å¤„ç†
```python
def _process_text_na_dataframe(X, placeholder=NA_PLACEHOLDER, ord_encoder=None, 
                              *, fit_encoder=False):
    # 1. å¤„ç†å­—ç¬¦ä¸²åˆ—çš„ç¼ºå¤±å€¼
    string_cols = X.select_dtypes(include=["string", "object"]).columns
    if len(string_cols) > 0:
        X[string_cols] = X[string_cols].fillna(placeholder)
    
    # 2. åº”ç”¨åºæ•°ç¼–ç 
    if fit_encoder and ord_encoder is not None:
        X_encoded = ord_encoder.fit_transform(X)
    elif ord_encoder is not None:
        X_encoded = ord_encoder.transform(X)
    else:
        X_encoded = X
    
    # 3. å°†å ä½ç¬¦æ¢å¤ä¸ºNaN
    string_cols_ix = [X.columns.get_loc(col) for col in string_cols]
    placeholder_mask = X[string_cols] == placeholder
    X_encoded[:, string_cols_ix] = np.where(
        placeholder_mask, np.nan, X_encoded[:, string_cols_ix]
    )
    
    return X_encoded.astype(np.float64)
```

### 5. ç±»åˆ«ç‰¹å¾æ¨æ–­ (`infer_categorical_features`)

#### 5.1 æ¨æ–­é€»è¾‘
```python
def infer_categorical_features(X, *, provided, min_samples_for_inference, 
                              max_unique_for_category, min_unique_for_numerical):
    maybe_categoricals = () if provided is None else provided
    large_enough_x_to_infer_categorical = X.shape[0] > min_samples_for_inference
    indices = []
    
    for ix, col in enumerate(X.T):
        if ix in maybe_categoricals:
            # ç”¨æˆ·æŒ‡å®šçš„ç±»åˆ«ç‰¹å¾ï¼šæ£€æŸ¥å”¯ä¸€å€¼æ•°é‡
            if len(np.unique(col)) <= max_unique_for_category:
                indices.append(ix)
        elif (large_enough_x_to_infer_categorical and 
              len(np.unique(col)) < min_unique_for_numerical):
            # è‡ªåŠ¨æ¨æ–­ï¼šæ ·æœ¬è¶³å¤Ÿä¸”å”¯ä¸€å€¼è¾ƒå°‘
            indices.append(ix)
    
    return indices
```

#### 5.2 é»˜è®¤å‚æ•°é…ç½®
```python
# é»˜è®¤é…ç½®å€¼
MIN_NUMBER_SAMPLES_FOR_CATEGORICAL_INFERENCE = 100  # æ¨æ–­æ‰€éœ€æœ€å°æ ·æœ¬æ•°
MAX_UNIQUE_FOR_CATEGORICAL_FEATURES = 20           # ç±»åˆ«ç‰¹å¾æœ€å¤§å”¯ä¸€å€¼æ•°
MIN_UNIQUE_FOR_NUMERICAL_FEATURES = 3             # æ•°å€¼ç‰¹å¾æœ€å°å”¯ä¸€å€¼æ•°
```

### 6. é›†æˆé…ç½®ç”Ÿæˆ (`EnsembleConfig.generate_for_classification`)

#### 6.1 é›†æˆç­–ç•¥
TabPFNä½¿ç”¨é›†æˆæ–¹æ³•æ¥æé«˜é¢„æµ‹æ€§èƒ½ï¼Œé€šè¿‡ç”Ÿæˆå¤šä¸ªä¸åŒçš„"æç¤º"ï¼ˆpromptsï¼‰ï¼š

```python
ensemble_configs = EnsembleConfig.generate_for_classification(
    n=self.n_estimators,                    # é›†æˆæˆå‘˜æ•°é‡ï¼ˆé»˜è®¤4ï¼‰
    subsample_size=subsample_size,           # å­é‡‡æ ·å¤§å°
    add_fingerprint_feature=fingerprint,    # æ·»åŠ æŒ‡çº¹ç‰¹å¾
    feature_shift_decoder=feature_shift,    # ç‰¹å¾ä½ç§»æ–¹æ³•
    polynomial_features=polynomial_features, # å¤šé¡¹å¼ç‰¹å¾
    max_index=len(X),                       # æœ€å¤§ç´¢å¼•
    preprocessor_configs=preprocessor_configs, # é¢„å¤„ç†é…ç½®
    class_shift_method=class_shift_method,   # ç±»åˆ«ä½ç§»æ–¹æ³•
    n_classes=self.n_classes_,              # ç±»åˆ«æ•°é‡
    random_state=rng,                       # éšæœºçŠ¶æ€
)
```

#### 6.2 é¢„å¤„ç†é…ç½®
```python
# é»˜è®¤åˆ†ç±»é¢„å¤„ç†é…ç½®
def default_classifier_preprocessor_configs():
    return [
        PreprocessorConfig(
            categorical_transform="ordinal_common_categories",
            numerical_transform="quantile_uniform_to_normal",
            global_transform="svd"
        ),
        PreprocessorConfig(
            categorical_transform="ordinal",
            numerical_transform=None,
            global_transform=None
        )
    ]
```

### 7. é«˜çº§é¢„å¤„ç†æ­¥éª¤

#### 7.1 ç‰¹å¾é¢„å¤„ç†å˜æ¢å™¨
TabPFNå†…éƒ¨ä½¿ç”¨å¤šç§ç‰¹å¾é¢„å¤„ç†æ­¥éª¤ï¼š

**ç§»é™¤å¸¸é‡ç‰¹å¾** (`RemoveConstantFeaturesStep`)ï¼š
```python
class RemoveConstantFeaturesStep:
    def _fit(self, X, categorical_features):
        # æ£€æµ‹å¸¸é‡ç‰¹å¾ï¼ˆæ‰€æœ‰å€¼ç›¸åŒï¼‰
        sel_ = ((X[0:1, :] == X).mean(axis=0) < 1.0).tolist()
        if not any(sel_):
            raise ValueError("All features are constant!")
        self.sel_ = sel_
```

**ç±»åˆ«ç‰¹å¾ç¼–ç ** (`EncodeCategoricalFeaturesStep`)ï¼š
```python
class EncodeCategoricalFeaturesStep:
    def _get_transformer(self, X, categorical_features):
        # æ ¹æ®é…ç½®é€‰æ‹©ç¼–ç æ–¹å¼
        if self.categorical_transform_name.startswith("ordinal"):
            # åºæ•°ç¼–ç 
            ct = ColumnTransformer([
                ("ordinal_encoder", OrdinalEncoder(
                    handle_unknown="use_encoded_value",
                    unknown_value=np.nan
                ), categorical_features)
            ], remainder="passthrough")
        elif self.categorical_transform_name == "onehot":
            # ç‹¬çƒ­ç¼–ç ï¼ˆæœ‰å¤§å°é™åˆ¶ï¼‰
            ct = ColumnTransformer([...])
```

**è¾“å…¥æ ‡å‡†åŒ–** (`InputNormalizationEncoderStep`)ï¼š
```python
class InputNormalizationEncoderStep:
    def _fit(self, x, single_eval_pos):
        # å¼‚å¸¸å€¼ç§»é™¤
        if self.remove_outliers:
            x, (lower, upper) = remove_outliers(
                x, normalize_positions=normalize_position,
                n_sigma=self.remove_outliers_sigma
            )
        
        # æ•°æ®æ ‡å‡†åŒ–
        if self.normalize_x:
            x, (mean, std) = normalize_data(
                x, normalize_positions=normalize_position,
                return_scaling=True
            )
```

### 8. æ¨ç†å¼•æ“åˆ›å»º

#### 8.1 å¼•æ“ç±»å‹
æ ¹æ®`fit_mode`å‚æ•°é€‰æ‹©ä¸åŒçš„æ¨ç†å¼•æ“ï¼š

```python
def create_inference_engine(fit_mode, ...):
    if fit_mode == "low_memory":
        # ä½å†…å­˜æ¨¡å¼ï¼šæŒ‰éœ€é¢„å¤„ç†
        engine = InferenceEngineOnDemand(...)
    elif fit_mode == "fit_preprocessors":
        # é¢„å¤„ç†ç¼“å­˜æ¨¡å¼ï¼šç¼“å­˜é¢„å¤„ç†ç»“æœ
        engine = InferenceEngineCachePreprocessing(...)
    elif fit_mode == "fit_with_cache":
        # å®Œå…¨ç¼“å­˜æ¨¡å¼ï¼šç¼“å­˜é¢„å¤„ç†å’ŒKV
        engine = InferenceEngineCacheKV(...)
```

#### 8.2 æ¨¡å¼ç‰¹ç‚¹
- **low_memory**ï¼šæœ€èŠ‚çœå†…å­˜ï¼Œä½†é‡å¤é¢„å¤„ç†è¾ƒæ…¢
- **fit_preprocessors**ï¼šå¹³è¡¡å†…å­˜å’Œé€Ÿåº¦ï¼Œé€‚åˆå¤šæ¬¡é¢„æµ‹
- **fit_with_cache**ï¼šæœ€å¿«é€Ÿåº¦ï¼Œä½†éœ€è¦å¤§é‡GPUå†…å­˜

## ğŸ”„ é¢„æµ‹æ—¶çš„é¢„å¤„ç†æµç¨‹

### 1. è¾“å…¥éªŒè¯
```python
def predict_proba(self, X):
    check_is_fitted(self)  # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²è®­ç»ƒ
    X = validate_X_predict(X, self)  # éªŒè¯é¢„æµ‹æ•°æ®
```

### 2. æ•°æ®ç±»å‹ä¿®å¤å’Œç¼–ç 
```python
# åº”ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„æ•°æ®ç±»å‹ä¿®å¤
X = _fix_dtypes(X, cat_indices=self.categorical_features_indices)

# ä½¿ç”¨å·²è®­ç»ƒçš„ç¼–ç å™¨è¿›è¡Œå˜æ¢ï¼ˆä¸é‡æ–°æ‹Ÿåˆï¼‰
X = _process_text_na_dataframe(X, ord_encoder=self.preprocessor_)
```

### 3. æ¨¡å‹æ¨ç†
```python
outputs = []
for output, config in self.executor_.iter_outputs(X, device=self.device_, autocast=self.use_autocast_):
    # åº”ç”¨softmaxæ¸©åº¦
    if self.softmax_temperature != 1:
        output = output[:, :self.n_classes_].float() / self.softmax_temperature
    
    # é€†è½¬ç±»åˆ«æ’åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if config.class_permutation is not None:
        output = output[..., config.class_permutation]
    
    outputs.append(output)
```

## ğŸ“Š å…³é”®é…ç½®å‚æ•°

### ModelInterfaceConfig ä¸»è¦å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `MAX_NUMBER_OF_SAMPLES` | 10,000 | æœ€å¤§æ ·æœ¬æ•°é™åˆ¶ |
| `MAX_NUMBER_OF_FEATURES` | 500 | æœ€å¤§ç‰¹å¾æ•°é™åˆ¶ |
| `MAX_NUMBER_OF_CLASSES` | 10 | æœ€å¤§ç±»åˆ«æ•°é™åˆ¶ |
| `MIN_NUMBER_SAMPLES_FOR_CATEGORICAL_INFERENCE` | 100 | ç±»åˆ«ç‰¹å¾æ¨æ–­æœ€å°æ ·æœ¬æ•° |
| `MAX_UNIQUE_FOR_CATEGORICAL_FEATURES` | 20 | ç±»åˆ«ç‰¹å¾æœ€å¤§å”¯ä¸€å€¼æ•° |
| `MIN_UNIQUE_FOR_NUMERICAL_FEATURES` | 3 | æ•°å€¼ç‰¹å¾æœ€å°å”¯ä¸€å€¼æ•° |
| `OUTLIER_REMOVAL_STD` | "auto" | å¼‚å¸¸å€¼ç§»é™¤æ ‡å‡†å·®å€æ•° |
| `POLYNOMIAL_FEATURES` | "no" | å¤šé¡¹å¼ç‰¹å¾ç”Ÿæˆ |
| `SUBSAMPLE_SAMPLES` | None | å­é‡‡æ ·è®¾ç½® |
| `FINGERPRINT_FEATURE` | False | æ˜¯å¦æ·»åŠ æŒ‡çº¹ç‰¹å¾ |

## ğŸš¨ é‡è¦æ³¨æ„äº‹é¡¹

### 1. æ•°æ®å…¼å®¹æ€§
- **æ”¯æŒçš„è¾“å…¥æ ¼å¼**ï¼špandas DataFrameã€numpy ndarray
- **ä¸æ”¯æŒçš„æ ¼å¼**ï¼šç¨€ç–çŸ©é˜µã€å­—ç¬¦ä¸²dtypeçš„numpyæ•°ç»„
- **ç¼ºå¤±å€¼å¤„ç†**ï¼šNaNå€¼è¢«ä¿ç•™å¹¶ç‰¹æ®Šå¤„ç†

### 2. ç±»åˆ«ç‰¹å¾å¤„ç†
- **è‡ªåŠ¨æ¨æ–­**ï¼šåŸºäºå”¯ä¸€å€¼æ•°é‡å’Œæ ·æœ¬å¤§å°
- **ç”¨æˆ·æŒ‡å®š**ï¼šé€šè¿‡`categorical_features_indices`å‚æ•°
- **ç¼–ç æ–¹å¼**ï¼šä¸»è¦ä½¿ç”¨åºæ•°ç¼–ç ï¼Œé¿å…ç»´åº¦çˆ†ç‚¸

### 3. é¢„è®­ç»ƒé™åˆ¶
- **æ ·æœ¬æ•°**ï¼šå»ºè®® â‰¤ 10,000
- **ç‰¹å¾æ•°**ï¼šå»ºè®® â‰¤ 500  
- **ç±»åˆ«æ•°**ï¼šç¡¬é™åˆ¶ â‰¤ 10ï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰
- **å¯å¿½ç•¥**ï¼šè®¾ç½®`ignore_pretraining_limits=True`

### 4. å†…å­˜ç®¡ç†
- **fit_modeé€‰æ‹©**ï¼šæ ¹æ®GPUå†…å­˜å’Œä½¿ç”¨æ¨¡å¼é€‰æ‹©
- **memory_saving_mode**ï¼šè‡ªåŠ¨æˆ–æ‰‹åŠ¨è®¾ç½®å†…å­˜èŠ‚çœæ¨¡å¼
- **batchå¤„ç†**ï¼šå¤§æ•°æ®é›†éœ€è¦æ‰‹åŠ¨åˆ†æ‰¹å¤„ç†

## ğŸ”§ ä¸ä¼ ç»ŸMLé¢„å¤„ç†çš„åŒºåˆ«

### 1. è‡ªåŠ¨åŒ–ç¨‹åº¦æ›´é«˜
- è‡ªåŠ¨æ¨æ–­ç±»åˆ«ç‰¹å¾
- è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„ç¼–ç æ–¹å¼
- è‡ªåŠ¨å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼

### 2. æ·±åº¦å­¦ä¹ ç‰¹åŒ–
- é’ˆå¯¹Transformeræ¶æ„ä¼˜åŒ–
- æ”¯æŒåºåˆ—åŒ–çš„ç‰¹å¾è¡¨ç¤º
- å†…ç½®é›†æˆå­¦ä¹ æœºåˆ¶

### 3. é¢„è®­ç»ƒçº¦æŸ
- å—é¢„è®­ç»ƒæ•°æ®åˆ†å¸ƒé™åˆ¶
- å¯¹æ•°æ®è§„æ¨¡æœ‰æ˜ç¡®é™åˆ¶
- éœ€è¦è€ƒè™‘åŸŸé€‚åº”é—®é¢˜

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®å‡†å¤‡
- æå‰æ¸…ç†æ˜æ˜¾çš„å¼‚å¸¸å€¼
- åˆç†è®¾ç½®ç±»åˆ«ç‰¹å¾ç´¢å¼•
- æ§åˆ¶æ•°æ®é›†å¤§å°åœ¨é™åˆ¶èŒƒå›´å†…

### 2. é…ç½®ä¼˜åŒ–
- æ ¹æ®ç¡¬ä»¶é€‰æ‹©åˆé€‚çš„`fit_mode`
- è°ƒæ•´`inference_precision`å¹³è¡¡é€Ÿåº¦å’Œç²¾åº¦
- åˆç†è®¾ç½®`n_estimators`

### 3. å†…å­˜ç®¡ç†
- ç›‘æ§GPUå†…å­˜ä½¿ç”¨
- é€‚å½“ä½¿ç”¨`memory_saving_mode`
- å¤§æ•°æ®é›†è€ƒè™‘åˆ†æ‰¹å¤„ç†

---

**æ€»ç»“**ï¼šTabPFNçš„é¢„å¤„ç†æµç¨‹è™½ç„¶å¤æ‚ï¼Œä½†å¤§éƒ¨åˆ†æ­¥éª¤éƒ½æ˜¯è‡ªåŠ¨åŒ–çš„ã€‚ç†è§£è¿™ä¸ªæµç¨‹æœ‰åŠ©äºæ›´å¥½åœ°å‡†å¤‡æ•°æ®ã€è°ƒä¼˜å‚æ•°ï¼Œå¹¶åœ¨é‡åˆ°é—®é¢˜æ—¶è¿›è¡Œæœ‰æ•ˆçš„è°ƒè¯•ã€‚å¯¹äºåŒ»ç–—æ•°æ®ç­‰ç‰¹å®šé¢†åŸŸçš„åº”ç”¨ï¼Œéœ€è¦ç‰¹åˆ«æ³¨æ„ç±»åˆ«ç‰¹å¾çš„æ­£ç¡®è¯†åˆ«å’Œå¤„ç†ã€‚

## ğŸ¯ TabPFNçš„å¤šæ ·åŒ–æ•°æ®å¤„ç†ç­–ç•¥è¯¦è§£

TabPFNé€šè¿‡ç”Ÿæˆå¤šä¸ªä¸åŒçš„**é›†æˆé…ç½®**ï¼ˆEnsembleConfigï¼‰æ¥å®ç°å¤šæ ·åŒ–çš„æ•°æ®å¤„ç†ï¼Œæ¯ä¸ªé…ç½®éƒ½ä¼šäº§ç”Ÿä¸€ä¸ªä¸åŒçš„"æ•°æ®è§†è§’"ï¼Œæœ€ç»ˆé€šè¿‡é›†æˆå­¦ä¹ æå‡æ¨¡å‹æ€§èƒ½ã€‚

### ğŸ”§ é›†æˆé…ç½®ç”Ÿæˆæœºåˆ¶

#### ğŸ“Š æºæ–‡ä»¶ä½ç½®
- **ä¸»è¦å®ç°**ï¼š`src/tabpfn/preprocessing.py:259-369`
- **è°ƒç”¨ä½ç½®**ï¼š`src/tabpfn/classifier.py:484-503`

#### ğŸ² äº”å¤§éšæœºåŒ–ç­–ç•¥

TabPFNé€šè¿‡ä»¥ä¸‹äº”ä¸ªç»´åº¦çš„éšæœºåŒ–æ¥ç”Ÿæˆä¸åŒçš„æ•°æ®å¤„ç†æ–¹å¼ï¼š

### 1. ğŸ”„ ç‰¹å¾å˜æ¢ç­–ç•¥ (Feature Transformations)

#### é»˜è®¤åˆ†ç±»å™¨é¢„å¤„ç†é…ç½®
```python
# æºæ–‡ä»¶ï¼šsrc/tabpfn/preprocessing.py:174-201
def default_classifier_preprocessor_configs():
    return [
        # é…ç½®1ï¼šé‡åŒ–å˜æ¢ + SVDé™ç»´
        PreprocessorConfig(
            "quantile_uni_coarse",           # ç²—ç²’åº¦åˆ†ä½æ•°å˜æ¢
            append_original=True,            # ä¿ç•™åŸå§‹ç‰¹å¾
            categorical_name="ordinal_very_common_categories_shuffled",  # ç±»åˆ«ç‰¹å¾åºæ•°ç¼–ç 
            global_transformer_name="svd",   # SVDå…¨å±€å˜æ¢
            subsample_features=-1,           # ä¸è¿›è¡Œç‰¹å¾å­é‡‡æ ·
        ),
        # é…ç½®2ï¼šæ— å˜æ¢ + ç±»åˆ«ç‰¹å¾æ•°å€¼åŒ–
        PreprocessorConfig(
            "none",                          # ä¸è¿›è¡Œæ•°å€¼å˜æ¢
            categorical_name="numeric",      # ç±»åˆ«ç‰¹å¾å½“ä½œæ•°å€¼å¤„ç†
            subsample_features=-1,
        ),
    ]
```

#### å¯ç”¨çš„ç‰¹å¾å˜æ¢ç±»å‹ï¼ˆ25ç§å®Œæ•´åˆ—è¡¨ï¼‰

**æºæ–‡ä»¶ä½ç½®**ï¼š`src/tabpfn/preprocessing.py:51-85`

```python
# å®Œæ•´çš„25ç§æ•°å€¼ç‰¹å¾å˜æ¢æ–¹æ³•
name: Literal[
    # åŸºç¡€å˜æ¢
    "none",                      # ä»…æ ‡å‡†åŒ–ï¼Œæ— å…¶ä»–å˜æ¢
    "robust",                    # é²æ£’æ ‡å‡†åŒ–ï¼ˆä¸­ä½æ•°+MADï¼‰
    
    # å¹‚å˜æ¢ç³»åˆ—
    "power",                     # Box-Coxå¹‚å˜æ¢
    "safepower",                 # å®‰å…¨å¹‚å˜æ¢ï¼ˆå¤„ç†è´Ÿå€¼ï¼‰
    "power_box",                 # Box-Coxå˜æ¢å˜ä½“
    
    # åˆ†ä½æ•°å˜æ¢ç³»åˆ—
    "quantile_norm",             # æ­£æ€åˆ†ä½æ•°å˜æ¢
    "quantile_uni_coarse",       # ç²—ç²’åº¦å‡åŒ€åˆ†ä½æ•°å˜æ¢
    "quantile_uni_fine",         # ç²¾ç»†å‡åŒ€åˆ†ä½æ•°å˜æ¢
    "quantile_uni",              # æ ‡å‡†å‡åŒ€åˆ†ä½æ•°å˜æ¢
    
    # KDIï¼ˆæ ¸å¯†åº¦ä¼°è®¡ï¼‰å˜æ¢ç³»åˆ—
    "kdi",                       # æ ‡å‡†KDIå˜æ¢
    "kdi_random_alpha",          # éšæœºalphaçš„KDIå˜æ¢
    "kdi_uni",                   # å‡åŒ€KDIå˜æ¢
    "kdi_random_alpha_uni",      # éšæœºalphaå‡åŒ€KDIå˜æ¢
    "kdi_norm",                  # æ­£æ€KDIå˜æ¢
    "kdi_random_alpha_norm",     # éšæœºalphaæ­£æ€KDIå˜æ¢
    "kdi_random_alpha_uni_coarse",  # éšæœºalphaå‡åŒ€ç²—ç²’åº¦KDIå˜æ¢
    "kdi_uni_coarse",            # å‡åŒ€ç²—ç²’åº¦KDIå˜æ¢
    "kdi_norm_coarse",           # æ­£æ€ç²—ç²’åº¦KDIå˜æ¢
    "kdi_random_alpha_norm_coarse", # éšæœºalphaæ­£æ€ç²—ç²’åº¦KDIå˜æ¢
    
    # ç‰¹æ®Šå˜æ¢
    "per_feature",               # æ¯ä¸ªç‰¹å¾ç‹¬ç«‹é€‰æ‹©æœ€ä½³å˜æ¢
    "per_feature_coarse",        # æ¯ä¸ªç‰¹å¾ç‹¬ç«‹é€‰æ‹©ï¼ˆç²—ç²’åº¦ï¼‰
    "per_feature_norm",          # æ¯ä¸ªç‰¹å¾ç‹¬ç«‹é€‰æ‹©ï¼ˆæ­£æ€ç›®æ ‡ï¼‰
    "per_feature_uni",           # æ¯ä¸ªç‰¹å¾ç‹¬ç«‹é€‰æ‹©ï¼ˆå‡åŒ€ç›®æ ‡ï¼‰
    "per_feature_norm_coarse",   # æ¯ä¸ªç‰¹å¾ç‹¬ç«‹é€‰æ‹©ï¼ˆæ­£æ€ç²—ç²’åº¦ï¼‰
    "per_feature_uni_coarse",    # æ¯ä¸ªç‰¹å¾ç‹¬ç«‹é€‰æ‹©ï¼ˆå‡åŒ€ç²—ç²’åº¦ï¼‰
]
```

#### é»˜è®¤ä½¿ç”¨çš„å˜æ¢æ–¹æ³•

**åˆ†ç±»ä»»åŠ¡é»˜è®¤é…ç½®**ï¼š
```python
# é…ç½®1ï¼šä¿å®ˆç­–ç•¥
"quantile_uni_coarse",   # ç²—ç²’åº¦åˆ†ä½æ•°å˜æ¢
# é…ç½®2ï¼šæ¿€è¿›ç­–ç•¥  
"none",                  # æ— å˜æ¢ï¼ˆä»…æ ‡å‡†åŒ–ï¼‰
```

**å›å½’ä»»åŠ¡é»˜è®¤é…ç½®**ï¼š
```python
# é…ç½®1ï¼šç²¾ç»†ç­–ç•¥
"quantile_uni",          # ç²¾ç»†åˆ†ä½æ•°å˜æ¢
# é…ç½®2ï¼šå¹‚å˜æ¢ç­–ç•¥
"safepower",             # å®‰å…¨å¹‚å˜æ¢
```

#### ä¸ºä»€ä¹ˆé»˜è®¤åªç”¨ä¸¤ç§æ–¹æ³•ï¼Ÿ

è™½ç„¶TabPFNå®šä¹‰äº†25ç§æ•°å€¼å˜æ¢æ–¹æ³•ï¼Œä½†é»˜è®¤é…ç½®åªä½¿ç”¨å…¶ä¸­2ç§ï¼ŒåŸå› å¦‚ä¸‹ï¼š

1. **ç»éªŒä¼˜åŒ–**ï¼šç»è¿‡å¤§é‡å®éªŒéªŒè¯ï¼Œè¿™ä¸¤ç§ç»„åˆåœ¨å¤šæ•°æƒ…å†µä¸‹æ•ˆæœæœ€ä½³
2. **äº’è¡¥æ€§ç­–ç•¥**ï¼šä¸€ä¸ªä¿å®ˆï¼ˆé‡åŒ–å˜æ¢ï¼‰ï¼Œä¸€ä¸ªæ¿€è¿›ï¼ˆæ— å˜æ¢ï¼‰ï¼Œè¦†ç›–ä¸åŒæ•°æ®åˆ†å¸ƒ
3. **è®¡ç®—æ•ˆç‡**ï¼šå‡å°‘ä¸å¿…è¦çš„è®¡ç®—å¼€é”€ï¼Œæé«˜è®­ç»ƒé€Ÿåº¦
4. **å¹³è¡¡æ€§è€ƒè™‘**ï¼šé¿å…è¿‡åº¦å¤æ‚åŒ–ï¼Œåœ¨æ€§èƒ½å’Œç®€æ´æ€§é—´å–å¾—å¹³è¡¡

#### å¦‚ä½•ä½¿ç”¨å…¶ä»–å˜æ¢æ–¹æ³•ï¼Ÿ

```python
# è‡ªå®šä¹‰é¢„å¤„ç†é…ç½®ä½¿ç”¨å…¶ä»–å˜æ¢æ–¹æ³•
from tabpfn.preprocessing import PreprocessorConfig

custom_configs = [
    PreprocessorConfig("kdi_random_alpha", categorical_name="ordinal"),
    PreprocessorConfig("power_box", categorical_name="onehot"),
    PreprocessorConfig("per_feature", categorical_name="numeric"),
]

model = TabPFNClassifier(preprocessor_configs=custom_configs)
```

### 2. ğŸ¯ ç±»åˆ«ç‰¹å¾ç¼–ç ç­–ç•¥

#### ç¼–ç æ–¹å¼é€‰æ‹©
```python
# æºæ–‡ä»¶ï¼šsrc/tabpfn/preprocessing.py:84-100
categorical_name: Literal[
    "none",                              # ä¿æŒåŸæ ·
    "numeric",                           # å½“ä½œæ•°å€¼ç‰¹å¾å¤„ç†
    "onehot",                           # ç‹¬çƒ­ç¼–ç 
    "ordinal",                          # åºæ•°ç¼–ç ï¼ˆæŒ‰é¢‘ç‡æ’åºï¼‰
    "ordinal_shuffled",                 # åºæ•°ç¼–ç ï¼ˆéšæœºé¡ºåºï¼‰
    "ordinal_very_common_categories_shuffled"  # ä»…å¯¹å¸¸è§ç±»åˆ«ç¼–ç 
]
```

### 3. ğŸ”€ ç‰¹å¾ä½ç½®æ‰“ä¹± (Feature Shifting)

#### å®ç°æœºåˆ¶
```python
# æºæ–‡ä»¶ï¼šsrc/tabpfn/preprocessing.py:289-291
start = rng.integers(0, MAXIMUM_FEATURE_SHIFT)  # éšæœºèµ·å§‹ä½ç½®
featshifts = np.arange(start, start + n)        # ç”Ÿæˆä½ç§»åºåˆ—
featshifts = rng.choice(featshifts, size=n, replace=False)  # éšæœºé€‰æ‹©
```

#### æ‰“ä¹±æ–¹å¼
- **shuffle**ï¼šå®Œå…¨éšæœºæ‰“ä¹±ç‰¹å¾é¡ºåº
- **rotate**ï¼šç¯å½¢æ—‹è½¬ç‰¹å¾ä½ç½®
- **None**ï¼šä¸è¿›è¡Œç‰¹å¾ä½ç½®å˜æ¢

### 4. ğŸ·ï¸ ç±»åˆ«æ ‡ç­¾æ’åˆ— (Class Permutation)

#### åˆ†ç±»ä»»åŠ¡çš„ç±»åˆ«æ‰“ä¹±
```python
# æºæ–‡ä»¶ï¼šsrc/tabpfn/preprocessing.py:293-313
if class_shift_method == "rotate":
    # ç¯å½¢æ—‹è½¬ç±»åˆ«æ ‡ç­¾
    arange = np.arange(0, n_classes)
    shifts = rng.permutation(n_classes).tolist()
    class_permutations = [np.roll(arange, s) for s in shifts]
    
elif class_shift_method == "shuffle":
    # å®Œå…¨éšæœºæ‰“ä¹±ç±»åˆ«æ ‡ç­¾
    noise = rng.random((n * CLASS_SHUFFLE_OVERESTIMATE_FACTOR, n_classes))
    shufflings = np.argsort(noise, axis=1)
    uniqs = np.unique(shufflings, axis=0)  # ç¡®ä¿å”¯ä¸€æ€§
```

### 5. ğŸ“Š æ•°æ®å­é‡‡æ · (Subsampling)

#### å­é‡‡æ ·ç­–ç•¥
```python
# æºæ–‡ä»¶ï¼šsrc/tabpfn/preprocessing.py:315-329
if isinstance(subsample_size, (int, float)):
    subsamples = generate_index_permutations(
        n=n,                    # é›†æˆæˆå‘˜æ•°é‡
        max_index=max_index,    # æœ€å¤§æ ·æœ¬ç´¢å¼•
        subsample=subsample_size,  # å­é‡‡æ ·æ¯”ä¾‹æˆ–æ•°é‡
        random_state=static_seed,
    )
```

### ğŸ”„ æ•°æ®å¤„ç†ç®¡é“æ„å»º

#### ç®¡é“æ­¥éª¤åºåˆ—
```python
# æºæ–‡ä»¶ï¼šsrc/tabpfn/preprocessing.py:452-502
def to_pipeline(self) -> SequentialFeatureTransformer:
    steps = []
    
    # 1. å¤šé¡¹å¼ç‰¹å¾ç”Ÿæˆï¼ˆå¯é€‰ï¼‰
    if use_poly_features:
        steps.append(NanHandlingPolynomialFeaturesStep(...))
    
    # 2. æ ¸å¿ƒé¢„å¤„ç†æ­¥éª¤
    steps.extend([
        RemoveConstantFeaturesStep(),              # ç§»é™¤å¸¸é‡ç‰¹å¾
        ReshapeFeatureDistributionsStep(...),     # ç‰¹å¾åˆ†å¸ƒé‡å¡‘
        EncodeCategoricalFeaturesStep(...),       # ç±»åˆ«ç‰¹å¾ç¼–ç 
    ])
    
    # 3. æŒ‡çº¹ç‰¹å¾æ·»åŠ ï¼ˆå¯é€‰ï¼‰
    if self.add_fingerprint_feature:
        steps.append(AddFingerprintFeaturesStep(...))
    
    # 4. ç‰¹å¾ä½ç½®æ‰“ä¹±
    steps.append(ShuffleFeaturesStep(...))
    
    return SequentialFeatureTransformer(steps)
```

### ğŸ² é›†æˆæˆå‘˜é…ç½®åˆ†é…

#### å‡è¡¡åˆ†é…ç­–ç•¥
```python
# æºæ–‡ä»¶ï¼šsrc/tabpfn/preprocessing.py:331-345
balance_count = n // len(preprocessor_configs)  # æ¯ä¸ªé…ç½®çš„åŸºç¡€é‡å¤æ¬¡æ•°

# 1. å‡åŒ€åˆ†é…é¢„å¤„ç†é…ç½®
configs_ = balance(preprocessor_configs, balance_count)

# 2. éšæœºå¡«å……å‰©ä½™ä½ç½®
leftover = n - len(configs_)
if leftover > 0:
    picks = rng.choice(len(preprocessor_configs), size=leftover, replace=True)
    configs_.extend(preprocessor_configs[i] for i in picks)
```

### ğŸ“ˆ å®é™…åº”ç”¨ç¤ºä¾‹

#### 4ä¸ªé›†æˆæˆå‘˜çš„é…ç½®ç¤ºä¾‹
å‡è®¾`n_estimators=4`ï¼ŒTabPFNä¼šç”Ÿæˆå¦‚ä¸‹é…ç½®ï¼š

```python
# æˆå‘˜1ï¼šé‡åŒ–å˜æ¢ + SVD + ç‰¹å¾æ‰“ä¹± + ç±»åˆ«æ—‹è½¬ + å­é‡‡æ ·
EnsembleConfig(
    preprocess_config=quantile_uni_coarse_config,
    feature_shift_count=42,
    feature_shift_decoder="shuffle",
    class_permutation=[0,2,1],  # ç±»åˆ«é‡æ’åˆ—
    subsample_ix=[0,2,4,6,...], # å­é‡‡æ ·ç´¢å¼•
)

# æˆå‘˜2ï¼šæ— å˜æ¢ + æ•°å€¼åŒ–ç±»åˆ« + ç‰¹å¾æ—‹è½¬ + ç±»åˆ«æ‰“ä¹±
EnsembleConfig(
    preprocess_config=none_config,
    feature_shift_count=17,
    feature_shift_decoder="rotate",
    class_permutation=[1,0,2],
    subsample_ix=None,  # ä¸å­é‡‡æ ·
)

# æˆå‘˜3å’Œ4ï¼šé‡å¤ä¸Šè¿°é…ç½®ä½†ä½¿ç”¨ä¸åŒçš„éšæœºç§å­
```

### ğŸ”§ é¢„æµ‹æ—¶çš„ä¸€è‡´æ€§å¤„ç†

#### é¢„æµ‹é˜¶æ®µçš„é…ç½®åº”ç”¨
```python
# æºæ–‡ä»¶ï¼šsrc/tabpfn/classifier.py:553-584
for output, config in self.executor_.iter_outputs(X, device=self.device_, autocast=self.use_autocast_):
    # 1. åº”ç”¨ç›¸åŒçš„é¢„å¤„ç†ç®¡é“
    # 2. æ¨¡å‹å‰å‘ä¼ æ’­
    # 3. åå‘åº”ç”¨ç±»åˆ«æ’åˆ—
    if config.class_permutation is not None:
        output = output[..., config.class_permutation]  # æ¢å¤åŸå§‹ç±»åˆ«é¡ºåº
    
    outputs.append(output)

# 4. é›†æˆæ‰€æœ‰è¾“å‡º
if self.average_before_softmax:
    output = torch.stack(outputs).mean(dim=0)
    output = torch.nn.functional.softmax(output, dim=1)
else:
    outputs = [torch.nn.functional.softmax(o, dim=1) for o in outputs]
    output = torch.stack(outputs).mean(dim=0)
```

### ğŸ¯ è®¾è®¡ä¼˜åŠ¿

#### 1. **æ•°æ®å¢å¼ºæ•ˆæœ**
- æ¯ä¸ªé›†æˆæˆå‘˜çœ‹åˆ°çš„æ˜¯æ•°æ®çš„ä¸åŒ"è§†è§’"
- å¢åŠ äº†æ¨¡å‹å¯¹æ•°æ®å˜åŒ–çš„é²æ£’æ€§

#### 2. **ç‰¹å¾å·¥ç¨‹è‡ªåŠ¨åŒ–**
- è‡ªåŠ¨å°è¯•å¤šç§ç‰¹å¾å˜æ¢ç»„åˆ
- æ— éœ€æ‰‹åŠ¨è°ƒå‚å³å¯è·å¾—è¾ƒå¥½æ•ˆæœ

#### 3. **ä¸å˜æ€§å­¦ä¹ **
- é€šè¿‡ç‰¹å¾å’Œç±»åˆ«æ‰“ä¹±å­¦ä¹ ä½ç½®ä¸å˜æ€§
- æå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›

#### 4. **é›†æˆå­¦ä¹ ä¼˜åŠ¿**
- å‡å°‘è¿‡æ‹Ÿåˆé£é™©
- æé«˜é¢„æµ‹ç¨³å®šæ€§å’Œå‡†ç¡®æ€§

è¿™ç§å¤šæ ·åŒ–çš„æ•°æ®å¤„ç†ç­–ç•¥æ˜¯TabPFNèƒ½å¤Ÿåœ¨æ— éœ€å¤§é‡è°ƒå‚çš„æƒ…å†µä¸‹è·å¾—è‰¯å¥½æ€§èƒ½çš„å…³é”®åŸå› ä¹‹ä¸€ã€‚

## ğŸ”¬ å®Œæ•´é¢„å¤„ç†æµç¨‹çš„æ·±åº¦è§£æ

### ğŸ“‹ é¢„å¤„ç†æµç¨‹çš„å…­ä¸ªé˜¶æ®µ

TabPFNçš„é¢„å¤„ç†å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å…­ä¸ªé€å±‚é€’è¿›çš„é˜¶æ®µï¼š

```
é˜¶æ®µ1: æ•°æ®éªŒè¯ä¸å‡†å¤‡ â†’ é˜¶æ®µ2: åŸºç¡€é¢„å¤„ç† â†’ é˜¶æ®µ3: é›†æˆé…ç½®ç”Ÿæˆ â†’ 
é˜¶æ®µ4: ç®¡é“æ„å»ºä¸æ‹Ÿåˆ â†’ é˜¶æ®µ5: æ¨ç†å¼•æ“åˆ›å»º â†’ é˜¶æ®µ6: é¢„æµ‹æ‰§è¡Œ
```

### ğŸ¯ é˜¶æ®µ1: æ•°æ®éªŒè¯ä¸å‡†å¤‡ (Data Validation & Preparation)

#### 1.1 è¾“å…¥æ•°æ®æ£€æŸ¥æµç¨‹
```python
# æºæ–‡ä»¶: src/tabpfn/utils.py:338-436
def validate_Xy_fit(X, y, estimator, *, max_num_features, max_num_samples):
    # æ­¥éª¤1: sklearnåŸºç¡€éªŒè¯
    X, y = validate_data(
        estimator, X=X, y=y,
        accept_sparse=False,           # ä¸æ¥å—ç¨€ç–çŸ©é˜µ
        ensure_all_finite="allow-nan", # å…è®¸NaNå€¼
        ensure_min_samples=2,          # è‡³å°‘2ä¸ªæ ·æœ¬
        ensure_min_features=1,         # è‡³å°‘1ä¸ªç‰¹å¾
        multi_output=False,            # ä¸æ”¯æŒå¤šè¾“å‡º
        y_numeric=False                # yå¯ä»¥æ˜¯å­—ç¬¦ä¸²æ ‡ç­¾
    )
    
    # æ­¥éª¤2: é¢„è®­ç»ƒé™åˆ¶æ£€æŸ¥
    if X.shape[1] > max_num_features:
        if ignore_pretraining_limits:
            warnings.warn(f"ç‰¹å¾æ•° {X.shape[1]} è¶…å‡ºé¢„è®­ç»ƒé™åˆ¶ {max_num_features}")
        else:
            raise ValueError(f"ç‰¹å¾æ•°è¶…é™ï¼Œè¯·è®¾ç½® ignore_pretraining_limits=True")
    
    # æ­¥éª¤3: æ ·æœ¬æ•°é‡æ£€æŸ¥
    if X.shape[0] > max_num_samples:
        # ç±»ä¼¼çš„æ£€æŸ¥å’Œè­¦å‘Šé€»è¾‘
    
    # æ­¥éª¤4: åˆ†ç±»ç›®æ ‡æ£€æŸ¥
    if is_classifier(estimator):
        check_classification_targets(y)
        if len(np.unique(y)) > MAX_NUMBER_OF_CLASSES:
            raise ValueError(f"ç±»åˆ«æ•°è¶…å‡ºé™åˆ¶")
```

#### 1.2 ç›®æ ‡å˜é‡é¢„å¤„ç†
```python
# åˆ†ç±»ä»»åŠ¡çš„æ ‡ç­¾ç¼–ç 
if hasattr(self, 'label_encoder_'):
    # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
    unique_labels, counts = np.unique(y, return_counts=True)
    self.class_counts_ = counts
    
    # æ ‡ç­¾ç¼–ç 
    self.label_encoder_ = LabelEncoder()
    y_encoded = self.label_encoder_.fit_transform(y)
    self.classes_ = self.label_encoder_.classes_
    self.n_classes_ = len(self.classes_)
```

### ğŸ› ï¸ é˜¶æ®µ2: åŸºç¡€é¢„å¤„ç† (Basic Preprocessing)

#### 2.1 æ•°æ®ç±»å‹ä¿®å¤è¯¦ç»†æµç¨‹
```python
# æºæ–‡ä»¶: src/tabpfn/utils.py:246-316
def _fix_dtypes(X, cat_indices, numeric_dtype="float64"):
    # æ­¥éª¤1: è¾“å…¥ç±»å‹è¯†åˆ«å’Œè½¬æ¢
    if isinstance(X, pd.DataFrame):
        # DataFrame: ç›´æ¥ä½¿ç”¨ï¼Œæ”¯æŒåˆ—åç´¢å¼•
        pass
    elif isinstance(X, np.ndarray):
        if X.dtype.kind in ['U', 'S']:  # å­—ç¬¦ä¸²æ•°ç»„
            raise ValueError("ä¸æ”¯æŒå­—ç¬¦ä¸²dtypeçš„numpyæ•°ç»„ï¼Œè¯·è½¬æ¢ä¸ºDataFrame")
        elif X.dtype == 'object':
            # å¯¹è±¡æ•°ç»„: è½¬æ¢ä¸ºDataFrameå¹¶å¯ç”¨ç±»å‹æ¨æ–­
            X = pd.DataFrame(X)
            convert_dtype = True
        else:
            # æ•°å€¼æ•°ç»„: è½¬æ¢ä¸ºDataFrameå¹¶æŒ‡å®šæ•°å€¼ç±»å‹
            X = pd.DataFrame(X)
            convert_dtype = False
    
    # æ­¥éª¤2: ç±»åˆ«ç‰¹å¾æ ‡è®°
    if cat_indices is not None:
        # å¤„ç†ç´¢å¼•ç±»å‹å…¼å®¹æ€§
        is_numeric_indices = all(isinstance(i, (int, np.integer)) for i in cat_indices)
        columns_are_numeric = all(isinstance(col, (int, np.integer)) for col in X.columns)
        use_iloc = is_numeric_indices and not columns_are_numeric
        
        # æ ‡è®°ç±»åˆ«ç‰¹å¾
        if use_iloc:
            X.iloc[:, cat_indices] = X.iloc[:, cat_indices].astype("category")
        else:
            X[cat_indices] = X[cat_indices].astype("category")
    
    # æ­¥éª¤3: æ™ºèƒ½ç±»å‹æ¨æ–­
    if convert_dtype:
        X = X.convert_dtypes()  # pandasæ™ºèƒ½ç±»å‹æ¨æ–­
    
    # æ­¥éª¤4: æ•°å€¼ç±»å‹ç»Ÿä¸€
    integer_columns = X.select_dtypes(include=["number"]).columns
    if len(integer_columns) > 0:
        X[integer_columns] = X[integer_columns].astype(numeric_dtype)
    
    return X
```

#### 2.2 åºæ•°ç¼–ç å™¨åˆ›å»º
```python
# æºæ–‡ä»¶: src/tabpfn/utils.py:318-336
def _get_ordinal_encoder(*, numpy_dtype=DEFAULT_NUMPY_PREPROCESSING_DTYPE):
    # ç¼–ç å™¨é…ç½®
    oe = OrdinalEncoder(
        categories="auto",                    # è‡ªåŠ¨æ¨æ–­æ‰€æœ‰å¯èƒ½ç±»åˆ«
        dtype=numpy_dtype,                   # è¾“å‡ºæ•°æ®ç±»å‹
        handle_unknown="use_encoded_value",   # æœªçŸ¥ç±»åˆ«å¤„ç†ç­–ç•¥
        unknown_value=-1,                    # æœªçŸ¥ç±»åˆ«ç¼–ç å€¼
        encoded_missing_value=np.nan,        # ç¼ºå¤±å€¼ä¿æŒä¸ºNaN
    )
    
    # åˆ—å˜æ¢å™¨é…ç½®
    to_convert = ["category", "string"]  # éœ€è¦ç¼–ç çš„åˆ—ç±»å‹
    return ColumnTransformer(
        transformers=[
            ("encoder", oe, make_column_selector(dtype_include=to_convert))
        ],
        remainder=FunctionTransformer(),      # å…¶ä»–åˆ—ä¿æŒä¸å˜
        sparse_threshold=0.0,                # è¾“å‡ºå¯†é›†çŸ©é˜µ
        verbose_feature_names_out=False      # ç®€æ´çš„ç‰¹å¾å
    )
```

#### 2.3 ç±»åˆ«ç‰¹å¾è‡ªåŠ¨æ¨æ–­
```python
# æºæ–‡ä»¶: src/tabpfn/utils.py:438-488
def infer_categorical_features(X, *, provided, min_samples_for_inference, 
                              max_unique_for_category, min_unique_for_numerical):
    maybe_categoricals = () if provided is None else provided
    large_enough_x_to_infer_categorical = X.shape[0] > min_samples_for_inference
    indices = []
    
    for ix, col in enumerate(X.T):
        unique_values = len(np.unique(col[~pd.isna(col)]))  # æ’é™¤NaNè®¡ç®—å”¯ä¸€å€¼
        
        if ix in maybe_categoricals:
            # ç”¨æˆ·æŒ‡å®šçš„ç±»åˆ«ç‰¹å¾
            if unique_values <= max_unique_for_category:
                indices.append(ix)
                print(f"ç‰¹å¾ {ix}: ç”¨æˆ·æŒ‡å®šä¸ºç±»åˆ«ç‰¹å¾ï¼Œå”¯ä¸€å€¼æ•°={unique_values}")
        elif (large_enough_x_to_infer_categorical and 
              unique_values < min_unique_for_numerical):
            # è‡ªåŠ¨æ¨æ–­çš„ç±»åˆ«ç‰¹å¾
            indices.append(ix)
            print(f"ç‰¹å¾ {ix}: è‡ªåŠ¨æ¨æ–­ä¸ºç±»åˆ«ç‰¹å¾ï¼Œå”¯ä¸€å€¼æ•°={unique_values}")
    
    return indices
```

### âš™ï¸ é˜¶æ®µ3: é›†æˆé…ç½®ç”Ÿæˆ (Ensemble Configuration Generation)

#### 3.1 é…ç½®ç”Ÿæˆçš„å®Œæ•´æµç¨‹
```python
# æºæ–‡ä»¶: src/tabpfn/preprocessing.py:257-369
@classmethod
def generate_for_classification(cls, *, n, subsample_size, max_index, 
                               add_fingerprint_feature, polynomial_features,
                               feature_shift_decoder, preprocessor_configs,
                               class_shift_method, n_classes, random_state):
    
    static_seed, rng = infer_random_state(random_state)
    
    # æ­¥éª¤1: ç‰¹å¾ä½ç§»ç”Ÿæˆ
    start = rng.integers(0, MAXIMUM_FEATURE_SHIFT)  # éšæœºèµ·å§‹ä½ç½®
    featshifts = np.arange(start, start + n)        # è¿ç»­ä½ç§»åºåˆ—
    featshifts = rng.choice(featshifts, size=n, replace=False)  # éšæœºé€‰æ‹©nä¸ª
    
    # æ­¥éª¤2: ç±»åˆ«æ’åˆ—ç”Ÿæˆ
    if class_shift_method == "rotate":
        # ç¯å½¢æ—‹è½¬: æ¯ä¸ªæˆå‘˜ä½¿ç”¨ä¸åŒçš„æ—‹è½¬é‡
        arange = np.arange(0, n_classes)
        shifts = rng.permutation(n_classes).tolist()
        # å¦‚æœæˆå‘˜æ•°>ç±»åˆ«æ•°ï¼Œé‡å¤ä½¿ç”¨æ—‹è½¬é‡
        while len(shifts) < n:
            shifts.extend(rng.permutation(n_classes).tolist())
        class_permutations = [np.roll(arange, s) for s in shifts[:n]]
        
    elif class_shift_method == "shuffle":
        # éšæœºæ‰“ä¹±: ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„æ’åˆ—å¹¶å‡è¡¡åˆ†é…
        noise = rng.random((n * CLASS_SHUFFLE_OVERESTIMATE_FACTOR, n_classes))
        shufflings = np.argsort(noise, axis=1)
        uniqs = np.unique(shufflings, axis=0)  # å»é‡å¾—åˆ°å”¯ä¸€æ’åˆ—
        
        # å‡è¡¡åˆ†é…æ’åˆ—
        balance_count = n // len(uniqs)
        class_permutations = balance(uniqs, balance_count)
        
        # å¤„ç†å‰©ä½™ä½ç½®
        leftover = n - len(class_permutations)
        if leftover > 0:
            extra_picks = rng.choice(len(uniqs), size=leftover, replace=True)
            class_permutations.extend(uniqs[i] for i in extra_picks)
    
    # æ­¥éª¤3: å­é‡‡æ ·ç´¢å¼•ç”Ÿæˆ
    if isinstance(subsample_size, (int, float)):
        subsamples = generate_index_permutations(
            n=n, 
            max_index=max_index, 
            subsample=subsample_size, 
            random_state=static_seed
        )
    else:
        subsamples = [None] * n
    
    # æ­¥éª¤4: é¢„å¤„ç†é…ç½®åˆ†é…
    balance_count = n // len(preprocessor_configs)
    configs_ = balance(preprocessor_configs, balance_count)
    
    # å¤„ç†å‰©ä½™é…ç½®
    leftover = n - len(configs_)
    if leftover > 0:
        picks = rng.choice(len(preprocessor_configs), size=leftover, replace=True)
        configs_.extend(preprocessor_configs[i] for i in picks)
    
    # æ­¥éª¤5: æ‰§è¡Œç§å­ç”Ÿæˆ
    seeds = rng.integers(0, np.iinfo(np.int32).max, n)
    
    # æ­¥éª¤6: æœ€ç»ˆé…ç½®ç»„è£…
    return [
        ClassifierEnsembleConfig(
            preprocess_config=config,
            add_fingerprint_feature=add_fingerprint_feature,
            polynomial_features=polynomial_features,
            feature_shift_count=featshift,
            feature_shift_decoder=feature_shift_decoder,
            subsample_ix=subsample,
            class_permutation=class_perm,
            execution_seed=seed,
        )
        for config, featshift, subsample, class_perm, seed 
        in zip(configs_, featshifts, subsamples, class_permutations, seeds)
    ]
```

### ğŸ—ï¸ é˜¶æ®µ4: ç®¡é“æ„å»ºä¸æ‹Ÿåˆ (Pipeline Construction & Fitting)

#### 4.1 é¢„å¤„ç†ç®¡é“æ„å»º
```python
# æºæ–‡ä»¶: src/tabpfn/preprocessing.py:452-502
def to_pipeline(self, *, random_state) -> SequentialFeatureTransformer:
    static_seed, _ = infer_random_state(random_state)
    steps = []
    
    # æ­¥éª¤1: å¤šé¡¹å¼ç‰¹å¾ç”Ÿæˆï¼ˆå¯é€‰ï¼‰
    use_poly_features = (
        isinstance(self.polynomial_features, int) or 
        self.polynomial_features == "all"
    )
    if use_poly_features:
        max_poly_features = (
            self.polynomial_features if isinstance(self.polynomial_features, int) 
            else None
        )
        steps.append(NanHandlingPolynomialFeaturesStep(
            max_features=max_poly_features,
            random_state=static_seed,
        ))
    
    # æ­¥éª¤2: æ ¸å¿ƒé¢„å¤„ç†æ­¥éª¤
    steps.extend([
        # 2.1 ç§»é™¤å¸¸é‡ç‰¹å¾
        RemoveConstantFeaturesStep(),
        
        # 2.2 ç‰¹å¾åˆ†å¸ƒé‡å¡‘
        ReshapeFeatureDistributionsStep(
            transform_name=self.preprocess_config.name,
            append_to_original=self.preprocess_config.append_original,
            subsample_features=self.preprocess_config.subsample_features,
            global_transformer_name=self.preprocess_config.global_transformer_name,
            apply_to_categorical=(self.preprocess_config.categorical_name == "numeric"),
            random_state=static_seed,
        ),
        
        # 2.3 ç±»åˆ«ç‰¹å¾ç¼–ç 
        EncodeCategoricalFeaturesStep(
            self.preprocess_config.categorical_name,
            random_state=static_seed,
        ),
    ])
    
    # æ­¥éª¤3: æŒ‡çº¹ç‰¹å¾æ·»åŠ ï¼ˆå¯é€‰ï¼‰
    if self.add_fingerprint_feature:
        steps.append(AddFingerprintFeaturesStep(random_state=static_seed))
    
    # æ­¥éª¤4: ç‰¹å¾ä½ç½®æ‰“ä¹±
    steps.append(ShuffleFeaturesStep(
        shuffle_method=self.feature_shift_decoder,
        shuffle_index=self.feature_shift_count,
        random_state=static_seed,
    ))
    
    return SequentialFeatureTransformer(steps)
```

#### 4.2 å¹¶è¡Œç®¡é“æ‹Ÿåˆ
```python
# æºæ–‡ä»¶: src/tabpfn/preprocessing.py:593-671
def fit_preprocessing(configs, X_train, y_train, *, random_state, cat_ix, 
                     n_workers, parallel_mode):
    """å¹¶è¡Œæ‹Ÿåˆæ‰€æœ‰é›†æˆé…ç½®çš„é¢„å¤„ç†ç®¡é“"""
    
    _, rng = infer_random_state(random_state)
    
    # ä¸ºæ¯ä¸ªé…ç½®ç”Ÿæˆç‹¬ç«‹çš„æ‰§è¡Œç§å­
    seeds = rng.integers(0, np.iinfo(np.int32).max, len(configs))
    
    # é…ç½®å¹¶è¡Œæ‰§è¡Œå™¨
    if parallel_mode == "sequential":
        executor = joblib.Parallel(n_jobs=1, batch_size="auto")
    else:
        executor = joblib.Parallel(n_jobs=n_workers, batch_size="auto")
    
    # åˆ›å»ºå·¥ä½œå‡½æ•°
    func = partial(fit_preprocessing_one, cat_ix=cat_ix)
    worker_func = joblib.delayed(func)
    
    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰é…ç½®
    results = executor([
        worker_func(config, X_train, y_train, seed)
        for config, seed in zip(configs, seeds)
    ])
    
    return results

def fit_preprocessing_one(config, X_train, y_train, random_state, *, cat_ix):
    """æ‹Ÿåˆå•ä¸ªé›†æˆé…ç½®"""
    static_seed, _ = infer_random_state(random_state)
    
    # æ­¥éª¤1: åº”ç”¨å­é‡‡æ ·
    if config.subsample_ix is not None:
        X_train = X_train[config.subsample_ix].copy()
        y_train = y_train[config.subsample_ix].copy()
    
    # æ­¥éª¤2: æ„å»ºå¹¶æ‹Ÿåˆé¢„å¤„ç†ç®¡é“
    preprocessor = config.to_pipeline(random_state=static_seed)
    res = preprocessor.fit_transform(X_train, cat_ix)
    
    # æ­¥éª¤3: ç›®æ ‡å˜é‡å˜æ¢
    if isinstance(config, ClassifierEnsembleConfig):
        if config.class_permutation is not None:
            y_train = config.class_permutation[y_train]
    elif isinstance(config, RegressorEnsembleConfig):
        if config.target_transform is not None:
            y_train = config.target_transform.fit_transform(
                y_train.reshape(-1, 1)
            ).ravel()
    
    return (config, preprocessor, res.X, y_train, res.categorical_features)
```

### ğŸš€ é˜¶æ®µ5: æ¨ç†å¼•æ“åˆ›å»º (Inference Engine Creation)

#### 5.1 å¼•æ“ç±»å‹é€‰æ‹©
```python
# æºæ–‡ä»¶: src/tabpfn/base.py:154-230
def create_inference_engine(fit_mode, model, interface_config, ensemble_configs, 
                           fitted_preprocessors, device, use_autocast):
    
    if fit_mode == "low_memory":
        # ä½å†…å­˜æ¨¡å¼: æ¯æ¬¡é¢„æµ‹æ—¶é‡æ–°é¢„å¤„ç†
        return InferenceEngineOnDemand(
            model=model,
            interface_config=interface_config,
            ensemble_configs=ensemble_configs,
            fitted_preprocessors=fitted_preprocessors,
            device=device,
            use_autocast=use_autocast,
        )
    
    elif fit_mode == "fit_preprocessors":
        # é¢„å¤„ç†ç¼“å­˜æ¨¡å¼: ç¼“å­˜é¢„å¤„ç†ç»“æœï¼Œé€‚åˆå¤šæ¬¡é¢„æµ‹
        return InferenceEngineCachePreprocessing(
            model=model,
            interface_config=interface_config,
            ensemble_configs=ensemble_configs,
            fitted_preprocessors=fitted_preprocessors,
            device=device,
            use_autocast=use_autocast,
        )
    
    elif fit_mode == "fit_with_cache":
        # å®Œå…¨ç¼“å­˜æ¨¡å¼: ç¼“å­˜é¢„å¤„ç†å’Œé”®å€¼å¯¹ï¼Œæœ€å¿«ä½†å ç”¨æœ€å¤šGPUå†…å­˜
        return InferenceEngineCacheKV(
            model=model,
            interface_config=interface_config,
            ensemble_configs=ensemble_configs,
            fitted_preprocessors=fitted_preprocessors,
            device=device,
            use_autocast=use_autocast,
        )
```

### ğŸ”® é˜¶æ®µ6: é¢„æµ‹æ‰§è¡Œ (Prediction Execution)

#### 6.1 é¢„æµ‹æ—¶çš„æ•°æ®æµ
```python
# æºæ–‡ä»¶: src/tabpfn/classifier.py:536-614
def predict_proba(self, X):
    # æ­¥éª¤1: æ¨¡å‹çŠ¶æ€æ£€æŸ¥
    check_is_fitted(self)
    
    # æ­¥éª¤2: è¾“å…¥éªŒè¯
    X = validate_X_predict(X, self)
    
    # æ­¥éª¤3: æ•°æ®ç±»å‹ä¿®å¤ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
    X = _fix_dtypes(X, cat_indices=self.categorical_features_indices)
    
    # æ­¥éª¤4: åºæ•°ç¼–ç åº”ç”¨ï¼ˆä½¿ç”¨å·²è®­ç»ƒçš„ç¼–ç å™¨ï¼‰
    X = _process_text_na_dataframe(X, ord_encoder=self.preprocessor_)
    
    # æ­¥éª¤5: é›†æˆæ¨ç†
    outputs = []
    for output, config in self.executor_.iter_outputs(X, device=self.device_, 
                                                     autocast=self.use_autocast_):
        # 5.1 åº”ç”¨softmaxæ¸©åº¦
        if self.softmax_temperature != 1:
            output = output[:, :self.n_classes_].float() / self.softmax_temperature
        
        # 5.2 é€†è½¬ç±»åˆ«æ’åˆ—ï¼ˆæ¢å¤åŸå§‹ç±»åˆ«é¡ºåºï¼‰
        if config.class_permutation is not None:
            inverse_permutation = np.argsort(config.class_permutation)
            output = output[..., inverse_permutation]
        
        outputs.append(output)
    
    # æ­¥éª¤6: é›†æˆç»“æœèšåˆ
    if self.average_before_softmax:
        # åœ¨softmaxå‰å¹³å‡
        output = torch.stack(outputs).mean(dim=0)
        output = torch.nn.functional.softmax(output, dim=1)
    else:
        # åœ¨softmaxåå¹³å‡
        outputs = [torch.nn.functional.softmax(o, dim=1) for o in outputs]
        output = torch.stack(outputs).mean(dim=0)
    
    # æ­¥éª¤7: åå¤„ç†
    if self.balance_probabilities:
        # æ¦‚ç‡å¹³è¡¡å¤„ç†
        output = self._balance_probabilities(output)
    
    if self.inference_precision == "16":
        # 16ä½ç²¾åº¦å¤„ç†
        output = output.half()
    
    # æ­¥éª¤8: æœ€ç»ˆæ ‡å‡†åŒ–
    output = output / output.sum(dim=1, keepdim=True)  # ç¡®ä¿æ¦‚ç‡å’Œä¸º1
    
    return output.cpu().numpy()
```

### ğŸ”§ é¢„å¤„ç†ç®¡é“çš„å†…éƒ¨æ­¥éª¤è¯¦è§£

#### 6.2 å•ä¸ªé¢„å¤„ç†ç®¡é“çš„æ‰§è¡Œæµç¨‹
```python
# æ¯ä¸ªé›†æˆæˆå‘˜çš„é¢„å¤„ç†ç®¡é“æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š

# æ­¥éª¤1: å¤šé¡¹å¼ç‰¹å¾ç”Ÿæˆï¼ˆå¯é€‰ï¼‰
if polynomial_features:
    X = NanHandlingPolynomialFeaturesStep.transform(X)
    # ç”Ÿæˆäº¤äº’ç‰¹å¾ï¼Œå¤„ç†NaNå€¼

# æ­¥éª¤2: ç§»é™¤å¸¸é‡ç‰¹å¾
X = RemoveConstantFeaturesStep.transform(X)
# ç§»é™¤æ‰€æœ‰å€¼ç›¸åŒçš„ç‰¹å¾

# æ­¥éª¤3: ç‰¹å¾åˆ†å¸ƒé‡å¡‘
X = ReshapeFeatureDistributionsStep.transform(X)
# åº”ç”¨é€‰å®šçš„æ•°å€¼å˜æ¢ï¼ˆå¦‚quantile_uni_coarseï¼‰

# æ­¥éª¤4: ç±»åˆ«ç‰¹å¾ç¼–ç 
X = EncodeCategoricalFeaturesStep.transform(X)
# åº”ç”¨é€‰å®šçš„ç¼–ç æ–¹æ³•ï¼ˆå¦‚ordinalç¼–ç ï¼‰

# æ­¥éª¤5: æŒ‡çº¹ç‰¹å¾æ·»åŠ ï¼ˆå¯é€‰ï¼‰
if add_fingerprint_feature:
    X = AddFingerprintFeaturesStep.transform(X)
    # æ·»åŠ æ•°æ®é›†ç‰¹å¾æŒ‡çº¹

# æ­¥éª¤6: ç‰¹å¾ä½ç½®æ‰“ä¹±
X = ShuffleFeaturesStep.transform(X)
# æ ¹æ®feature_shift_countè¿›è¡Œç‰¹å¾é‡æ’
```

### ğŸ“Š å®Œæ•´æµç¨‹çš„æ€§èƒ½ç‰¹ç‚¹

#### æ—¶é—´å¤æ‚åº¦åˆ†æ
- **æ•°æ®éªŒè¯**: O(nÃ—m) - çº¿æ€§äºæ•°æ®å¤§å°
- **ç±»å‹ä¿®å¤**: O(nÃ—m) - ä¸»è¦æ˜¯æ•°æ®å¤åˆ¶
- **ç±»åˆ«æ¨æ–­**: O(mÃ—k) - mä¸ªç‰¹å¾ï¼Œæ¯ä¸ªæœ€å¤škä¸ªå”¯ä¸€å€¼
- **é…ç½®ç”Ÿæˆ**: O(e) - eä¸ªé›†æˆæˆå‘˜ï¼Œä¸æ•°æ®å¤§å°æ— å…³
- **ç®¡é“æ‹Ÿåˆ**: O(eÃ—nÃ—mÃ—f) - eä¸ªæˆå‘˜ï¼Œfä¸ºå˜æ¢å¤æ‚åº¦
- **æ¨ç†**: O(eÃ—nÃ—mÃ—f) - ç±»ä¼¼æ‹Ÿåˆè¿‡ç¨‹

#### å†…å­˜ä½¿ç”¨åˆ†æ
- **åŸå§‹æ•°æ®**: nÃ—mÃ—8å­—èŠ‚ï¼ˆfloat64ï¼‰
- **é›†æˆé…ç½®**: eÃ—é…ç½®å¤§å°ï¼ˆé€šå¸¸å¾ˆå°ï¼‰
- **é¢„å¤„ç†ç¼“å­˜**: å–å†³äºfit_modeé€‰æ‹©
  - low_memory: æœ€å°å†…å­˜ä½¿ç”¨
  - fit_preprocessors: ä¸­ç­‰å†…å­˜ä½¿ç”¨
  - fit_with_cache: æœ€å¤§å†…å­˜ä½¿ç”¨ä½†æœ€å¿«é€Ÿåº¦

#### å¹¶è¡ŒåŒ–æ•ˆæœ
- **é…ç½®ç”Ÿæˆ**: ä¸²è¡Œæ‰§è¡Œï¼ˆä¾èµ–éšæœºç§å­åºåˆ—ï¼‰
- **ç®¡é“æ‹Ÿåˆ**: å®Œå…¨å¹¶è¡Œï¼ˆæ¯ä¸ªé…ç½®ç‹¬ç«‹ï¼‰
- **æ¨ç†æ‰§è¡Œ**: éƒ¨åˆ†å¹¶è¡Œï¼ˆå–å†³äºGPUå†…å­˜å’Œæ¨¡å‹å¤§å°ï¼‰

è¿™ä¸ªå®Œæ•´çš„å…­é˜¶æ®µé¢„å¤„ç†æµç¨‹ä½“ç°äº†TabPFNåœ¨è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ æ–¹é¢çš„å…ˆè¿›è®¾è®¡ç†å¿µï¼Œé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æ•°æ®å˜æ¢ã€é›†æˆç­–ç•¥å’Œå¹¶è¡Œæ‰§è¡Œï¼Œå®ç°äº†é«˜æ•ˆã€é²æ£’ã€å¯æ‰©å±•çš„è¡¨æ ¼æ•°æ®å¤„ç†ç³»ç»Ÿã€‚

## ğŸ² éšæœºç§å­åˆ†é…æœºåˆ¶è¯¦è§£

TabPFNé‡‡ç”¨äº†ç²¾å¿ƒè®¾è®¡çš„**åˆ†å±‚éšæœºç§å­ç³»ç»Ÿ**ï¼Œæ—¢ä¿è¯äº†é›†æˆæˆå‘˜é—´çš„å¤šæ ·æ€§ï¼Œåˆç¡®ä¿äº†ç»“æœçš„å¯é‡ç°æ€§ã€‚ç†è§£è¿™ä¸ªæœºåˆ¶å¯¹äºæŒæ¡TabPFNçš„å·¥ä½œåŸç†è‡³å…³é‡è¦ã€‚

### ğŸ”§ éšæœºç§å­çš„å››ä¸ªå±‚æ¬¡

#### 1. **ä¸»éšæœºç§å­** (ç”¨æˆ·è®¾ç½®å±‚)
```python
# ç”¨æˆ·åˆå§‹åŒ–æ—¶è®¾ç½®
model = TabPFNClassifier(random_state=42, n_estimators=32)
# ä¸»ç§å­: 42 (ç”¨æˆ·æŒ‡å®šï¼Œæ§åˆ¶å…¨å±€å¯é‡ç°æ€§)
```

#### 2. **é™æ€ç§å­ç”Ÿæˆ** (å…¨å±€æ§åˆ¶å±‚)
```python
# æºæ–‡ä»¶ï¼šsrc/tabpfn/classifier.py:379-381
static_seed, rng = infer_random_state(self.random_state)
# static_seed: 42 (å›ºå®šå€¼ï¼Œç”¨äºå…³é”®ç»„ä»¶)
# rng: åŸºäº42çš„éšæœºæ•°ç”Ÿæˆå™¨ (ç”¨äºç”Ÿæˆå˜åŒ–)
```

#### 3. **é›†æˆé…ç½®ç§å­** (é…ç½®ç”Ÿæˆå±‚)
```python
# æºæ–‡ä»¶ï¼šsrc/tabpfn/preprocessing.py:287-288
static_seed, rng = infer_random_state(random_state)  # ä½¿ç”¨ä¸»ç§å­42
# æ‰€æœ‰32ä¸ªé…ç½®å…±äº«åŒä¸€ä¸ªrngï¼Œä½†æ¯æ¬¡è°ƒç”¨äº§ç”Ÿä¸åŒçš„éšæœºå€¼

# ç‰¹å¾ä½ç§»ç”Ÿæˆ
start = rng.integers(0, MAXIMUM_FEATURE_SHIFT)  # ä¸€æ¬¡è°ƒç”¨ï¼Œå¦‚: 156
featshifts = np.arange(start, start + 32)       # [156, 157, ..., 187]
featshifts = rng.choice(featshifts, size=32, replace=False)  # æ‰“ä¹±: [163, 156, 178, ...]

# ç±»åˆ«æ’åˆ—ç”Ÿæˆ
if class_shift_method == "shuffle":
    noise = rng.random((32 * FACTOR, n_classes))  # ä¸€æ¬¡è°ƒç”¨ï¼Œç”Ÿæˆå¤§çŸ©é˜µ
    shufflings = np.argsort(noise, axis=1)        # æ¯è¡Œäº§ç”Ÿä¸åŒæ’åˆ—
```

#### 4. **é¢„å¤„ç†æ‰§è¡Œç§å­** (ç‹¬ç«‹æ‰§è¡Œå±‚)
```python
# æºæ–‡ä»¶ï¼šsrc/tabpfn/preprocessing.py:665-671
seeds = rng.integers(0, np.iinfo(np.int32).max, len(configs))  # ä¸º32ä¸ªé…ç½®ç”Ÿæˆ32ä¸ªç‹¬ç«‹ç§å­
# ä¾‹å¦‚ï¼š[1847392847, 928473625, 563920147, 739284756, ...]

yield from executor([
    worker_func(config, X_train, y_train, seed)  # æ¯ä¸ªé…ç½®ä½¿ç”¨å®Œå…¨ç‹¬ç«‹çš„ç§å­
    for config, seed in zip(configs, seeds)
])
```

### ğŸ“Š 32ä¸ªé…ç½®çš„å®Œæ•´ç”Ÿæˆè¿‡ç¨‹

å‡è®¾ç”¨æˆ·è®¾ç½®`random_state=42`ï¼Œ`n_estimators=32`ï¼Œä»¥ä¸‹æ˜¯å®Œæ•´çš„ç”Ÿæˆè¿‡ç¨‹ï¼š

#### æ­¥éª¤1: ä¸»ç§å­åˆå§‹åŒ–
```python
main_random_state = 42
static_seed, rng = infer_random_state(42)
# static_seed = 42
# rng = Generator(PCG64) åŸºäºç§å­42
```

#### æ­¥éª¤2: ç‰¹å¾ä½ç§»åˆ†é… (å…±äº«rng)
```python
start = rng.integers(0, 1000)  # å‡è®¾ç”Ÿæˆ: 156
featshifts = np.arange(156, 188)  # [156, 157, 158, ..., 187]
featshifts = rng.choice(featshifts, 32, replace=False)
# ç»“æœ: [163, 156, 178, 169, 184, 172, 161, 175, ...]
```

#### æ­¥éª¤3: ç±»åˆ«æ’åˆ—åˆ†é… (å…±äº«rng)
```python
# å‡è®¾3ä¸ªç±»åˆ«ï¼Œclass_shift_method="shuffle"
noise = rng.random((32 * 10, 3))  # ç”Ÿæˆ320x3çš„éšæœºçŸ©é˜µ
shufflings = np.argsort(noise, axis=1)  # æ¯è¡Œäº§ç”Ÿä¸€ç§æ’åˆ—
uniqs = np.unique(shufflings, axis=0)   # å»é‡ï¼Œå¾—åˆ°6ç§å”¯ä¸€æ’åˆ—
# uniqs: [[0,1,2], [0,2,1], [1,0,2], [1,2,0], [2,0,1], [2,1,0]]

balance_count = 32 // 6  # 5 (æ¯ç§æ’åˆ—é‡å¤5æ¬¡)
class_permutations = balance(uniqs, 5)  # æ¯ç§æ’åˆ—é‡å¤5æ¬¡
# æœ€ç»ˆ32ä¸ªæ’åˆ—: [0,1,2]Ã—5 + [0,2,1]Ã—5 + ... + [2,1,0]Ã—2
```

#### æ­¥éª¤4: å­é‡‡æ ·ç´¢å¼•åˆ†é… (å…±äº«rng)
```python
if subsample_size is not None:
    subsamples = [rng.permutation(max_index)[:subsample_size] for _ in range(32)]
    # 32ç»„ä¸åŒçš„å­é‡‡æ ·ç´¢å¼•
else:
    subsamples = [None] * 32  # ä¸è¿›è¡Œå­é‡‡æ ·
```

#### æ­¥éª¤5: é¢„å¤„ç†é…ç½®åˆ†é… (å‡è¡¡ç­–ç•¥)
```python
# é»˜è®¤2ç§é¢„å¤„ç†é…ç½®
preprocessor_configs = default_classifier_preprocessor_configs()  # 2ä¸ªé…ç½®
balance_count = 32 // 2  # 16

# å‡è¡¡åˆ†é…
configs_ = [config1] * 16 + [config2] * 16
# é…ç½®1: quantile_uni_coarse (16ä¸ªæˆå‘˜)
# é…ç½®2: none (16ä¸ªæˆå‘˜)
```

#### æ­¥éª¤6: æ‰§è¡Œç§å­ç”Ÿæˆ (ç‹¬ç«‹ç§å­)
```python
execution_seeds = rng.integers(0, 2**31-1, 32)
# 32ä¸ªå®Œå…¨ç‹¬ç«‹çš„ç§å­: [1847392847, 928473625, 563920147, ...]
```

### ğŸ¯ æœ€ç»ˆé…ç½®åˆ†é…ç¤ºä¾‹

åŸºäºä¸Šè¿°ç”Ÿæˆè¿‡ç¨‹ï¼Œ32ä¸ªé…ç½®çš„æœ€ç»ˆåˆ†é…å¦‚ä¸‹ï¼š

```python
# é…ç½®1-16: ä½¿ç”¨quantile_uni_coarseé¢„å¤„ç†
EnsembleConfig_1 = {
    'preprocess_config': quantile_uni_coarse_config,
    'feature_shift_count': 163,
    'feature_shift_decoder': 'shuffle',  # æ¥è‡ªå…¨å±€é…ç½®
    'class_permutation': [0,1,2],
    'subsample_ix': [0,3,7,12,18,...],  # ç¬¬1ç»„å­é‡‡æ ·
    'execution_seed': 1847392847
}

EnsembleConfig_2 = {
    'preprocess_config': quantile_uni_coarse_config,
    'feature_shift_count': 156,
    'feature_shift_decoder': 'shuffle',
    'class_permutation': [0,1,2],
    'subsample_ix': [1,5,9,14,21,...],  # ç¬¬2ç»„å­é‡‡æ ·
    'execution_seed': 928473625
}

# ... é…ç½®3-16ç±»ä¼¼ï¼Œä½†feature_shift_countã€class_permutationã€subsample_ixã€execution_seedéƒ½ä¸åŒ

# é…ç½®17-32: ä½¿ç”¨noneé¢„å¤„ç†
EnsembleConfig_17 = {
    'preprocess_config': none_config,
    'feature_shift_count': 178,
    'feature_shift_decoder': 'shuffle',
    'class_permutation': [1,0,2],
    'subsample_ix': [2,6,11,17,24,...],  # ç¬¬17ç»„å­é‡‡æ ·
    'execution_seed': 563920147
}

# ... é…ç½®18-32ç±»ä¼¼
```

### ğŸ”„ éšæœºæ€§çš„ä¸åŒå±‚é¢è¯¦è§£

#### 1. **é…ç½®çº§éšæœºæ€§** (ç›¸å¯¹å›ºå®šï¼ŒåŸºäºå…±äº«rng)
- **ç‰¹å¾ä½ç§»å€¼**: 32ä¸ªä¸åŒå€¼ï¼Œä½†ç”Ÿæˆè§„åˆ™å›ºå®š
- **ç±»åˆ«æ’åˆ—**: å¤šç§æ’åˆ—ç»„åˆï¼Œä½†åˆ†é…æ¨¡å¼å›ºå®š
- **å­é‡‡æ ·ç´¢å¼•**: 32ç»„ä¸åŒç´¢å¼•ï¼Œä½†ç”Ÿæˆç­–ç•¥å›ºå®š
- **é¢„å¤„ç†é…ç½®**: å‡è¡¡åˆ†é…ï¼Œç¡®ä¿æ¯ç§ç­–ç•¥éƒ½è¢«ä½¿ç”¨

#### 2. **æ‰§è¡Œçº§éšæœºæ€§** (å®Œå…¨ç‹¬ç«‹ï¼ŒåŸºäºç‹¬ç«‹ç§å­)
```python
def fit_preprocessing_one(config, X_train, y_train, execution_seed, *, cat_ix):
    # æ¯ä¸ªé…ç½®ä½¿ç”¨å®Œå…¨ç‹¬ç«‹çš„éšæœºç§å­
    static_seed, _ = infer_random_state(execution_seed)  # ç‹¬ç«‹ç§å­
    
    # æ„å»ºé¢„å¤„ç†ç®¡é“æ—¶çš„éšæœºåŒ–
    preprocessor = config.to_pipeline(random_state=static_seed)
    
    # ç®¡é“å†…éƒ¨çš„éšæœºåŒ–ï¼š
    # - å¤šé¡¹å¼ç‰¹å¾é€‰æ‹©éšæœºåŒ–
    # - ç‰¹å¾å˜æ¢å‚æ•°éšæœºåŒ–  
    # - ç±»åˆ«ç¼–ç éšæœºåŒ–
    # - æŒ‡çº¹ç‰¹å¾ç”ŸæˆéšæœºåŒ–
    # - ç‰¹å¾æ‰“ä¹±éšæœºåŒ–
```

### ğŸ² å¯é‡ç°æ€§ä¿è¯æœºåˆ¶

#### å…¨å±€å¯é‡ç°æ€§
```python
# åœºæ™¯1: ç›¸åŒé…ç½®ï¼Œå®Œå…¨ç›¸åŒç»“æœ
model1 = TabPFNClassifier(random_state=42, n_estimators=32)
model2 = TabPFNClassifier(random_state=42, n_estimators=32)
model1.fit(X, y)
model2.fit(X, y)
# model1å’Œmodel2çš„32ä¸ªé…ç½®å®Œå…¨ç›¸åŒï¼Œé¢„æµ‹ç»“æœå®Œå…¨ä¸€è‡´

# åœºæ™¯2: ä¸åŒä¸»ç§å­ï¼Œå®Œå…¨ä¸åŒç»“æœ
model3 = TabPFNClassifier(random_state=123, n_estimators=32)
model3.fit(X, y)
# model3çš„32ä¸ªé…ç½®ä¸model1/model2å®Œå…¨ä¸åŒ
```

#### é…ç½®é—´ç‹¬ç«‹æ€§
```python
# æ¯ä¸ªé…ç½®çš„å†…éƒ¨éšæœºåŒ–å®Œå…¨ç‹¬ç«‹
é…ç½®1çš„execution_seed = 1847392847 â†’ ç‹¬ç«‹çš„éšæœºåŒ–è¿‡ç¨‹
é…ç½®2çš„execution_seed = 928473625  â†’ ç‹¬ç«‹çš„éšæœºåŒ–è¿‡ç¨‹
é…ç½®3çš„execution_seed = 563920147  â†’ ç‹¬ç«‹çš„éšæœºåŒ–è¿‡ç¨‹
# ...
# é…ç½®1çš„éšæœºåŒ–ä¸ä¼šå½±å“é…ç½®2ï¼Œä½†æ•´ä½“åºåˆ—æ˜¯ç¡®å®šçš„
```

### ğŸ“ˆ n_estimatorså¯¹é…ç½®ç”Ÿæˆçš„å½±å“

#### n_estimators=4çš„æƒ…å†µ
```python
# 2ç§é¢„å¤„ç†é…ç½®ï¼Œå‡è¡¡åˆ†é…
balance_count = 4 // 2 = 2
é…ç½®åˆ†é…: [config1, config1, config2, config2]
ç‰¹å¾ä½ç§»: 4ä¸ªä¸åŒå€¼
ç±»åˆ«æ’åˆ—: æœ€å¤š4ç§ä¸åŒæ’åˆ—
æ‰§è¡Œç§å­: 4ä¸ªç‹¬ç«‹ç§å­
```

#### n_estimators=32çš„æƒ…å†µ
```python
# 2ç§é¢„å¤„ç†é…ç½®ï¼Œå‡è¡¡åˆ†é…
balance_count = 32 // 2 = 16
é…ç½®åˆ†é…: [config1]Ã—16 + [config2]Ã—16
ç‰¹å¾ä½ç§»: 32ä¸ªä¸åŒå€¼
ç±»åˆ«æ’åˆ—: å¤šç§æ’åˆ—çš„é‡å¤ä½¿ç”¨
æ‰§è¡Œç§å­: 32ä¸ªç‹¬ç«‹ç§å­
```

#### n_estimators=100çš„æƒ…å†µ
```python
# 2ç§é¢„å¤„ç†é…ç½®ï¼Œå‡è¡¡åˆ†é…+éšæœºè¡¥å……
balance_count = 100 // 2 = 50
é…ç½®åˆ†é…: [config1]Ã—50 + [config2]Ã—50
ç‰¹å¾ä½ç§»: 100ä¸ªä¸åŒå€¼
ç±»åˆ«æ’åˆ—: æ‰€æœ‰å¯èƒ½æ’åˆ—çš„å¤šæ¬¡é‡å¤
æ‰§è¡Œç§å­: 100ä¸ªç‹¬ç«‹ç§å­
```

### ğŸš€ è®¾è®¡ä¼˜åŠ¿æ€»ç»“

#### 1. **ç¡®å®šæ€§ä¸éšæœºæ€§çš„å¹³è¡¡**
- **ç¡®å®šæ€§**: ç›¸åŒä¸»ç§å­äº§ç”Ÿç›¸åŒé…ç½®åºåˆ—
- **éšæœºæ€§**: é…ç½®é—´å’Œé…ç½®å†…éƒ½æœ‰å……åˆ†çš„éšæœºåŒ–

#### 2. **å¤šå±‚æ¬¡çš„å¤šæ ·æ€§ä¿è¯**
- **é¢„å¤„ç†ç­–ç•¥å¤šæ ·æ€§**: ä¸åŒçš„æ•°å€¼å˜æ¢å’Œç¼–ç æ–¹æ³•
- **ä½ç½®å¤šæ ·æ€§**: ç‰¹å¾ä½ç§»æ‰“ç ´ä½ç½®ä¾èµ–
- **æ ‡ç­¾å¤šæ ·æ€§**: ç±»åˆ«æ’åˆ—æ¶ˆé™¤æ ‡ç­¾åè§
- **æ ·æœ¬å¤šæ ·æ€§**: å­é‡‡æ ·å¢åŠ æ•°æ®è§†è§’
- **æ‰§è¡Œå¤šæ ·æ€§**: ç‹¬ç«‹ç§å­ä¿è¯å†…éƒ¨éšæœºåŒ–

#### 3. **å¯æ‰©å±•æ€§å’Œçµæ´»æ€§**
- **ä»»æ„n_estimators**: æ”¯æŒä»å°åˆ°å¤§çš„é›†æˆè§„æ¨¡
- **å‡è¡¡åˆ†é…**: ç¡®ä¿æ‰€æœ‰ç­–ç•¥éƒ½è¢«å…¬å¹³ä½¿ç”¨
- **ç‹¬ç«‹æ‰§è¡Œ**: æ¯ä¸ªé…ç½®éƒ½æœ‰å®Œæ•´çš„éšæœºåŒ–ç©ºé—´

#### 4. **è°ƒè¯•å’Œåˆ†æå‹å¥½**
- **åˆ†å±‚è®¾è®¡**: å¯ä»¥å•ç‹¬åˆ†ææ¯ä¸ªå±‚æ¬¡çš„å½±å“
- **å¯é‡ç°æ€§**: ä¾¿äºå®éªŒé‡å¤å’Œç»“æœéªŒè¯
- **å¯è¿½æº¯æ€§**: æ¯ä¸ªé…ç½®çš„ç”Ÿæˆè¿‡ç¨‹éƒ½å¯ä»¥è¿½è¸ª

è¿™ç§ç²¾å¿ƒè®¾è®¡çš„éšæœºç§å­åˆ†é…æœºåˆ¶æ˜¯TabPFNèƒ½å¤Ÿåœ¨ä¿è¯å¯é‡ç°æ€§çš„åŒæ—¶å®ç°å¼ºå¤§é›†æˆæ•ˆæœçš„å…³é”®æŠ€æœ¯åŸºç¡€ã€‚

## ğŸ“ preprocessing.py æ–‡ä»¶åŠŸèƒ½è¯¦è§£

`src/tabpfn/preprocessing.py` æ˜¯TabPFNé¢„å¤„ç†ç³»ç»Ÿçš„**æ ¸å¿ƒé…ç½®å’Œé›†æˆç®¡ç†æ–‡ä»¶**ï¼Œè´Ÿè´£å®šä¹‰å’Œç”Ÿæˆå¤šæ ·åŒ–çš„æ•°æ®å¤„ç†ç­–ç•¥ã€‚è¯¥æ–‡ä»¶å®ç°äº†TabPFNç‹¬ç‰¹çš„é›†æˆå­¦ä¹ æœºåˆ¶ã€‚

### ğŸ¯ æ–‡ä»¶ä¸»è¦åŠŸèƒ½

#### 1. **é¢„å¤„ç†é…ç½®å®šä¹‰** (`PreprocessorConfig`)

**æºæ–‡ä»¶ä½ç½®**: `src/tabpfn/preprocessing.py:51-155`

```python
@dataclass
class PreprocessorConfig:
    """æ•°æ®é¢„å¤„ç†å™¨çš„é…ç½®ç±»"""
    
    # æ•°å€¼ç‰¹å¾å˜æ¢æ–¹æ³•ï¼ˆ25ç§é€‰æ‹©ï¼‰
    name: Literal[
        "per_feature",           # æ¯ä¸ªç‰¹å¾ç‹¬ç«‹å˜æ¢
        "power", "safepower",    # å¹‚å˜æ¢ï¼ˆæ ‡å‡†/å®‰å…¨ç‰ˆæœ¬ï¼‰
        "quantile_uni_coarse",   # ç²—ç²’åº¦åˆ†ä½æ•°å˜æ¢
        "quantile_norm",         # æ­£æ€åˆ†ä½æ•°å˜æ¢
        "robust",                # é²æ£’æ ‡å‡†åŒ–
        "kdi",                   # æ ¸å¯†åº¦ä¼°è®¡å˜æ¢
        "none",                  # ä»…æ ‡å‡†åŒ–
        # ... æ›´å¤šKDIå˜ä½“
    ]
    
    # ç±»åˆ«ç‰¹å¾ç¼–ç æ–¹æ³•ï¼ˆ6ç§é€‰æ‹©ï¼‰
    categorical_name: Literal[
        "none",                  # ä¿æŒåŸæ ·
        "numeric",               # å½“ä½œæ•°å€¼å¤„ç†
        "onehot",               # ç‹¬çƒ­ç¼–ç 
        "ordinal",              # åºæ•°ç¼–ç 
        "ordinal_shuffled",     # éšæœºåºæ•°ç¼–ç 
        "ordinal_very_common_categories_shuffled"  # å¸¸è§ç±»åˆ«éšæœºç¼–ç 
    ]
    
    # å…¶ä»–é…ç½®
    append_original: bool = False        # æ˜¯å¦ä¿ç•™åŸå§‹ç‰¹å¾
    subsample_features: float = -1       # ç‰¹å¾å­é‡‡æ ·æ¯”ä¾‹
    global_transformer_name: str | None = None  # å…¨å±€å˜æ¢å™¨åç§°
```

**åŠŸèƒ½ç‰¹ç‚¹**ï¼š
- **25ç§æ•°å€¼å˜æ¢æ–¹æ³•**ï¼šä»ç®€å•æ ‡å‡†åŒ–åˆ°å¤æ‚çš„KDIå˜æ¢
- **6ç§ç±»åˆ«ç¼–ç ç­–ç•¥**ï¼šæ¶µç›–ä¸»æµç¼–ç æ–¹æ³•
- **çµæ´»ç»„åˆ**ï¼šæ”¯æŒç‰¹å¾ä¿ç•™ã€å­é‡‡æ ·ã€å…¨å±€å˜æ¢ç­‰

#### 2. **é»˜è®¤é…ç½®ç­–ç•¥**

**åˆ†ç±»å™¨é»˜è®¤é…ç½®** (`src/tabpfn/preprocessing.py:174-186`):
```python
def default_classifier_preprocessor_configs():
    return [
        # ç­–ç•¥1ï¼šä¿å®ˆ+é™ç»´ç­–ç•¥
        PreprocessorConfig(
            "quantile_uni_coarse",                           # åˆ†ä½æ•°å˜æ¢
            append_original=True,                            # ä¿ç•™åŸå§‹ç‰¹å¾
            categorical_name="ordinal_very_common_categories_shuffled",  # æ™ºèƒ½ç±»åˆ«ç¼–ç 
            global_transformer_name="svd",                   # SVDé™ç»´
        ),
        # ç­–ç•¥2ï¼šæ¿€è¿›+ç®€åŒ–ç­–ç•¥  
        PreprocessorConfig(
            "none",                                          # æ— æ•°å€¼å˜æ¢
            categorical_name="numeric",                      # ç±»åˆ«æ•°å€¼åŒ–
        ),
    ]
```

**å›å½’å™¨é»˜è®¤é…ç½®** (`src/tabpfn/preprocessing.py:189-202`):
```python
def default_regressor_preprocessor_configs():
    return [
        # ç­–ç•¥1ï¼šåˆ†ä½æ•°å˜æ¢+SVD
        PreprocessorConfig(
            "quantile_uni",                                  # ç²¾ç»†åˆ†ä½æ•°å˜æ¢
            append_original=True,
            categorical_name="ordinal_very_common_categories_shuffled",
            global_transformer_name="svd",
        ),
        # ç­–ç•¥2ï¼šå¹‚å˜æ¢+ç‹¬çƒ­ç¼–ç 
        PreprocessorConfig(
            "safepower",                                     # å®‰å…¨å¹‚å˜æ¢
            categorical_name="onehot"                        # ç‹¬çƒ­ç¼–ç 
        ),
    ]
```

#### 3. **é›†æˆé…ç½®ç”Ÿæˆå™¨** (`EnsembleConfig`)

**æ ¸å¿ƒç±»å®šä¹‰** (`src/tabpfn/preprocessing.py:240-255`):
```python
@dataclass
class EnsembleConfig:
    """é›†æˆæˆå‘˜é…ç½®"""
    preprocess_config: PreprocessorConfig           # é¢„å¤„ç†é…ç½®
    add_fingerprint_feature: bool                   # æ˜¯å¦æ·»åŠ æŒ‡çº¹ç‰¹å¾
    polynomial_features: Literal["no", "all"] | int # å¤šé¡¹å¼ç‰¹å¾
    feature_shift_count: int                        # ç‰¹å¾ä½ç§»æ•°é‡
    feature_shift_decoder: Literal["shuffle", "rotate"] | None  # ä½ç§»æ–¹æ³•
    subsample_ix: npt.NDArray[np.int64] | None     # å­é‡‡æ ·ç´¢å¼•
```

**åˆ†ç±»ä»»åŠ¡é…ç½®ç”Ÿæˆ** (`src/tabpfn/preprocessing.py:257-369`):
```python
@classmethod
def generate_for_classification(cls, *, n, subsample_size, max_index, 
                               add_fingerprint_feature, polynomial_features,
                               feature_shift_decoder, preprocessor_configs,
                               class_shift_method, n_classes, random_state):
    """ä¸ºåˆ†ç±»ä»»åŠ¡ç”Ÿæˆnä¸ªä¸åŒçš„é›†æˆé…ç½®"""
    
    # 1. ç”Ÿæˆç‰¹å¾ä½ç§»åºåˆ—
    start = rng.integers(0, MAXIMUM_FEATURE_SHIFT)
    featshifts = np.arange(start, start + n)
    featshifts = rng.choice(featshifts, size=n, replace=False)
    
    # 2. ç”Ÿæˆç±»åˆ«æ’åˆ—
    if class_shift_method == "rotate":
        # ç¯å½¢æ—‹è½¬ç±»åˆ«æ ‡ç­¾
        arange = np.arange(0, n_classes)
        shifts = rng.permutation(n_classes).tolist()
        class_permutations = [np.roll(arange, s) for s in shifts]
    elif class_shift_method == "shuffle":
        # éšæœºæ‰“ä¹±ç±»åˆ«æ ‡ç­¾
        noise = rng.random((n * CLASS_SHUFFLE_OVERESTIMATE_FACTOR, n_classes))
        shufflings = np.argsort(noise, axis=1)
        uniqs = np.unique(shufflings, axis=0)
        class_permutations = balance(uniqs, n // len(uniqs))
    
    # 3. ç”Ÿæˆå­é‡‡æ ·ç´¢å¼•
    if isinstance(subsample_size, (int, float)):
        subsamples = generate_index_permutations(n, max_index, subsample_size, random_state)
    else:
        subsamples = [None] * n
    
    # 4. å‡è¡¡åˆ†é…é¢„å¤„ç†é…ç½®
    balance_count = n // len(preprocessor_configs)
    configs_ = balance(preprocessor_configs, balance_count)
    
    # 5. ç”Ÿæˆæœ€ç»ˆé…ç½®åˆ—è¡¨
    return [ClassifierEnsembleConfig(...) for ...]
```

#### 4. **æ•°æ®å¤„ç†ç®¡é“æ„å»º**

**ç®¡é“ç”Ÿæˆæ–¹æ³•** (`src/tabpfn/preprocessing.py:452-502`):
```python
def to_pipeline(self, *, random_state) -> SequentialFeatureTransformer:
    """å°†é›†æˆé…ç½®è½¬æ¢ä¸ºé¢„å¤„ç†ç®¡é“"""
    steps = []
    
    # æ­¥éª¤1: å¤šé¡¹å¼ç‰¹å¾ç”Ÿæˆï¼ˆå¯é€‰ï¼‰
    if use_poly_features:
        steps.append(NanHandlingPolynomialFeaturesStep(
            max_features=max_poly_features,
            random_state=random_state,
        ))
    
    # æ­¥éª¤2: æ ¸å¿ƒé¢„å¤„ç†æ­¥éª¤
    steps.extend([
        RemoveConstantFeaturesStep(),                    # ç§»é™¤å¸¸é‡ç‰¹å¾
        ReshapeFeatureDistributionsStep(                # ç‰¹å¾åˆ†å¸ƒé‡å¡‘
            transform_name=self.preprocess_config.name,
            append_to_original=self.preprocess_config.append_original,
            subsample_features=self.preprocess_config.subsample_features,
            global_transformer_name=self.preprocess_config.global_transformer_name,
            apply_to_categorical=(self.preprocess_config.categorical_name == "numeric"),
            random_state=random_state,
        ),
        EncodeCategoricalFeaturesStep(                  # ç±»åˆ«ç‰¹å¾ç¼–ç 
            self.preprocess_config.categorical_name,
            random_state=random_state,
        ),
    ])
    
    # æ­¥éª¤3: æŒ‡çº¹ç‰¹å¾æ·»åŠ ï¼ˆå¯é€‰ï¼‰
    if self.add_fingerprint_feature:
        steps.append(AddFingerprintFeaturesStep(random_state=random_state))
    
    # æ­¥éª¤4: ç‰¹å¾ä½ç½®æ‰“ä¹±
    steps.append(ShuffleFeaturesStep(
        shuffle_method=self.feature_shift_decoder,
        shuffle_index=self.feature_shift_count,
        random_state=random_state,
    ))
    
    return SequentialFeatureTransformer(steps)
```

#### 5. **å­é‡‡æ ·ç´¢å¼•ç”Ÿæˆ**

**ç´¢å¼•ç”Ÿæˆå‡½æ•°** (`src/tabpfn/preprocessing.py:204-238`):
```python
def generate_index_permutations(n, *, max_index, subsample, random_state):
    """ç”Ÿæˆç”¨äºå­é‡‡æ ·çš„ç´¢å¼•"""
    _, rng = infer_random_state(random_state)
    
    if isinstance(subsample, int):
        # å›ºå®šæ•°é‡å­é‡‡æ ·
        if subsample < 1:
            raise ValueError(f"{subsample=} must be larger than 1 if int")
        subsample = min(subsample, max_index)
        return [rng.permutation(max_index)[:subsample] for _ in range(n)]
    
    if isinstance(subsample, float):
        # æ¯”ä¾‹å­é‡‡æ ·
        if not (0 < subsample < 1):
            raise ValueError(f"{subsample=} must be in (0, 1) if float")
        subsample = int(subsample * max_index) + 1
        return [rng.permutation(max_index)[:subsample] for _ in range(n)]
```

#### 6. **å¹¶è¡Œé¢„å¤„ç†æ‰§è¡Œ**

**å¹¶è¡Œæ‰§è¡Œå‡½æ•°** (`src/tabpfn/preprocessing.py:593-671`):
```python
def fit_preprocessing(configs, X_train, y_train, *, random_state, cat_ix, 
                     n_workers, parallel_mode):
    """å¹¶è¡Œæ‹Ÿåˆå¤šä¸ªé¢„å¤„ç†ç®¡é“"""
    
    # ä½¿ç”¨joblibè¿›è¡Œå¹¶è¡Œå¤„ç†
    executor = joblib.Parallel(n_jobs=1, batch_size="auto")
    func = partial(fit_preprocessing_one, cat_ix=cat_ix)
    worker_func = joblib.delayed(func)
    
    # ä¸ºæ¯ä¸ªé…ç½®ç”Ÿæˆç‹¬ç«‹çš„éšæœºç§å­
    seeds = rng.integers(0, np.iinfo(np.int32).max, len(configs))
    
    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰é¢„å¤„ç†é…ç½®
    yield from executor([
        worker_func(config, X_train, y_train, seed)
        for config, seed in zip(configs, seeds)
    ])
```

**å•ä¸ªé…ç½®å¤„ç†** (`src/tabpfn/preprocessing.py:535-590`):
```python
def fit_preprocessing_one(config, X_train, y_train, random_state, *, cat_ix):
    """æ‹Ÿåˆå•ä¸ªé›†æˆé…ç½®çš„é¢„å¤„ç†ç®¡é“"""
    
    # 1. åº”ç”¨å­é‡‡æ ·ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
    if config.subsample_ix is not None:
        X_train = X_train[config.subsample_ix].copy()
        y_train = y_train[config.subsample_ix].copy()
    
    # 2. æ„å»ºå¹¶æ‹Ÿåˆé¢„å¤„ç†ç®¡é“
    preprocessor = config.to_pipeline(random_state=static_seed)
    res = preprocessor.fit_transform(X_train, cat_ix)
    
    # 3. åº”ç”¨ç›®æ ‡å˜é‡å˜æ¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if isinstance(config, RegressorEnsembleConfig):
        if config.target_transform is not None:
            y_train = config.target_transform.fit_transform(
                y_train.reshape(-1, 1)
            ).ravel()
    elif isinstance(config, ClassifierEnsembleConfig):
        if config.class_permutation is not None:
            y_train = config.class_permutation[y_train]  # åº”ç”¨ç±»åˆ«æ’åˆ—
    
    return (config, preprocessor, res.X, y_train, res.categorical_features)
```

### ğŸ¯ æ–‡ä»¶æ ¸å¿ƒä»·å€¼

#### 1. **é…ç½®ç®¡ç†ä¸­å¿ƒ**
- é›†ä¸­å®šä¹‰æ‰€æœ‰é¢„å¤„ç†ç­–ç•¥
- æä¾›é»˜è®¤é…ç½®å’Œè‡ªå®šä¹‰é…ç½®æ¥å£
- æ”¯æŒåˆ†ç±»å’Œå›å½’ä»»åŠ¡çš„ä¸åŒéœ€æ±‚

#### 2. **é›†æˆå­¦ä¹ å¼•æ“**
- è‡ªåŠ¨ç”Ÿæˆå¤šæ ·åŒ–çš„æ•°æ®å¤„ç†"è§†è§’"
- å®ç°ç‰¹å¾å˜æ¢ã€ç¼–ç ã€ä½ç§»ã€å­é‡‡æ ·çš„éšæœºåŒ–
- ç¡®ä¿é›†æˆæˆå‘˜çš„å¤šæ ·æ€§å’Œäº’è¡¥æ€§

#### 3. **ç®¡é“æ„å»ºå·¥å‚**
- å°†é…ç½®è½¬æ¢ä¸ºå¯æ‰§è¡Œçš„é¢„å¤„ç†ç®¡é“
- æ”¯æŒå¤æ‚çš„å¤šæ­¥éª¤æ•°æ®å˜æ¢
- ä¿è¯è®­ç»ƒå’Œé¢„æµ‹æ—¶çš„ä¸€è‡´æ€§

#### 4. **å¹¶è¡Œå¤„ç†æ¡†æ¶**
- æ”¯æŒå¤šä¸ªé¢„å¤„ç†é…ç½®çš„å¹¶è¡Œæ‰§è¡Œ
- ä¼˜åŒ–è®¡ç®—æ•ˆç‡å’Œå†…å­˜ä½¿ç”¨
- æä¾›çµæ´»çš„å¹¶è¡Œæ¨¡å¼é€‰æ‹©

### ğŸ”§ ä¸å…¶ä»–æ–‡ä»¶çš„å…³ç³»

#### è¾“å…¥ä¾èµ–
- **é…ç½®å‚æ•°**: ä»`config.py`è·å–é»˜è®¤é…ç½®
- **é¢„å¤„ç†æ­¥éª¤**: ä»`model/preprocessing.py`å¯¼å…¥å…·ä½“çš„å˜æ¢å™¨
- **å·¥å…·å‡½æ•°**: ä»`utils.py`è·å–éšæœºæ•°ç”Ÿæˆç­‰å·¥å…·

#### è¾“å‡ºæä¾›
- **é›†æˆé…ç½®**: ä¸º`classifier.py`å’Œ`regressor.py`æä¾›é…ç½®
- **é¢„å¤„ç†ç®¡é“**: ä¸ºæ¨ç†å¼•æ“æä¾›å¯æ‰§è¡Œçš„ç®¡é“
- **å¹¶è¡Œæ‰§è¡Œ**: ä¸ºè®­ç»ƒè¿‡ç¨‹æä¾›é«˜æ•ˆçš„é¢„å¤„ç†

### ğŸ“Š è®¾è®¡æ¨¡å¼ç‰¹ç‚¹

#### 1. **å·¥å‚æ¨¡å¼**
- `PreprocessorConfig`ä½œä¸ºé…ç½®å·¥å‚
- `EnsembleConfig`ä½œä¸ºé›†æˆé…ç½®å·¥å‚
- `to_pipeline()`ä½œä¸ºç®¡é“æ„å»ºå·¥å‚

#### 2. **ç­–ç•¥æ¨¡å¼**
- å¤šç§ç‰¹å¾å˜æ¢ç­–ç•¥å¯äº’æ¢
- å¤šç§ç¼–ç ç­–ç•¥å¯é€‰æ‹©
- å¤šç§éšæœºåŒ–ç­–ç•¥å¯ç»„åˆ

#### 3. **å»ºé€ è€…æ¨¡å¼**
- é€æ­¥æ„å»ºå¤æ‚çš„é¢„å¤„ç†ç®¡é“
- æ”¯æŒå¯é€‰ç»„ä»¶çš„çµæ´»ç»„åˆ
- ä¿è¯æ„å»ºè¿‡ç¨‹çš„ä¸€è‡´æ€§

### ğŸš€ åˆ›æ–°è®¾è®¡ç†å¿µ

#### 1. **è‡ªåŠ¨åŒ–ç‰¹å¾å·¥ç¨‹**
- æ— éœ€æ‰‹åŠ¨é€‰æ‹©æœ€ä½³é¢„å¤„ç†æ–¹æ³•
- è‡ªåŠ¨æ¢ç´¢å¤šç§æ•°æ®å˜æ¢ç»„åˆ
- é€šè¿‡é›†æˆå­¦ä¹ è·å¾—æœ€ä½³æ•ˆæœ

#### 2. **æ•°æ®å¢å¼ºæ€æƒ³**
- æ¯ä¸ªé›†æˆæˆå‘˜çœ‹åˆ°ä¸åŒçš„æ•°æ®"è§†è§’"
- é€šè¿‡éšæœºåŒ–å¢åŠ æ•°æ®çš„å¤šæ ·æ€§
- æå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§

#### 3. **ç«¯åˆ°ç«¯ä¼˜åŒ–**
- é¢„å¤„ç†ä¸æ¨¡å‹è®­ç»ƒç´§å¯†é›†æˆ
- è€ƒè™‘ä¸‹æ¸¸ä»»åŠ¡çš„ç‰¹å®šéœ€æ±‚
- é’ˆå¯¹Transformeræ¶æ„è¿›è¡Œä¼˜åŒ–

è¿™ä¸ªæ–‡ä»¶ä½“ç°äº†TabPFNåœ¨è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ æ–¹é¢çš„å…ˆè¿›ç†å¿µï¼Œé€šè¿‡æ™ºèƒ½çš„é…ç½®ç®¡ç†å’Œé›†æˆç­–ç•¥ï¼Œå®ç°äº†é«˜æ•ˆã€çµæ´»ã€å¯æ‰©å±•çš„æ•°æ®é¢„å¤„ç†ç³»ç»Ÿã€‚

---

## ğŸ¯ TabPFNé¢„å¤„ç†ç³»ç»Ÿæ€»ç»“

### ğŸ† æ ¸å¿ƒåˆ›æ–°ç‚¹

#### 1. **è‡ªåŠ¨åŒ–ç‰¹å¾å·¥ç¨‹**
- **25ç§æ•°å€¼å˜æ¢æ–¹æ³•**ï¼šä»ç®€å•æ ‡å‡†åŒ–åˆ°å¤æ‚KDIå˜æ¢ï¼Œè‡ªåŠ¨æ¢ç´¢æœ€ä½³å˜æ¢
- **6ç§ç±»åˆ«ç¼–ç ç­–ç•¥**ï¼šæ™ºèƒ½é€‰æ‹©åˆé€‚çš„ç¼–ç æ–¹æ³•ï¼Œé¿å…ç»´åº¦çˆ†ç‚¸
- **è‡ªåŠ¨ç±»åˆ«ç‰¹å¾æ¨æ–­**ï¼šåŸºäºå”¯ä¸€å€¼æ•°é‡å’Œæ ·æœ¬å¤§å°çš„æ™ºèƒ½æ¨æ–­

#### 2. **å¤šæ ·åŒ–é›†æˆç­–ç•¥**
- **äº”ç»´éšæœºåŒ–**ï¼šç‰¹å¾å˜æ¢ã€ç¼–ç æ–¹å¼ã€ä½ç½®æ‰“ä¹±ã€æ ‡ç­¾æ’åˆ—ã€æ•°æ®å­é‡‡æ ·
- **å‡è¡¡åˆ†é…æœºåˆ¶**ï¼šç¡®ä¿æ‰€æœ‰ç­–ç•¥éƒ½è¢«å…¬å¹³ä½¿ç”¨
- **ç‹¬ç«‹éšæœºåŒ–**ï¼šæ¯ä¸ªé›†æˆæˆå‘˜ä½¿ç”¨å®Œå…¨ç‹¬ç«‹çš„éšæœºç§å­

#### 3. **åˆ†å±‚æ¶æ„è®¾è®¡**
- **å…­é˜¶æ®µæµæ°´çº¿**ï¼šæ•°æ®éªŒè¯â†’åŸºç¡€é¢„å¤„ç†â†’é…ç½®ç”Ÿæˆâ†’ç®¡é“æ„å»ºâ†’å¼•æ“åˆ›å»ºâ†’é¢„æµ‹æ‰§è¡Œ
- **æ¨¡å—åŒ–ç»„ä»¶**ï¼šæ¯ä¸ªé¢„å¤„ç†æ­¥éª¤éƒ½æ˜¯ç‹¬ç«‹çš„ã€å¯æ›¿æ¢çš„ç»„ä»¶
- **çµæ´»é…ç½®ç³»ç»Ÿ**ï¼šæ”¯æŒç”¨æˆ·è‡ªå®šä¹‰å’Œé»˜è®¤é…ç½®çš„å®Œç¾ç»“åˆ

#### 4. **é«˜æ•ˆå¹¶è¡Œæ‰§è¡Œ**
- **ç®¡é“çº§å¹¶è¡Œ**ï¼šå¤šä¸ªé›†æˆé…ç½®å¯ä»¥å®Œå…¨å¹¶è¡Œæ‹Ÿåˆ
- **å†…å­˜ä¼˜åŒ–**ï¼šä¸‰ç§fit_modeæ»¡è¶³ä¸åŒå†…å­˜å’Œé€Ÿåº¦éœ€æ±‚
- **GPUåŠ é€Ÿ**ï¼šæ”¯æŒè‡ªåŠ¨æ··åˆç²¾åº¦å’Œè®¾å¤‡è‡ªåŠ¨é€‰æ‹©

### ğŸ”§ æŠ€æœ¯ä¼˜åŠ¿

#### 1. **é²æ£’æ€§**
- **é¢„è®­ç»ƒé™åˆ¶æ£€æŸ¥**ï¼šé˜²æ­¢è¶…å‡ºæ¨¡å‹èƒ½åŠ›èŒƒå›´
- **æ•°æ®ç±»å‹å…¼å®¹**ï¼šè‡ªåŠ¨å¤„ç†pandas/numpyå…¼å®¹æ€§é—®é¢˜
- **ç¼ºå¤±å€¼å¤„ç†**ï¼šæ™ºèƒ½å¤„ç†NaNå€¼ï¼Œé¿å…ä¿¡æ¯ä¸¢å¤±
- **å¼‚å¸¸å€¼æ£€æµ‹**ï¼šè‡ªåŠ¨è¯†åˆ«å’Œå¤„ç†æ•°æ®å¼‚å¸¸

#### 2. **å¯æ‰©å±•æ€§**
- **ä»»æ„é›†æˆè§„æ¨¡**ï¼šæ”¯æŒä»å°åˆ°å¤§çš„n_estimatorsè®¾ç½®
- **çµæ´»é…ç½®**ï¼šæ˜“äºæ·»åŠ æ–°çš„å˜æ¢æ–¹æ³•å’Œç¼–ç ç­–ç•¥
- **æ¨¡å—åŒ–è®¾è®¡**ï¼šä¾¿äºç»´æŠ¤å’ŒåŠŸèƒ½æ‰©å±•
- **å‘åå…¼å®¹**ï¼šä¿æŒAPIç¨³å®šæ€§

#### 3. **å¯é‡ç°æ€§**
- **åˆ†å±‚éšæœºç§å­**ï¼šå››å±‚ç§å­ä½“ç³»ç¡®ä¿å®Œå…¨å¯é‡ç°
- **ç¡®å®šæ€§é…ç½®**ï¼šç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡º
- **è°ƒè¯•å‹å¥½**ï¼šæ¯ä¸ªæ­¥éª¤éƒ½å¯ä»¥å•ç‹¬éªŒè¯å’Œè°ƒè¯•

#### 4. **æ€§èƒ½ä¼˜åŒ–**
- **è®¡ç®—æ•ˆç‡**ï¼šå¹¶è¡Œå¤„ç†å’ŒGPUåŠ é€Ÿ
- **å†…å­˜æ•ˆç‡**ï¼šå¤šç§å†…å­˜æ¨¡å¼é€‚åº”ä¸åŒç¡¬ä»¶
- **é¢„å¤„ç†ç¼“å­˜**ï¼šé¿å…é‡å¤è®¡ç®—ï¼Œæå‡é¢„æµ‹é€Ÿåº¦

### ğŸ¨ è®¾è®¡å“²å­¦

#### 1. **è‡ªåŠ¨åŒ–ä¼˜å…ˆ**
- **æœ€å°ç”¨æˆ·å¹²é¢„**ï¼šå¤§å¤šæ•°é…ç½®éƒ½æœ‰åˆç†çš„é»˜è®¤å€¼
- **æ™ºèƒ½æ¨æ–­**ï¼šè‡ªåŠ¨è¯†åˆ«æ•°æ®ç‰¹å¾å’Œæœ€ä½³å¤„ç†ç­–ç•¥
- **ç«¯åˆ°ç«¯ä¼˜åŒ–**ï¼šä»æ•°æ®è¾“å…¥åˆ°æ¨¡å‹è¾“å‡ºçš„å…¨æµç¨‹ä¼˜åŒ–

#### 2. **å¤šæ ·æ€§é©±åŠ¨**
- **æ•°æ®å¢å¼ºæ€æƒ³**ï¼šé€šè¿‡å¤šç§å˜æ¢å¢åŠ æ•°æ®è§†è§’
- **é›†æˆå­¦ä¹ ç†å¿µ**ï¼šé€šè¿‡å¤šæ ·æ€§æå‡æ¨¡å‹æ€§èƒ½
- **é²æ£’æ€§è€ƒè™‘**ï¼šå‡å°‘å¯¹ç‰¹å®šæ•°æ®åˆ†å¸ƒçš„ä¾èµ–

#### 3. **å®ç”¨æ€§å¯¼å‘**
- **åŒ»ç–—æ•°æ®å‹å¥½**ï¼šç‰¹åˆ«é€‚åˆç±»åˆ«ç‰¹å¾è¾ƒå¤šçš„åŒ»ç–—æ•°æ®
- **å°æ ·æœ¬ä¼˜åŒ–**ï¼šé’ˆå¯¹è¡¨æ ¼æ•°æ®çš„å°æ ·æœ¬åœºæ™¯ä¼˜åŒ–
- **æ˜“äºé›†æˆ**ï¼šä¸ç°æœ‰MLå·¥ä½œæµç¨‹æ— ç¼é›†æˆ

### ğŸ“Š é€‚ç”¨åœºæ™¯

#### 1. **æœ€ä½³é€‚ç”¨åœºæ™¯**
- **è¡¨æ ¼æ•°æ®åˆ†ç±»/å›å½’**ï¼šTabPFNçš„æ ¸å¿ƒåº”ç”¨é¢†åŸŸ
- **å°åˆ°ä¸­ç­‰è§„æ¨¡æ•°æ®é›†**ï¼šæ ·æœ¬æ•°â‰¤10Kï¼Œç‰¹å¾æ•°â‰¤500
- **æ··åˆæ•°æ®ç±»å‹**ï¼šæ•°å€¼+ç±»åˆ«ç‰¹å¾çš„æ··åˆæ•°æ®
- **å¿«é€ŸåŸå‹å¼€å‘**ï¼šéœ€è¦å¿«é€Ÿè·å¾—åŸºçº¿ç»“æœ

#### 2. **åŒ»ç–—æ•°æ®ç‰¹åˆ«ä¼˜åŠ¿**
- **ç±»åˆ«ç‰¹å¾å¤„ç†**ï¼šåŒ»ç–—æ•°æ®ä¸­å¸¸è§çš„åˆ†ç±»å˜é‡
- **ç¼ºå¤±å€¼é²æ£’**ï¼šåŒ»ç–—æ•°æ®ä¸­å¸¸è§çš„ç¼ºå¤±å€¼é—®é¢˜
- **å°æ ·æœ¬æ€§èƒ½**ï¼šåŒ»ç–—æ•°æ®é›†é€šå¸¸è§„æ¨¡è¾ƒå°
- **å¯è§£é‡Šæ€§éœ€æ±‚**ï¼šæ”¯æŒSHAPç­‰å¯è§£é‡Šæ€§åˆ†æ

#### 3. **é™åˆ¶å’Œæ³¨æ„äº‹é¡¹**
- **é¢„è®­ç»ƒé™åˆ¶**ï¼šå—é¢„è®­ç»ƒæ•°æ®åˆ†å¸ƒçº¦æŸ
- **è§„æ¨¡é™åˆ¶**ï¼šä¸é€‚åˆè¶…å¤§è§„æ¨¡æ•°æ®é›†
- **é¢†åŸŸé€‚åº”**ï¼šå¯èƒ½éœ€è¦é¢†åŸŸç‰¹å®šçš„è°ƒä¼˜
- **è®¡ç®—èµ„æº**ï¼šéœ€è¦GPUæ”¯æŒä»¥è·å¾—æœ€ä½³æ€§èƒ½

### ğŸš€ æœªæ¥å‘å±•æ–¹å‘

#### 1. **æŠ€æœ¯æ”¹è¿›**
- **æ›´å¤šå˜æ¢æ–¹æ³•**ï¼šæ‰©å±•æ•°å€¼å˜æ¢å’Œç¼–ç ç­–ç•¥
- **è‡ªé€‚åº”é…ç½®**ï¼šæ ¹æ®æ•°æ®ç‰¹å¾è‡ªåŠ¨é€‰æ‹©æœ€ä½³é…ç½®
- **å¢é‡å­¦ä¹ **ï¼šæ”¯æŒåœ¨çº¿å­¦ä¹ å’Œæ¨¡å‹æ›´æ–°
- **å¤šæ¨¡æ€æ”¯æŒ**ï¼šæ‰©å±•åˆ°æ–‡æœ¬ã€å›¾åƒç­‰å…¶ä»–æ•°æ®ç±»å‹

#### 2. **æ€§èƒ½ä¼˜åŒ–**
- **æ›´é«˜æ•ˆçš„å¹¶è¡Œ**ï¼šè¿›ä¸€æ­¥ä¼˜åŒ–å¹¶è¡Œæ‰§è¡Œç­–ç•¥
- **å†…å­˜ä¼˜åŒ–**ï¼šå‡å°‘å†…å­˜å ç”¨ï¼Œæ”¯æŒæ›´å¤§æ•°æ®é›†
- **é€Ÿåº¦æå‡**ï¼šä¼˜åŒ–é¢„å¤„ç†å’Œæ¨ç†é€Ÿåº¦
- **ç²¾åº¦æ”¹è¿›**ï¼šå¹³è¡¡é€Ÿåº¦å’Œç²¾åº¦çš„trade-off

#### 3. **æ˜“ç”¨æ€§æå‡**
- **è‡ªåŠ¨è°ƒå‚**ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³è¶…å‚æ•°
- **å¯è§†åŒ–å·¥å…·**ï¼šæä¾›é¢„å¤„ç†è¿‡ç¨‹çš„å¯è§†åŒ–
- **è¯Šæ–­å·¥å…·**ï¼šæ›´å¥½çš„è°ƒè¯•å’Œæ€§èƒ½åˆ†æå·¥å…·
- **æ–‡æ¡£å®Œå–„**ï¼šæ›´è¯¦ç»†çš„ä½¿ç”¨æŒ‡å—å’Œæœ€ä½³å®è·µ

---

**ç»“è®º**ï¼šTabPFNçš„é¢„å¤„ç†ç³»ç»Ÿä»£è¡¨äº†è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ åœ¨è¡¨æ ¼æ•°æ®å¤„ç†æ–¹é¢çš„é‡è¦è¿›å±•ã€‚é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„å¤šå±‚æ¬¡æ¶æ„ã€æ™ºèƒ½çš„é…ç½®ç®¡ç†å’Œé«˜æ•ˆçš„å¹¶è¡Œæ‰§è¡Œï¼Œå®ƒä¸ºç”¨æˆ·æä¾›äº†ä¸€ä¸ªå¼ºå¤§ã€çµæ´»ã€æ˜“ç”¨çš„æ•°æ®é¢„å¤„ç†è§£å†³æ–¹æ¡ˆã€‚å¯¹äºåŒ»ç–—æ•°æ®ç­‰ç‰¹å®šé¢†åŸŸçš„åº”ç”¨ï¼ŒTabPFNçš„é¢„å¤„ç†ç³»ç»Ÿç‰¹åˆ«å€¼å¾—æ·±å…¥ç ”ç©¶å’Œåº”ç”¨ã€‚