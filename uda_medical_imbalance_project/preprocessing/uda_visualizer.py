"""
UDA Medical Imbalance Project - UDAç»“æœå¯è§†åŒ–å™¨

å®ç°åŸŸé€‚åº”å‰åçš„å¯è§†åŒ–å¯¹æ¯”åˆ†æï¼ŒåŒ…æ‹¬ï¼š
1. é™ç»´å¯è§†åŒ– (PCA, t-SNE)
2. ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”
3. åŸŸè·ç¦»åº¦é‡ (KLæ•£åº¦, Wassersteinè·ç¦», MMD)
4. æ€§èƒ½å¯¹æ¯”å›¾è¡¨

ä½œè€…: UDA Medical Team
æ—¥æœŸ: 2025-06-27
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, Any, Optional, Tuple, List, Union
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# ç§‘å­¦è®¡ç®—å’Œå¯è§†åŒ–
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from scipy import stats
from scipy.stats import entropy

# Wassersteinè·ç¦»å¯¼å…¥ï¼ˆå…¼å®¹ä¸åŒscipyç‰ˆæœ¬ï¼‰
try:
    from scipy.spatial.distance import wasserstein_distance
except ImportError:
    try:
        from scipy.stats import wasserstein_distance
    except ImportError:
        # å¦‚æœéƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–å®ç°
        def wasserstein_distance(u_values: np.ndarray, v_values: np.ndarray) -> float:
            """ç®€åŒ–çš„Wassersteinè·ç¦»å®ç°"""
            return np.mean(np.abs(np.sort(u_values) - np.sort(v_values)))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    from uda.adapt_methods import AdaptUDAMethod
    UDA_AVAILABLE = True
except ImportError:
    UDA_AVAILABLE = False
    # åˆ›å»ºå ä½ç¬¦ç±»å‹
    class AdaptUDAMethod:
        pass

import logging
logger = logging.getLogger(__name__)

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
sns.set_palette("husl")

# æ·»åŠ ADAPTåº“çš„ä¸“ä¸šæŒ‡æ ‡å¯¼å…¥
try:
    from adapt.metrics import (
        cov_distance,
        neg_j_score, 
        linear_discrepancy,
        normalized_linear_discrepancy,
        frechet_distance,
        normalized_frechet_distance
    )
    ADAPT_AVAILABLE = True
    print("âœ… ADAPTåº“æŒ‡æ ‡å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ ADAPTåº“å¯¼å…¥å¤±è´¥: {e}")
    print("ğŸ“ å°†ä½¿ç”¨å¤‡ç”¨æŒ‡æ ‡è®¡ç®—æ–¹æ³•")
    ADAPT_AVAILABLE = False

class UDAVisualizer:
    """UDAç»“æœå¯è§†åŒ–å™¨"""
    
    def __init__(self, figsize: Tuple[int, int] = (12, 8), 
                 save_plots: bool = True, 
                 output_dir: str = "results/uda_visualization"):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å™¨
        
        å‚æ•°:
        - figsize: å›¾ç‰‡å¤§å°
        - save_plots: æ˜¯å¦ä¿å­˜å›¾ç‰‡
        - output_dir: è¾“å‡ºç›®å½•
        """
        super().__init__()
        self.figsize = figsize
        self.save_plots = save_plots
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # é¢œè‰²é…ç½®
        self.colors = {
            'source': '#2E86AB',      # è“è‰² - æºåŸŸ
            'target': '#A23B72',      # ç´«è‰² - ç›®æ ‡åŸŸ
            'adapted': '#F18F01',     # æ©™è‰² - é€‚åº”å
            'class_0': '#E63946',     # çº¢è‰² - ç±»åˆ«0
            'class_1': '#2A9D8F'      # ç»¿è‰² - ç±»åˆ«1
        }
        
        logger.info(f"UDAå¯è§†åŒ–å™¨åˆå§‹åŒ–å®Œæˆï¼Œè¾“å‡ºç›®å½•: {self.output_dir}")
    
    def visualize_domain_adaptation_complete(self, 
                                           X_source: np.ndarray, 
                                           y_source: np.ndarray,
                                           X_target: np.ndarray, 
                                           y_target: np.ndarray,
                                           uda_method: Optional[AdaptUDAMethod] = None,
                                           method_name: str = "UDA") -> Dict[str, Any]:
        """
        å®Œæ•´çš„åŸŸé€‚åº”å¯è§†åŒ–åˆ†æ
        
        å‚æ•°:
        - X_source, y_source: æºåŸŸæ•°æ®
        - X_target, y_target: ç›®æ ‡åŸŸæ•°æ®  
        - uda_method: è®­ç»ƒå¥½çš„UDAæ–¹æ³•
        - method_name: æ–¹æ³•åç§°
        
        è¿”å›:
        - å¯è§†åŒ–ç»“æœå­—å…¸
        """
        results = {}
        
        print(f"\n=== {method_name} åŸŸé€‚åº”å¯è§†åŒ–åˆ†æ ===")
        
        # 1. é™ç»´å¯è§†åŒ–
        print("1. ç”Ÿæˆé™ç»´å¯è§†åŒ–...")
        pca_results = self.plot_dimensionality_reduction(
            X_source, y_source, X_target, y_target, 
            uda_method, method_name
        )
        results['dimensionality_reduction'] = pca_results
        
        # 2. ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”
        print("2. åˆ†æç‰¹å¾åˆ†å¸ƒ...")
        dist_results = self.plot_feature_distributions(
            X_source, X_target, uda_method, method_name
        )
        results['feature_distributions'] = dist_results
        
        # 3. åŸŸè·ç¦»åº¦é‡
        print("3. è®¡ç®—åŸŸè·ç¦»åº¦é‡...")
        distance_results = self.calculate_domain_distances(
            X_source, X_target, uda_method, method_name
        )
        results['domain_distances'] = distance_results
        
        # 4. æ€§èƒ½å¯¹æ¯”
        if uda_method is not None:
            print("4. ç”Ÿæˆæ€§èƒ½å¯¹æ¯”...")
            perf_results = self.plot_performance_comparison(
                X_source, y_source, X_target, y_target,
                uda_method, method_name
            )
            results['performance'] = perf_results
        
        print(f"âœ“ {method_name} å¯è§†åŒ–åˆ†æå®Œæˆ")
        return results
    
    def plot_dimensionality_reduction(self, 
                                    X_source: np.ndarray, 
                                    y_source: np.ndarray,
                                    X_target: np.ndarray, 
                                    y_target: np.ndarray,
                                    uda_method: Optional[AdaptUDAMethod] = None,
                                    method_name: str = "UDA") -> Dict[str, Any]:
        """é™ç»´å¯è§†åŒ– (PCA + t-SNE)"""
        
        # æ•°æ®å‡†å¤‡ - è·å–é€‚åº”åçš„ç‰¹å¾
        X_source_adapted, X_target_adapted = self._get_adapted_features(
            X_source, X_target, uda_method, method_name
        )
        
        # ç›´æ¥ä½¿ç”¨åŸå§‹ç‰¹å¾ï¼Œä¸è¿›è¡Œæ ‡å‡†åŒ–
        print("  ğŸ“ ç›´æ¥ä½¿ç”¨åŸå§‹ç‰¹å¾è¿›è¡Œå¯è§†åŒ–ï¼Œä¸è¿›è¡Œæ ‡å‡†åŒ–")
        
        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle(f'{method_name} - Domain Adaptation Visualization', fontsize=16, fontweight='bold')
        
        results = {}
        
        # PCAå¯è§†åŒ–
        self._plot_pca_comparison(
            X_source, y_source, X_target, y_target,
            X_source_adapted, X_target_adapted,
            axes[0, :], method_name
        )
        
        # t-SNEå¯è§†åŒ–
        tsne_results = self._plot_tsne_comparison(
            X_source, y_source, X_target, y_target,
            X_source_adapted, X_target_adapted,
            axes[1, :], method_name
        )
        
        plt.tight_layout()
        
        if self.save_plots:
            save_path = self.output_dir / f"{method_name}_dimensionality_reduction.png"
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"  é™ç»´å¯è§†åŒ–å·²ä¿å­˜: {save_path}")
        
        plt.show()
        
        results.update(tsne_results)
        return results
    
    def _plot_pca_comparison(self, X_source: np.ndarray, y_source: np.ndarray, 
                           X_target: np.ndarray, y_target: np.ndarray,
                           X_source_adapted: np.ndarray, X_target_adapted: np.ndarray, 
                           axes: np.ndarray, method_name: str) -> None:
        """PCAå¯¹æ¯”å›¾"""
        
        # åˆå¹¶æ•°æ®è¿›è¡ŒPCA
        X_combined_before = np.vstack([X_source, X_target])
        X_combined_after = np.vstack([X_source_adapted, X_target_adapted])
        
        # PCAé™ç»´
        pca = PCA(n_components=2)
        X_pca_before = pca.fit_transform(X_combined_before)
        X_pca_after = pca.fit_transform(X_combined_after)
        
        n_source = len(X_source)
        
        # åŸŸé€‚åº”å‰
        ax1 = axes[0]
        ax1.scatter(X_pca_before[:n_source, 0], X_pca_before[:n_source, 1], 
                   c=self.colors['source'], alpha=0.6, label='Source Domain', s=50)
        ax1.scatter(X_pca_before[n_source:, 0], X_pca_before[n_source:, 1], 
                   c=self.colors['target'], alpha=0.6, label='Target Domain', s=50)
        ax1.set_title('Before Domain Adaptation (PCA)', fontweight='bold')
        ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')
        ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # åŸŸé€‚åº”å
        ax2 = axes[1]
        ax2.scatter(X_pca_after[:n_source, 0], X_pca_after[:n_source, 1], 
                   c=self.colors['source'], alpha=0.6, label='Source Domain', s=50)
        ax2.scatter(X_pca_after[n_source:, 0], X_pca_after[n_source:, 1], 
                   c=self.colors['adapted'], alpha=0.6, label='Target Domain (Adapted)', s=50)
        ax2.set_title(f'After {method_name} (PCA)', fontweight='bold')
        ax2.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')
        ax2.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
    
    def _plot_tsne_comparison(self, X_source: np.ndarray, y_source: np.ndarray, 
                            X_target: np.ndarray, y_target: np.ndarray,
                            X_source_adapted: np.ndarray, X_target_adapted: np.ndarray, 
                            axes: np.ndarray, method_name: str) -> Dict[str, Any]:
        """t-SNEå¯¹æ¯”å›¾"""
        
        # ä¸ºäº†è®¡ç®—æ•ˆç‡ï¼Œé™åˆ¶æ ·æœ¬æ•°é‡
        max_samples = 500
        if len(X_source) > max_samples:
            idx_source = np.random.choice(len(X_source), max_samples, replace=False)
            X_source = X_source[idx_source]
            y_source = y_source[idx_source]
            X_source_adapted = X_source_adapted[idx_source]
        
        if len(X_target) > max_samples:
            idx_target = np.random.choice(len(X_target), max_samples, replace=False)
            X_target = X_target[idx_target]
            y_target = y_target[idx_target]
            X_target_adapted = X_target_adapted[idx_target]
        
        # åˆå¹¶æ•°æ®è¿›è¡Œt-SNE
        X_combined_before = np.vstack([X_source, X_target])
        X_combined_after = np.vstack([X_source_adapted, X_target_adapted])
        
        # t-SNEé™ç»´
        tsne = TSNE(n_components=2, random_state=42, perplexity=30)
        X_tsne_before = tsne.fit_transform(X_combined_before)
        
        tsne_after = TSNE(n_components=2, random_state=42, perplexity=30)
        X_tsne_after = tsne_after.fit_transform(X_combined_after)
        
        n_source = len(X_source)
        
        # åŸŸé€‚åº”å‰
        ax1 = axes[0]
        ax1.scatter(X_tsne_before[:n_source, 0], X_tsne_before[:n_source, 1], 
                   c=self.colors['source'], alpha=0.6, label='Source Domain', s=50)
        ax1.scatter(X_tsne_before[n_source:, 0], X_tsne_before[n_source:, 1], 
                   c=self.colors['target'], alpha=0.6, label='Target Domain', s=50)
        ax1.set_title('Before Domain Adaptation (t-SNE)', fontweight='bold')
        ax1.set_xlabel('t-SNE 1')
        ax1.set_ylabel('t-SNE 2')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # åŸŸé€‚åº”å
        ax2 = axes[1]
        ax2.scatter(X_tsne_after[:n_source, 0], X_tsne_after[:n_source, 1], 
                   c=self.colors['source'], alpha=0.6, label='Source Domain', s=50)
        ax2.scatter(X_tsne_after[n_source:, 0], X_tsne_after[n_source:, 1], 
                   c=self.colors['adapted'], alpha=0.6, label='Target Domain (Adapted)', s=50)
        ax2.set_title(f'After {method_name} (t-SNE)', fontweight='bold')
        ax2.set_xlabel('t-SNE 1')
        ax2.set_ylabel('t-SNE 2')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        return {
            'tsne_before': X_tsne_before,
            'tsne_after': X_tsne_after,
            'n_source_samples': n_source
        }
    
    def plot_feature_distributions(self, 
                                 X_source: np.ndarray, 
                                 X_target: np.ndarray,
                                 uda_method: Optional[AdaptUDAMethod] = None,
                                 method_name: str = "UDA") -> Dict[str, Any]:
        """ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”å¯è§†åŒ– - ç”±äºç‰¹å¾å°ºåº¦å·®å¼‚å¤§ï¼Œè·³è¿‡å¯è§†åŒ–"""
        
        print(f"  ğŸ“ è·³è¿‡ç‰¹å¾åˆ†å¸ƒå¯è§†åŒ–ï¼ˆç‰¹å¾å°ºåº¦å·®å¼‚è¿‡å¤§ï¼Œä¸é€‚åˆç›´æ¥å¯è§†åŒ–ï¼‰")
        
        # è·å–é€‚åº”åçš„ç‰¹å¾ç”¨äºè¿”å›
        X_source_adapted, X_target_adapted = self._get_adapted_features(
            X_source, X_target, uda_method, method_name
        )
        
        return {
            'source_original': X_source,
            'target_original': X_target,
            'source_adapted': X_source_adapted,
            'target_adapted': X_target_adapted
        }
    
    def calculate_domain_distances(self, 
                                 X_source: np.ndarray, 
                                 X_target: np.ndarray,
                                 uda_method: Optional[AdaptUDAMethod] = None,
                                 method_name: str = "UDA") -> Dict[str, float]:
        """è®¡ç®—åŸŸè·ç¦»åº¦é‡ - ä½¿ç”¨ADAPTåº“çš„ä¸“ä¸šæŒ‡æ ‡"""
        
        # è·å–é€‚åº”åçš„ç‰¹å¾
        X_source_adapted, X_target_adapted = self._get_adapted_features(
            X_source, X_target, uda_method, method_name
        )
        
        distances = {}
        
        if ADAPT_AVAILABLE:
            # ä½¿ç”¨ADAPTåº“çš„æ ‡å‡†åŒ–æŒ‡æ ‡ï¼ˆåªä¿ç•™ç¨³å®šçš„æ ‡å‡†åŒ–ç‰ˆæœ¬ï¼‰
            print(f"  ğŸ“Š ä½¿ç”¨ADAPTåº“æ ‡å‡†åŒ–æŒ‡æ ‡è®¡ç®—åŸŸè·ç¦»...")
            
            # 1. æ ‡å‡†åŒ–çº¿æ€§å·®å¼‚ (Normalized Linear Discrepancy)
            try:
                norm_linear_disc_before = normalized_linear_discrepancy(X_source, X_target)
                distances['normalized_linear_discrepancy_before'] = float(norm_linear_disc_before)
                
                if uda_method is not None:
                    norm_linear_disc_after = normalized_linear_discrepancy(X_source_adapted, X_target_adapted)
                    distances['normalized_linear_discrepancy_after'] = float(norm_linear_disc_after)
                    distances['normalized_linear_discrepancy_improvement'] = float(norm_linear_disc_before - norm_linear_disc_after)
                    
                    print(f"  ğŸ“Š æ ‡å‡†åŒ–çº¿æ€§å·®å¼‚ (Normalized Linear Discrepancy):")
                    print(f"    é€‚åº”å‰: {norm_linear_disc_before:.6f}")
                    print(f"    é€‚åº”å: {norm_linear_disc_after:.6f}")
                    print(f"    æ”¹è¿›: {norm_linear_disc_before - norm_linear_disc_after:.6f}")
                else:
                    distances['normalized_linear_discrepancy_after'] = distances['normalized_linear_discrepancy_before']
                    distances['normalized_linear_discrepancy_improvement'] = 0.0
            except Exception as e:
                print(f"  âš ï¸ æ ‡å‡†åŒ–çº¿æ€§å·®å¼‚è®¡ç®—å¤±è´¥: {e}")
            
            # 2. æ ‡å‡†åŒ–Frechetè·ç¦» (Normalized Frechet Distance)
            try:
                norm_frechet_dist_before = normalized_frechet_distance(X_source, X_target)
                distances['normalized_frechet_distance_before'] = float(norm_frechet_dist_before)
                
                if uda_method is not None:
                    norm_frechet_dist_after = normalized_frechet_distance(X_source_adapted, X_target_adapted)
                    distances['normalized_frechet_distance_after'] = float(norm_frechet_dist_after)
                    distances['normalized_frechet_distance_improvement'] = float(norm_frechet_dist_before - norm_frechet_dist_after)
                    
                    print(f"  ğŸ“Š æ ‡å‡†åŒ–Frechetè·ç¦» (Normalized Frechet Distance):")
                    print(f"    é€‚åº”å‰: {norm_frechet_dist_before:.6f}")
                    print(f"    é€‚åº”å: {norm_frechet_dist_after:.6f}")
                    print(f"    æ”¹è¿›: {norm_frechet_dist_before - norm_frechet_dist_after:.6f}")
                else:
                    distances['normalized_frechet_distance_after'] = distances['normalized_frechet_distance_before']
                    distances['normalized_frechet_distance_improvement'] = 0.0
            except Exception as e:
                print(f"  âš ï¸ æ ‡å‡†åŒ–Frechetè·ç¦»è®¡ç®—å¤±è´¥: {e}")
            
            # 3. æ ‡å‡†åŒ–Wassersteinè·ç¦» (æˆ‘ä»¬è‡ªå®šä¹‰çš„å®ç°)
            try:
                norm_ws_before = self._calculate_normalized_wasserstein_distance(X_source, X_target)
                distances['normalized_wasserstein_before'] = norm_ws_before
                
                if uda_method is not None:
                    norm_ws_after = self._calculate_normalized_wasserstein_distance(X_source_adapted, X_target_adapted)
                    distances['normalized_wasserstein_after'] = norm_ws_after
                    distances['normalized_wasserstein_improvement'] = norm_ws_before - norm_ws_after
                    
                    print(f"  ğŸ“Š æ ‡å‡†åŒ–Wassersteinè·ç¦» (Normalized Wasserstein Distance):")
                    print(f"    é€‚åº”å‰: {norm_ws_before:.6f}")
                    print(f"    é€‚åº”å: {norm_ws_after:.6f}")
                    print(f"    æ”¹è¿›: {norm_ws_before - norm_ws_after:.6f}")
                else:
                    distances['normalized_wasserstein_after'] = norm_ws_before
                    distances['normalized_wasserstein_improvement'] = 0.0
            except Exception as e:
                print(f"  âš ï¸ æ ‡å‡†åŒ–Wassersteinè·ç¦»è®¡ç®—å¤±è´¥: {e}")
            
            # 4. æ ‡å‡†åŒ–KLæ•£åº¦ (æˆ‘ä»¬è‡ªå®šä¹‰çš„å®ç°)
            try:
                norm_kl_before = self._calculate_normalized_kl_divergence(X_source, X_target)
                distances['normalized_kl_divergence_before'] = norm_kl_before
                
                if uda_method is not None:
                    norm_kl_after = self._calculate_normalized_kl_divergence(X_source_adapted, X_target_adapted)
                    distances['normalized_kl_divergence_after'] = norm_kl_after
                    distances['normalized_kl_divergence_improvement'] = norm_kl_before - norm_kl_after
                    
                    print(f"  ğŸ“Š æ ‡å‡†åŒ–KLæ•£åº¦ (Normalized KL Divergence):")
                    print(f"    é€‚åº”å‰: {norm_kl_before:.6f}")
                    print(f"    é€‚åº”å: {norm_kl_after:.6f}")
                    print(f"    æ”¹è¿›: {norm_kl_before - norm_kl_after:.6f}")
                else:
                    distances['normalized_kl_divergence_after'] = norm_kl_before
                    distances['normalized_kl_divergence_improvement'] = 0.0
            except Exception as e:
                print(f"  âš ï¸ æ ‡å‡†åŒ–KLæ•£åº¦è®¡ç®—å¤±è´¥: {e}")
        
        else:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨åŸæœ‰çš„æŒ‡æ ‡å’Œæ–°å¢çš„æ ‡å‡†åŒ–æŒ‡æ ‡
            print(f"  ğŸ“Š ä½¿ç”¨å¤‡ç”¨æŒ‡æ ‡è®¡ç®—åŸŸè·ç¦»...")
            
            # 1. æ ‡å‡†åŒ–KLæ•£åº¦è®¡ç®— - ä»¿ç…§ADAPTåº“å®ç°
            try:
                norm_kl_before = self._calculate_normalized_kl_divergence(X_source, X_target)
                distances['normalized_kl_divergence_before'] = norm_kl_before
                
                if uda_method is not None:
                    norm_kl_after = self._calculate_normalized_kl_divergence(X_source_adapted, X_target_adapted)
                    distances['normalized_kl_divergence_after'] = norm_kl_after
                    distances['normalized_kl_divergence_improvement'] = norm_kl_before - norm_kl_after
                    
                    print(f"  ğŸ“Š æ ‡å‡†åŒ–KLæ•£åº¦è®¡ç®—:")
                    print(f"    é€‚åº”å‰: {norm_kl_before:.6f}")
                    print(f"    é€‚åº”å: {norm_kl_after:.6f}")
                    print(f"    æ”¹è¿›: {norm_kl_before - norm_kl_after:.6f}")
                else:
                    distances['normalized_kl_divergence_after'] = norm_kl_before
                    distances['normalized_kl_divergence_improvement'] = 0.0
            except Exception as e:
                print(f"  âš ï¸ æ ‡å‡†åŒ–KLæ•£åº¦è®¡ç®—å¤±è´¥: {e}")
            
            # 2. æ ‡å‡†åŒ–Wassersteinè·ç¦»è®¡ç®— - ä»¿ç…§ADAPTåº“å®ç°
            try:
                norm_ws_before = self._calculate_normalized_wasserstein_distance(X_source, X_target)
                distances['normalized_wasserstein_before'] = norm_ws_before
                
                if uda_method is not None:
                    norm_ws_after = self._calculate_normalized_wasserstein_distance(X_source_adapted, X_target_adapted)
                    distances['normalized_wasserstein_after'] = norm_ws_after
                    distances['normalized_wasserstein_improvement'] = norm_ws_before - norm_ws_after
                    
                    print(f"  ğŸ“Š æ ‡å‡†åŒ–Wassersteinè·ç¦»è®¡ç®—:")
                    print(f"    é€‚åº”å‰: {norm_ws_before:.6f}")
                    print(f"    é€‚åº”å: {norm_ws_after:.6f}")
                    print(f"    æ”¹è¿›: {norm_ws_before - norm_ws_after:.6f}")
                else:
                    distances['normalized_wasserstein_after'] = norm_ws_before
                    distances['normalized_wasserstein_improvement'] = 0.0
            except Exception as e:
                print(f"  âš ï¸ æ ‡å‡†åŒ–Wassersteinè·ç¦»è®¡ç®—å¤±è´¥: {e}")
            
            # 3. åŸå§‹KLæ•£åº¦è®¡ç®— - ä½¿ç”¨analytical_CORALçš„å®ç°
            try:
                kl_before, kl_per_feature_before = self._calculate_kl_divergence_improved(X_source, X_target)
                distances['kl_divergence_before'] = kl_before
                
                if uda_method is not None:
                    kl_after, kl_per_feature_after = self._calculate_kl_divergence_improved(X_source_adapted, X_target_adapted)
                    distances['kl_divergence_after'] = kl_after
                    distances['kl_divergence_improvement'] = kl_before - kl_after
                    
                    print(f"  ğŸ“Š åŸå§‹KLæ•£åº¦è®¡ç®—:")
                    print(f"    é€‚åº”å‰: {kl_before:.6f}")
                    print(f"    é€‚åº”å: {kl_after:.6f}")
                    print(f"    æ”¹è¿›: {kl_before - kl_after:.6f}")
                else:
                    distances['kl_divergence_after'] = kl_before
                    distances['kl_divergence_improvement'] = 0.0
            except Exception as e:
                print(f"  âš ï¸ åŸå§‹KLæ•£åº¦è®¡ç®—å¤±è´¥: {e}")
        
            # 4. åŸå§‹Wassersteinè·ç¦»è®¡ç®— - ä½¿ç”¨analytical_CORALçš„å®ç°
            try:
                ws_before, ws_per_feature_before = self._calculate_wasserstein_distance_improved(X_source, X_target)
                distances['wasserstein_before'] = ws_before
                
                if uda_method is not None:
                    ws_after, ws_per_feature_after = self._calculate_wasserstein_distance_improved(X_source_adapted, X_target_adapted)
                    distances['wasserstein_after'] = ws_after
                    distances['wasserstein_improvement'] = ws_before - ws_after
                    
                    print(f"  ğŸ“Š åŸå§‹Wassersteinè·ç¦»è®¡ç®—:")
                    print(f"    é€‚åº”å‰: {ws_before:.6f}")
                    print(f"    é€‚åº”å: {ws_after:.6f}")
                    print(f"    æ”¹è¿›: {ws_before - ws_after:.6f}")
                else:
                    distances['wasserstein_after'] = ws_before
                    distances['wasserstein_improvement'] = 0.0
            except Exception as e:
                print(f"  âš ï¸ åŸå§‹Wassersteinè·ç¦»è®¡ç®—å¤±è´¥: {e}")
        
            # 5. MMDè®¡ç®— - ä½¿ç”¨analytical_CORALçš„å®ç°
            try:
                mmd_before = self._calculate_mmd_improved(X_source, X_target)
                distances['mmd_before'] = mmd_before
                
                if uda_method is not None:
                    mmd_after = self._calculate_mmd_improved(X_source_adapted, X_target_adapted)
                    distances['mmd_after'] = mmd_after
                    distances['mmd_improvement'] = mmd_before - mmd_after
                    
                    print(f"  ğŸ“Š MMDè®¡ç®—:")
                    print(f"    é€‚åº”å‰: {mmd_before:.6f}")
                    print(f"    é€‚åº”å: {mmd_after:.6f}")
                    print(f"    æ”¹è¿›: {mmd_before - mmd_after:.6f}")
                else:
                    distances['mmd_after'] = mmd_before
                    distances['mmd_improvement'] = 0.0
            except Exception as e:
                print(f"  âš ï¸ MMDè®¡ç®—å¤±è´¥: {e}")
        
        # å¯è§†åŒ–è·ç¦»åº¦é‡
        self._plot_distance_metrics(distances, method_name)
        
        return distances
    
    def _get_adapted_features(self, 
                            X_source: np.ndarray, 
                            X_target: np.ndarray,
                            uda_method: Optional[AdaptUDAMethod] = None,
                            method_name: str = "UDA") -> Tuple[np.ndarray, np.ndarray]:
        """è·å–åŸŸé€‚åº”åçš„ç‰¹å¾ - æ”¹è¿›ç‰ˆæœ¬ï¼Œæ­£ç¡®å¤„ç†ä¸åŒUDAæ–¹æ³•çš„ç‰¹å¾å˜æ¢"""
        
        if uda_method is None:
            return X_source, X_target
        
        X_source_adapted = X_source.copy()
        X_target_adapted = X_target.copy()
        
        # è°ƒè¯•ä¿¡æ¯ï¼šè®°å½•åŸå§‹ç‰¹å¾
        print(f"  ğŸ” åŸå§‹ç‰¹å¾ç»Ÿè®¡:")
        print(f"    æºåŸŸå‡å€¼: {np.mean(X_source, axis=0)[:3]} ...")
        print(f"    ç›®æ ‡åŸŸå‡å€¼: {np.mean(X_target, axis=0)[:3]} ...")
        
        try:
            # æµ‹è¯•é¢„æµ‹åŠŸèƒ½
            try:
                test_pred = uda_method.predict(X_target[:5])
                print(f"  âœ“ UDAæ–¹æ³•é¢„æµ‹åŠŸèƒ½æ­£å¸¸ï¼Œé¢„æµ‹ç»“æœ: {test_pred}")
            except Exception as e:
                print(f"  âš  UDAæ–¹æ³•é¢„æµ‹åŠŸèƒ½å¼‚å¸¸: {e}")
            
            # è·å–UDAæ–¹æ³•çš„å†…éƒ¨æ¨¡å‹
            adapt_model = uda_method.adapt_model
            print(f"  ğŸ“‹ å†…éƒ¨æ¨¡å‹ç±»å‹: {type(adapt_model).__name__}")
            print(f"  ğŸ“‹ å¯ç”¨å±æ€§: {[attr for attr in dir(adapt_model) if not attr.startswith('_')][:10]}...")
            
            # æ”¹è¿›çš„ç‰¹å¾å˜æ¢è·å–æ–¹æ³•
            transform_success = False
            
            # ç‰¹æ®Šå¤„ç†ï¼šå¯¹äºä¸åŒç±»å‹çš„UDAæ–¹æ³•ä½¿ç”¨ä¸åŒç­–ç•¥
            if method_name in ['TCA', 'SA', 'FMMD', 'PRED']:
                # è¿™äº›æ–¹æ³•å¯èƒ½æ”¹å˜ç‰¹å¾ç»´åº¦ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                print(f"  ğŸ“ {method_name}æ–¹æ³•å¯èƒ½æ”¹å˜ç‰¹å¾ç»´åº¦ï¼Œä½¿ç”¨ç‰¹æ®Šå¤„ç†")
                
                # æ–¹æ³•1: å°è¯•è·å–å˜æ¢åçš„ç‰¹å¾ï¼ˆç”¨äºé™ç»´å¯è§†åŒ–ï¼‰
                if hasattr(adapt_model, 'transform'):
                    try:
                        if method_name == 'SA':
                            # SAæ–¹æ³•éœ€è¦domainå‚æ•°
                            X_source_transformed = adapt_model.transform(X_source, domain="src")
                            X_target_transformed = adapt_model.transform(X_target, domain="tgt")
                        else:
                            # å…¶ä»–æ–¹æ³•
                            X_source_transformed = adapt_model.transform(X_source)
                            X_target_transformed = adapt_model.transform(X_target)
                        
                        print(f"  âœ“ transformæˆåŠŸ: {X_source.shape} -> {X_source_transformed.shape}")
                        
                        # æ£€æŸ¥ç»´åº¦æ˜¯å¦æ”¹å˜
                        if X_source_transformed.shape[1] != X_source.shape[1]:
                            print(f"  âš  ç‰¹å¾ç»´åº¦æ”¹å˜: {X_source.shape[1]} -> {X_source_transformed.shape[1]}")
                            print(f"  ğŸ“ ä½¿ç”¨å˜æ¢åçš„é«˜ç»´ç‰¹å¾è¿›è¡Œè·ç¦»åº¦é‡è®¡ç®—")
                            # ä½¿ç”¨å˜æ¢åçš„ç‰¹å¾è¿›è¡Œè·ç¦»åº¦é‡
                            # è¿™æ ·å¯ä»¥çœŸæ­£åæ˜ åŸŸé€‚åº”çš„æ•ˆæœ
                            X_source_adapted = X_source_transformed
                            X_target_adapted = X_target_transformed
                        else:
                            # ç»´åº¦æœªæ”¹å˜ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨å˜æ¢åçš„ç‰¹å¾
                            X_source_adapted = X_source_transformed
                            X_target_adapted = X_target_transformed
                        
                        transform_success = True
                        
                    except Exception as e:
                        print(f"  âš  transformå¤±è´¥: {e}")
                
                # æ–¹æ³•2: å¦‚æœtransformå¤±è´¥ï¼Œå°è¯•è·å–å˜æ¢çŸ©é˜µ
                if not transform_success and hasattr(adapt_model, 'A_'):
                    try:
                        A = adapt_model.A_
                        print(f"  ğŸ” å˜æ¢çŸ©é˜µA_å½¢çŠ¶: {A.shape}")
                        
                        # æ£€æŸ¥çŸ©é˜µç»´åº¦æ˜¯å¦åŒ¹é…
                        if A.shape[0] == X_source.shape[1]:
                            X_source_adapted = X_source @ A
                            X_target_adapted = X_target @ A
                            transform_success = True
                            print(f"  âœ“ ä½¿ç”¨å˜æ¢çŸ©é˜µA_æˆåŠŸ: {A.shape}")
                        else:
                            print(f"  âš  å˜æ¢çŸ©é˜µç»´åº¦ä¸åŒ¹é…: {A.shape[0]} != {X_source.shape[1]}")
                    except Exception as e:
                        print(f"  âš  å˜æ¢çŸ©é˜µA_å¤±è´¥: {e}")
                    
            elif method_name == 'CORAL':
                # CORALæ–¹æ³•ï¼šåæ–¹å·®å¯¹é½ï¼Œç»´åº¦ä¸å˜
                try:
                    X_source_adapted, X_target_adapted = self._manual_coral_alignment(X_source, X_target)
                    transform_success = True
                    print(f"  âœ“ CORALå¯¹é½æˆåŠŸ")
                except Exception as e:
                    print(f"  âš  CORALå¯¹é½å¤±è´¥: {e}")
            
            elif method_name in ['KMM', 'KLIEP', 'LDM', 'ULSIF', 'RULSIF', 'NNW', 'IWC', 'IWN']:
                # å®ä¾‹é‡åŠ æƒæ–¹æ³•ï¼šä¸æ”¹å˜ç‰¹å¾ï¼Œåªæ”¹å˜æ ·æœ¬æƒé‡
                print(f"  ğŸ“ {method_name}ä¸ºå®ä¾‹é‡åŠ æƒæ–¹æ³•ï¼Œä¸æ”¹å˜ç‰¹å¾ç©ºé—´")
                # å¯¹äºå®ä¾‹é‡åŠ æƒæ–¹æ³•ï¼Œæˆ‘ä»¬ä½¿ç”¨åŸå§‹ç‰¹å¾
                # è¿™äº›æ–¹æ³•çš„"é€‚åº”"ä½“ç°åœ¨æ¨¡å‹æƒé‡ä¸Šï¼Œè€Œä¸æ˜¯ç‰¹å¾å˜æ¢ä¸Š
                X_source_adapted = X_source
                X_target_adapted = X_target
                transform_success = True
            
            else:
                # å…¶ä»–æ–¹æ³•ï¼šå°è¯•é€šç”¨çš„transformæ–¹æ³•
                if hasattr(adapt_model, 'transform'):
                    try:
                        X_source_adapted = adapt_model.transform(X_source)
                        X_target_adapted = adapt_model.transform(X_target)
                        transform_success = True
                        print(f"  âœ“ é€šç”¨transformæˆåŠŸ: {X_source.shape} -> {X_source_adapted.shape}")
                    except Exception as e:
                        print(f"  âš  é€šç”¨transformå¤±è´¥: {e}")
            
            # æ£€æŸ¥å˜æ¢æ˜¯å¦æœ‰æ•ˆ
            if transform_success:
                # æ£€æŸ¥ç»´åº¦æ˜¯å¦åŒ¹é…ï¼Œåªæœ‰åœ¨ç»´åº¦ç›¸åŒæ—¶æ‰è®¡ç®—ç‰¹å¾å˜åŒ–
                if X_source.shape[1] == X_source_adapted.shape[1] and X_target.shape[1] == X_target_adapted.shape[1]:
                    source_diff = np.mean(np.abs(X_source - X_source_adapted))
                    target_diff = np.mean(np.abs(X_target - X_target_adapted))
                    print(f"    æºåŸŸç‰¹å¾å¹³å‡å˜åŒ–: {source_diff:.6f}")
                    print(f"    ç›®æ ‡åŸŸç‰¹å¾å¹³å‡å˜åŒ–: {target_diff:.6f}")
                    
                    if source_diff < 1e-10 and target_diff < 1e-10:
                        print(f"  âš  è­¦å‘Š: ç‰¹å¾å˜åŒ–æå°ï¼Œå¯èƒ½æ²¡æœ‰çœŸæ­£è¿›è¡ŒåŸŸé€‚åº”")
                else:
                    # ç»´åº¦ä¸åŒ¹é…çš„æƒ…å†µ
                    print(f"    æºåŸŸç‰¹å¾ç»´åº¦å˜åŒ–: {X_source.shape[1]} -> {X_source_adapted.shape[1]}")
                    print(f"    ç›®æ ‡åŸŸç‰¹å¾ç»´åº¦å˜åŒ–: {X_target.shape[1]} -> {X_target_adapted.shape[1]}")
                
                # éªŒè¯ç‰¹å¾ç»´åº¦ä¸€è‡´æ€§
                if X_source_adapted.shape[1] != X_target_adapted.shape[1]:
                    print(f"  âš  è­¦å‘Š: æºåŸŸå’Œç›®æ ‡åŸŸé€‚åº”åç‰¹å¾ç»´åº¦ä¸ä¸€è‡´")
                    print(f"    æºåŸŸ: {X_source_adapted.shape}, ç›®æ ‡åŸŸ: {X_target_adapted.shape}")
                    # å›é€€åˆ°åŸå§‹ç‰¹å¾
                    X_source_adapted = X_source
                    X_target_adapted = X_target
                    print(f"  ğŸ“ å›é€€åˆ°åŸå§‹ç‰¹å¾è¿›è¡Œè·ç¦»åº¦é‡è®¡ç®—")
                
                # æ˜¾ç¤ºé€‚åº”åç‰¹å¾ç»Ÿè®¡
                print(f"    é€‚åº”åæºåŸŸå‡å€¼: {np.mean(X_source_adapted, axis=0)[:3]} ...")
                print(f"    é€‚åº”åç›®æ ‡åŸŸå‡å€¼: {np.mean(X_target_adapted, axis=0)[:3]} ...")
            else:
                print(f"  âš  æœªçŸ¥çš„UDAæ–¹æ³•ç±»å‹æˆ–å˜æ¢å¤±è´¥: {method_name}")
        
        except Exception as e:
            print(f"  âš  è·å–é€‚åº”åç‰¹å¾å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        return X_source_adapted, X_target_adapted
    
    def _manual_coral_alignment(self, X_source: np.ndarray, X_target: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """æ‰‹åŠ¨å®ç°CORALåæ–¹å·®å¯¹é½"""
        # è®¡ç®—åæ–¹å·®çŸ©é˜µ
        cov_src = np.cov(X_source.T)
        cov_tar = np.cov(X_target.T)
        
        # è®¡ç®—å˜æ¢çŸ©é˜µ (ç™½åŒ– + ç€è‰²)
        U_src, S_src, Vt_src = np.linalg.svd(cov_src)
        U_tar, S_tar, Vt_tar = np.linalg.svd(cov_tar)
        
        # é¿å…å¥‡å¼‚å€¼è¿‡å°
        S_src = np.maximum(S_src, 1e-8)
        S_tar = np.maximum(S_tar, 1e-8)
        
        # ç™½åŒ–çŸ©é˜µå’Œç€è‰²çŸ©é˜µ
        whiten = U_src @ np.diag(1.0 / np.sqrt(S_src)) @ Vt_src
        color = U_tar @ np.diag(np.sqrt(S_tar)) @ Vt_tar
        
        # åº”ç”¨å˜æ¢
        X_source_mean = np.mean(X_source, axis=0)
        X_target_mean = np.mean(X_target, axis=0)
        
        X_source_centered = X_source - X_source_mean
        
        # CORALå˜æ¢ï¼šæºåŸŸ -> ç™½åŒ– -> ç›®æ ‡åŸŸç€è‰²
        X_source_adapted = (X_source_centered @ whiten @ color) + X_target_mean
        X_target_adapted = X_target  # ç›®æ ‡åŸŸä¿æŒä¸å˜
        
        return X_source_adapted, X_target_adapted
    
    def _calculate_kl_divergence_improved(self, X1: np.ndarray, X2: np.ndarray, bins: int = 20, epsilon: float = 1e-10) -> Tuple[float, Dict[str, float]]:
        """æ”¹è¿›çš„KLæ•£åº¦è®¡ç®— - å‚è€ƒanalytical_CORALå®ç°"""
        n_features = X1.shape[1]
        kl_per_feature = {}
        
        for i in range(n_features):
            x_s = X1[:, i]
            x_t = X2[:, i]
            
            # ä½¿ç”¨ç»Ÿä¸€çš„binèŒƒå›´
            min_val = min(np.min(x_s), np.min(x_t))
            max_val = max(np.max(x_s), np.max(x_t))
            bin_range = (min_val, max_val)
            
            # è®¡ç®—ç›´æ–¹å›¾
            hist_s, _ = np.histogram(x_s, bins=bins, range=bin_range, density=True)
            hist_t, _ = np.histogram(x_t, bins=bins, range=bin_range, density=True)
            
            # é¿å…é›¶å€¼å¹¶å½’ä¸€åŒ–
            hist_s = hist_s + epsilon
            hist_t = hist_t + epsilon
            hist_s = hist_s / np.sum(hist_s)
            hist_t = hist_t / np.sum(hist_t)
            
            # è®¡ç®—å¯¹ç§°KLæ•£åº¦
            kl_s_t = entropy(hist_s, hist_t)
            kl_t_s = entropy(hist_t, hist_s)
            kl_per_feature[f'feature_{i}'] = (kl_s_t + kl_t_s) / 2
        
        return float(np.mean(list(kl_per_feature.values()))), kl_per_feature
    
    def _calculate_wasserstein_distance_improved(self, X1: np.ndarray, X2: np.ndarray) -> Tuple[float, Dict[str, float]]:
        """æ”¹è¿›çš„Wassersteinè·ç¦»è®¡ç®— - å‚è€ƒanalytical_CORALå®ç°"""
        n_features = X1.shape[1]
        wasserstein_per_feature = {}
        
        for i in range(n_features):
            x_s = X1[:, i]
            x_t = X2[:, i]
            ws_dist = wasserstein_distance(x_s, x_t)
            wasserstein_per_feature[f'feature_{i}'] = ws_dist
        
        return float(np.mean(list(wasserstein_per_feature.values()))), wasserstein_per_feature
    
    def _calculate_normalized_wasserstein_distance(self, X1: np.ndarray, X2: np.ndarray) -> float:
        """æ ‡å‡†åŒ–Wassersteinè·ç¦»è®¡ç®— - ä»¿ç…§ADAPTåº“çš„normalized_frechet_distanceå®ç°"""
        
        # è®¡ç®—ç¼©æ”¾å› å­å’Œä¸­å¿ƒç‚¹ (å‚è€ƒADAPTåº“çš„å®ç°)
        std_factor = (np.std(X1, axis=0) + np.std(X2, axis=0)) / 2
        mean_center = (np.mean(X1, axis=0) + np.mean(X2, axis=0)) / 2
        
        # é¿å…é›¶æ ‡å‡†å·®
        std_factor = np.where(std_factor == 0, 1, std_factor)
        
        # æ ‡å‡†åŒ–æ•°æ®
        X1_normalized = (X1 - mean_center) / std_factor
        X2_normalized = (X2 - mean_center) / std_factor
        
        # è®¡ç®—Wassersteinè·ç¦»
        n_features = X1_normalized.shape[1]
        wasserstein_sum = 0
        
        for i in range(n_features):
            x_s = X1_normalized[:, i]
            x_t = X2_normalized[:, i]
            ws_dist = wasserstein_distance(x_s, x_t)
            wasserstein_sum += ws_dist
        
        # é™¤ä»¥ç‰¹å¾æ•°é‡è¿›è¡Œå½’ä¸€åŒ–
        return float(wasserstein_sum / n_features)
    
    def _calculate_normalized_kl_divergence(self, X1: np.ndarray, X2: np.ndarray, bins: int = 20, epsilon: float = 1e-10) -> float:
        """æ ‡å‡†åŒ–KLæ•£åº¦è®¡ç®— - ä»¿ç…§ADAPTåº“çš„æ ‡å‡†åŒ–æ–¹æ³•"""
        
        # è®¡ç®—ç¼©æ”¾å› å­å’Œä¸­å¿ƒç‚¹
        std_factor = (np.std(X1, axis=0) + np.std(X2, axis=0)) / 2
        mean_center = (np.mean(X1, axis=0) + np.mean(X2, axis=0)) / 2
        
        # é¿å…é›¶æ ‡å‡†å·®
        std_factor = np.where(std_factor == 0, 1, std_factor)
        
        # æ ‡å‡†åŒ–æ•°æ®
        X1_normalized = (X1 - mean_center) / std_factor
        X2_normalized = (X2 - mean_center) / std_factor
        
        # è®¡ç®—KLæ•£åº¦
        n_features = X1_normalized.shape[1]
        kl_sum = 0
        
        for i in range(n_features):
            x_s = X1_normalized[:, i]
            x_t = X2_normalized[:, i]
            
            # ä½¿ç”¨ç»Ÿä¸€çš„binèŒƒå›´
            min_val = min(np.min(x_s), np.min(x_t))
            max_val = max(np.max(x_s), np.max(x_t))
            bin_range = (min_val, max_val)
            
            # è®¡ç®—ç›´æ–¹å›¾
            hist_s, _ = np.histogram(x_s, bins=bins, range=bin_range, density=True)
            hist_t, _ = np.histogram(x_t, bins=bins, range=bin_range, density=True)
            
            # é¿å…é›¶å€¼å¹¶å½’ä¸€åŒ–
            hist_s = hist_s + epsilon
            hist_t = hist_t + epsilon
            hist_s = hist_s / np.sum(hist_s)
            hist_t = hist_t / np.sum(hist_t)
            
            # è®¡ç®—å¯¹ç§°KLæ•£åº¦
            kl_s_t = entropy(hist_s, hist_t)
            kl_t_s = entropy(hist_t, hist_s)
            kl_sum += (kl_s_t + kl_t_s) / 2
        
        # é™¤ä»¥ç‰¹å¾æ•°é‡è¿›è¡Œå½’ä¸€åŒ–
        return float(kl_sum / n_features)
    
    def _calculate_mmd_improved(self, X1: np.ndarray, X2: np.ndarray, gamma: float = 1.0) -> float:
        """æ”¹è¿›çš„MMDè®¡ç®— - å‚è€ƒanalytical_CORALå®ç°"""
        from sklearn.metrics.pairwise import rbf_kernel
        
        n_x = X1.shape[0]
        n_y = X2.shape[0]
        
        # é™åˆ¶æ ·æœ¬æ•°é‡ä»¥æé«˜è®¡ç®—æ•ˆç‡
        max_samples = 200
        if n_x > max_samples:
            idx1 = np.random.choice(n_x, max_samples, replace=False)
            X1 = X1[idx1]
            n_x = max_samples
        if n_y > max_samples:
            idx2 = np.random.choice(n_y, max_samples, replace=False)
            X2 = X2[idx2]
            n_y = max_samples
        
        # è®¡ç®—æ ¸çŸ©é˜µ
        K_xx = rbf_kernel(X1, X1, gamma=gamma)
        K_yy = rbf_kernel(X2, X2, gamma=gamma)
        K_xy = rbf_kernel(X1, X2, gamma=gamma)
        
        # è®¡ç®—MMDÂ²
        mmd_squared = (np.sum(K_xx) - np.trace(K_xx)) / (n_x * (n_x - 1))
        mmd_squared += (np.sum(K_yy) - np.trace(K_yy)) / (n_y * (n_y - 1))
        mmd_squared -= 2 * np.mean(K_xy)
        
        return float(np.sqrt(max(mmd_squared, 0)))
    
    def _plot_distance_metrics(self, distances: Dict[str, float], method_name: str) -> None:
        """å¯è§†åŒ–è·ç¦»åº¦é‡"""
        
        # åªæ˜¾ç¤ºæ ‡å‡†åŒ–æŒ‡æ ‡ï¼ˆæ›´ç¨³å®šå’Œå¯æ¯”è¾ƒï¼‰
        available_metrics = []
        metric_labels = []
        
        # æ£€æŸ¥æ ‡å‡†åŒ–æŒ‡æ ‡æ˜¯å¦å¯ç”¨
        if 'normalized_linear_discrepancy_before' in distances:
            available_metrics.append('normalized_linear_discrepancy')
            metric_labels.append('Normalized Linear Discrepancy')
        if 'normalized_frechet_distance_before' in distances:
            available_metrics.append('normalized_frechet_distance')
            metric_labels.append('Normalized Frechet Distance')
        if 'normalized_wasserstein_before' in distances:
            available_metrics.append('normalized_wasserstein')
            metric_labels.append('Normalized Wasserstein Distance')
        if 'normalized_kl_divergence_before' in distances:
            available_metrics.append('normalized_kl_divergence')
            metric_labels.append('Normalized KL Divergence')
        
        if not available_metrics:
            print("  âš ï¸ æ²¡æœ‰å¯ç”¨çš„è·ç¦»æŒ‡æ ‡è¿›è¡Œå¯è§†åŒ–")
            return
        
        # æå–æ•°å€¼
        before_values = []
        after_values = []
        improvements = []
        
        for metric in available_metrics:
            if f'{metric}_before' in distances:
                before_values.append(distances[f'{metric}_before'])
                after_values.append(distances[f'{metric}_after'])
                improvements.append(distances[f'{metric}_improvement'])
        
        if not before_values:
            print("  âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„è·ç¦»åº¦é‡æ•°æ®è¿›è¡Œå¯è§†åŒ–")
            return
        
        # è°ƒæ•´å›¾è¡¨å¤§å°ä»¥é€‚åº”æ›´å¤šæŒ‡æ ‡
        n_metrics = len(available_metrics)
        if n_metrics <= 3:
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        else:
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 12))
        
        fig.suptitle(f'{method_name} - Domain Distance Metrics', fontsize=16, fontweight='bold')
        
        # è·ç¦»å¯¹æ¯”
        x = np.arange(len(available_metrics))
        width = 0.35
        
        ax1.bar(x - width/2, before_values, width, label='Before DA', color=self.colors['target'], alpha=0.8)
        ax1.bar(x + width/2, after_values, width, label='After DA', color=self.colors['adapted'], alpha=0.8)
        
        ax1.set_xlabel('Distance Metrics')
        ax1.set_ylabel('Distance Value')
        ax1.set_title('Domain Distance Comparison')
        ax1.set_xticks(x)
        ax1.set_xticklabels(metric_labels, rotation=45 if n_metrics > 3 else 0, ha='right' if n_metrics > 3 else 'center')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # æ”¹è¿›ç¨‹åº¦
        colors = ['green' if imp > 0 else 'red' for imp in improvements]
        bars = ax2.bar(available_metrics, improvements, color=colors, alpha=0.7)
        ax2.set_xlabel('Distance Metrics')
        ax2.set_ylabel('Improvement (Before - After)')
        ax2.set_title('Domain Distance Improvement')
        ax2.set_xticklabels(metric_labels, rotation=45 if n_metrics > 3 else 0, ha='right' if n_metrics > 3 else 'center')
        ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        ax2.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, imp in zip(bars, improvements):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height,
                    f'{imp:.3f}', ha='center', va='bottom' if height > 0 else 'top', fontsize=8)
        
        plt.tight_layout()
        
        if self.save_plots:
            save_path = self.output_dir / f"{method_name}_distance_metrics.png"
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"  è·ç¦»åº¦é‡å›¾å·²ä¿å­˜: {save_path}")
        
        plt.show()
    
    def plot_performance_comparison(self, 
                                  X_source: np.ndarray, 
                                  y_source: np.ndarray,
                                  X_target: np.ndarray, 
                                  y_target: np.ndarray,
                                  uda_method: AdaptUDAMethod,
                                  method_name: str = "UDA") -> Dict[str, Any]:
        """æ€§èƒ½å¯¹æ¯”å¯è§†åŒ–"""
        
        from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score
        from sklearn.linear_model import LogisticRegression
        
        # åŸºçº¿æ¨¡å‹ï¼ˆæ— åŸŸé€‚åº”ï¼‰
        baseline = LogisticRegression(penalty=None, random_state=42, max_iter=1000)
        baseline.fit(X_source, y_source)
        
        # é¢„æµ‹
        y_pred_baseline = baseline.predict(X_target)
        y_pred_uda = uda_method.predict(X_target)
        
        try:
            y_proba_baseline = baseline.predict_proba(X_target)[:, 1]
        except:
            y_proba_baseline = None
            
        try:
            y_proba_uda = uda_method.predict_proba(X_target)
            if y_proba_uda is not None and len(y_proba_uda.shape) > 1:
                y_proba_uda = y_proba_uda[:, 1]
        except:
            y_proba_uda = None
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = ['Accuracy', 'F1', 'Precision', 'Recall']
        baseline_scores = [
            accuracy_score(y_target, y_pred_baseline),
            f1_score(y_target, y_pred_baseline, average='binary'),
            precision_score(y_target, y_pred_baseline, average='binary'),
            recall_score(y_target, y_pred_baseline, average='binary')
        ]
        
        uda_scores = [
            accuracy_score(y_target, y_pred_uda),
            f1_score(y_target, y_pred_uda, average='binary'),
            precision_score(y_target, y_pred_uda, average='binary'),
            recall_score(y_target, y_pred_uda, average='binary')
        ]
        
        # æ·»åŠ AUCï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if y_proba_baseline is not None and y_proba_uda is not None:
            metrics.append('AUC')
            baseline_scores.append(roc_auc_score(y_target, y_proba_baseline))
            uda_scores.append(roc_auc_score(y_target, y_proba_uda))
        
        # å¯è§†åŒ–
        fig, ax = plt.subplots(1, 1, figsize=(12, 8))
        
        x = np.arange(len(metrics))
        width = 0.35
        
        bars1 = ax.bar(x - width/2, baseline_scores, width, 
                      label='Baseline (No DA)', color=self.colors['target'], alpha=0.8)
        bars2 = ax.bar(x + width/2, uda_scores, width, 
                      label=f'{method_name}', color=self.colors['adapted'], alpha=0.8)
        
        ax.set_xlabel('Metrics')
        ax.set_ylabel('Score')
        ax.set_title(f'Performance Comparison: {method_name} vs Baseline')
        ax.set_xticks(x)
        ax.set_xticklabels(metrics)
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, 1)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                       f'{height:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        
        if self.save_plots:
            save_path = self.output_dir / f"{method_name}_performance_comparison.png"
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"  æ€§èƒ½å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")
        
        plt.show()
        
        return {
            'baseline_scores': dict(zip(metrics, baseline_scores)),
            'uda_scores': dict(zip(metrics, uda_scores)),
            'improvements': {metric: uda - baseline for metric, uda, baseline 
                           in zip(metrics, uda_scores, baseline_scores)}
        }


def create_uda_visualizer(figsize: Tuple[int, int] = (12, 8),
                         save_plots: bool = True,
                         output_dir: str = "results/uda_visualization") -> UDAVisualizer:
    """ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºUDAå¯è§†åŒ–å™¨"""
    return UDAVisualizer(figsize=figsize, save_plots=save_plots, output_dir=output_dir)


if __name__ == "__main__":
    # ä½¿ç”¨ç¤ºä¾‹
    print("UDAå¯è§†åŒ–å™¨ä½¿ç”¨ç¤ºä¾‹:")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    X_source = np.random.normal(0, 1, (200, 8))
    y_source = np.random.choice([0, 1], 200, p=[0.6, 0.4])
    X_target = np.random.normal(0.5, 1.2, (150, 8))
    y_target = np.random.choice([0, 1], 150, p=[0.4, 0.6])
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = create_uda_visualizer()
    
    # ç”Ÿæˆå¯è§†åŒ–ï¼ˆæ— åŸŸé€‚åº”ï¼‰
    results = visualizer.visualize_domain_adaptation_complete(
        X_source, y_source, X_target, y_target,
        uda_method=None, method_name="No_DA"
    )
    
    print("âœ“ å¯è§†åŒ–ç¤ºä¾‹å®Œæˆ") 