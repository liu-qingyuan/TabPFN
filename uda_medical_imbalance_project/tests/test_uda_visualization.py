#!/usr/bin/env python3
"""
UDAå¯è§†åŒ–åŠŸèƒ½æµ‹è¯•

æµ‹è¯•UDAå¯è§†åŒ–å™¨çš„å„ä¸ªåŠŸèƒ½ï¼š
1. é™ç»´å¯è§†åŒ– (PCA, t-SNE)
2. ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”
3. åŸŸè·ç¦»åº¦é‡
4. æ€§èƒ½å¯¹æ¯”

è¿è¡Œæµ‹è¯•: python tests/test_uda_visualization.py
"""

import sys
import os
from pathlib import Path
import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def test_visualizer_basic_functionality():
    """æµ‹è¯•å¯è§†åŒ–å™¨åŸºæœ¬åŠŸèƒ½"""
    print("=== æµ‹è¯•UDAå¯è§†åŒ–å™¨åŸºæœ¬åŠŸèƒ½ ===")
    
    try:
        from preprocessing.uda_visualizer import create_uda_visualizer
        
        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = create_uda_visualizer(
            figsize=(10, 8),
            save_plots=False,  # æµ‹è¯•æ—¶ä¸ä¿å­˜å›¾ç‰‡
            output_dir="tests/temp_viz"
        )
        
        print("âœ“ å¯è§†åŒ–å™¨åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        np.random.seed(42)
        X_source = np.random.normal(0, 1, (100, 6))
        y_source = np.random.choice([0, 1], 100, p=[0.6, 0.4])
        X_target = np.random.normal(0.5, 1.2, (80, 6))
        y_target = np.random.choice([0, 1], 80, p=[0.4, 0.6])
        
        print("âœ“ æ¨¡æ‹Ÿæ•°æ®åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•é™ç»´å¯è§†åŒ–
        print("\n1. æµ‹è¯•é™ç»´å¯è§†åŒ–...")
        dim_results = visualizer.plot_dimensionality_reduction(
            X_source, y_source, X_target, y_target,
            uda_method=None, method_name="Test"
        )
        print("âœ“ é™ç»´å¯è§†åŒ–æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•ç‰¹å¾åˆ†å¸ƒ
        print("\n2. æµ‹è¯•ç‰¹å¾åˆ†å¸ƒ...")
        dist_results = visualizer.plot_feature_distributions(
            X_source, X_target, uda_method=None, method_name="Test"
        )
        print("âœ“ ç‰¹å¾åˆ†å¸ƒæµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•åŸŸè·ç¦»åº¦é‡
        print("\n3. æµ‹è¯•åŸŸè·ç¦»åº¦é‡...")
        distance_results = visualizer.calculate_domain_distances(
            X_source, X_target, uda_method=None, method_name="Test"
        )
        
        # æ£€æŸ¥è·ç¦»åº¦é‡ç»“æœ
        expected_metrics = ['kl_divergence_before', 'wasserstein_before', 'mmd_before']
        for metric in expected_metrics:
            assert metric in distance_results, f"ç¼ºå°‘è·ç¦»åº¦é‡: {metric}"
            assert isinstance(distance_results[metric], (int, float)), f"{metric} ä¸æ˜¯æ•°å€¼ç±»å‹"
        
        print("âœ“ åŸŸè·ç¦»åº¦é‡æµ‹è¯•é€šè¿‡")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_visualizer_with_uda_method():
    """æµ‹è¯•å¸¦UDAæ–¹æ³•çš„å¯è§†åŒ–"""
    print("\n=== æµ‹è¯•å¸¦UDAæ–¹æ³•çš„å¯è§†åŒ– ===")
    
    try:
        from preprocessing.uda_processor import create_uda_processor
        from preprocessing.uda_visualizer import create_uda_visualizer
        from uda.adapt_methods import is_adapt_available
        from sklearn.linear_model import LogisticRegression
        
        if not is_adapt_available():
            print("âš  Adaptåº“ä¸å¯ç”¨ï¼Œè·³è¿‡UDAæ–¹æ³•æµ‹è¯•")
            return True
        
        # åˆ›å»ºæ•°æ®
        np.random.seed(42)
        X_source = np.random.normal(0, 1, (150, 6))
        y_source = np.random.choice([0, 1], 150, p=[0.6, 0.4])
        X_target = np.random.normal(0.8, 1.3, (100, 6))
        y_target = np.random.choice([0, 1], 100, p=[0.4, 0.6])
        
        # åˆ›å»ºUDAå¤„ç†å™¨
        processor = create_uda_processor(
            method_name='CORAL',  # ä½¿ç”¨CORALæ–¹æ³•ï¼Œç›¸å¯¹ç¨³å®š
            base_estimator=LogisticRegression(penalty=None, random_state=42, max_iter=1000),
            save_results=False
        )
        
        # æ‹ŸåˆUDAæ–¹æ³•
        uda_method, results = processor.fit_transform(
            X_source, y_source, X_target, y_target
        )
        
        print(f"âœ“ UDAæ–¹æ³•æ‹ŸåˆæˆåŠŸ: {processor.config.method_name}")
        
        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = create_uda_visualizer(
            figsize=(12, 9),
            save_plots=False,
            output_dir="tests/temp_viz"
        )
        
        # å®Œæ•´å¯è§†åŒ–åˆ†æ
        viz_results = visualizer.visualize_domain_adaptation_complete(
            X_source, y_source, X_target, y_target,
            uda_method=uda_method,
            method_name=processor.config.method_name
        )
        
        # æ£€æŸ¥ç»“æœ
        expected_keys = ['dimensionality_reduction', 'feature_distributions', 'domain_distances']
        for key in expected_keys:
            assert key in viz_results, f"ç¼ºå°‘å¯è§†åŒ–ç»“æœ: {key}"
        
        print("âœ“ å¸¦UDAæ–¹æ³•çš„å¯è§†åŒ–æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ UDAæ–¹æ³•å¯è§†åŒ–æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_distance_metrics():
    """æµ‹è¯•è·ç¦»åº¦é‡è®¡ç®—"""
    print("\n=== æµ‹è¯•è·ç¦»åº¦é‡è®¡ç®— ===")
    
    try:
        from preprocessing.uda_visualizer import UDAVisualizer
        
        visualizer = UDAVisualizer(save_plots=False)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        np.random.seed(42)
        X1 = np.random.normal(0, 1, (100, 4))
        X2 = np.random.normal(1, 1.5, (80, 4))
        
        # æµ‹è¯•KLæ•£åº¦
        kl_div = visualizer._calculate_kl_divergence(X1, X2)
        assert isinstance(kl_div, (int, float)), "KLæ•£åº¦åº”è¯¥æ˜¯æ•°å€¼"
        assert kl_div >= 0, "KLæ•£åº¦åº”è¯¥éè´Ÿ"
        print(f"âœ“ KLæ•£åº¦è®¡ç®—: {kl_div:.4f}")
        
        # æµ‹è¯•Wassersteinè·ç¦»
        ws_dist = visualizer._calculate_wasserstein_distance(X1, X2)
        assert isinstance(ws_dist, (int, float)), "Wassersteinè·ç¦»åº”è¯¥æ˜¯æ•°å€¼"
        assert ws_dist >= 0, "Wassersteinè·ç¦»åº”è¯¥éè´Ÿ"
        print(f"âœ“ Wassersteinè·ç¦»è®¡ç®—: {ws_dist:.4f}")
        
        # æµ‹è¯•MMD
        mmd = visualizer._calculate_mmd(X1, X2)
        assert isinstance(mmd, (int, float)), "MMDåº”è¯¥æ˜¯æ•°å€¼"
        assert mmd >= 0, "MMDåº”è¯¥éè´Ÿ"
        print(f"âœ“ MMDè®¡ç®—: {mmd:.4f}")
        
        print("âœ“ è·ç¦»åº¦é‡è®¡ç®—æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ è·ç¦»åº¦é‡æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_performance_comparison():
    """æµ‹è¯•æ€§èƒ½å¯¹æ¯”åŠŸèƒ½"""
    print("\n=== æµ‹è¯•æ€§èƒ½å¯¹æ¯”åŠŸèƒ½ ===")
    
    try:
        from preprocessing.uda_visualizer import create_uda_visualizer
        from sklearn.linear_model import LogisticRegression
        
        # åˆ›å»ºæ¨¡æ‹ŸUDAæ–¹æ³•
        class MockUDAMethod:
            def __init__(self):
                self.model = LogisticRegression(random_state=42, max_iter=1000, penalty=None)
                self.fitted = False
            
            def fit(self, X_source, y_source, X_target):
                self.model.fit(X_source, y_source)
                self.fitted = True
                return self
            
            def predict(self, X):
                if not self.fitted:
                    raise ValueError("Method not fitted")
                return self.model.predict(X)
            
            def predict_proba(self, X):
                if not self.fitted:
                    raise ValueError("Method not fitted")
                return self.model.predict_proba(X)
        
        # åˆ›å»ºæ•°æ®
        np.random.seed(42)
        X_source = np.random.normal(0, 1, (100, 4))
        y_source = np.random.choice([0, 1], 100, p=[0.6, 0.4])
        X_target = np.random.normal(0.5, 1.2, (80, 4))
        y_target = np.random.choice([0, 1], 80, p=[0.4, 0.6])
        
        # åˆ›å»ºå¹¶æ‹Ÿåˆæ¨¡æ‹ŸUDAæ–¹æ³•
        mock_uda = MockUDAMethod()
        mock_uda.fit(X_source, y_source, X_target)
        
        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = create_uda_visualizer(save_plots=False)
        
        # æµ‹è¯•æ€§èƒ½å¯¹æ¯”
        perf_results = visualizer.plot_performance_comparison(
            X_source, y_source, X_target, y_target,
            uda_method=mock_uda,
            method_name="Mock_UDA"
        )
        
        # æ£€æŸ¥ç»“æœ
        assert 'baseline_scores' in perf_results, "ç¼ºå°‘åŸºçº¿åˆ†æ•°"
        assert 'uda_scores' in perf_results, "ç¼ºå°‘UDAåˆ†æ•°"
        assert 'improvements' in perf_results, "ç¼ºå°‘æ”¹è¿›æŒ‡æ ‡"
        
        print("âœ“ æ€§èƒ½å¯¹æ¯”åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½å¯¹æ¯”æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("UDAå¯è§†åŒ–åŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    tests = [
        test_visualizer_basic_functionality,
        test_distance_metrics,
        test_performance_comparison,
        test_visualizer_with_uda_method,
    ]
    
    passed = 0
    total = len(tests)
    
    for test_func in tests:
        try:
            if test_func():
                passed += 1
        except Exception as e:
            print(f"âŒ æµ‹è¯• {test_func.__name__} å¼‚å¸¸: {e}")
    
    print("\n" + "=" * 50)
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰å¯è§†åŒ–åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print("âš  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 