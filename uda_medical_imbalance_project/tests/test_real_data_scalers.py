# -*- coding: utf-8 -*-
"""
çœŸå®åŒ»ç–—æ•°æ®æ ‡å‡†åŒ–å™¨æµ‹è¯•æ¨¡å—

ä½¿ç”¨çœŸå®åŒ»ç–—æ•°æ®æµ‹è¯•æ ‡å‡†åŒ–åŠŸèƒ½ï¼š
- æ•°æ®Aï¼š295æ¡è®°å½•
- æ•°æ®Bï¼š190æ¡è®°å½•
- æµ‹è¯•è·¨åŸŸæ ‡å‡†åŒ–æ•ˆæœ
- å¯è§†åŒ–æ ‡å‡†åŒ–å‰åçš„æ•ˆæœ

Author: UDA Medical Project Team
Date: 2024
"""

import sys
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

try:
    from preprocessing.scalers import MedicalDataScaler, compare_scalers
    from data.loader import MedicalDataLoader
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæµ‹è¯•")
    sys.exit(1)

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“å’Œå›¾ç‰‡ä¿å­˜ç›®å½•
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False
IMG_DIR = Path(__file__).parent / 'imgs'
IMG_DIR.mkdir(exist_ok=True)


def save_figure(fig, filename, dpi=300):
    """ä¿å­˜å›¾ç‰‡åˆ°æŒ‡å®šç›®å½•"""
    filepath = IMG_DIR / filename
    fig.savefig(filepath, dpi=dpi, bbox_inches='tight', facecolor='white')
    print(f"ğŸ“Š å›¾ç‰‡å·²ä¿å­˜: {filepath}")


def visualize_scaling_effect(X_original, X_scaled, feature_names, categorical_features, 
                           title_prefix, filename_prefix):
    """å¯è§†åŒ–æ ‡å‡†åŒ–å‰åçš„æ•ˆæœ"""
    # è·å–æ•°å€¼ç‰¹å¾
    numerical_features = [f for f in feature_names if f not in categorical_features]
    
    if len(numerical_features) == 0:
        print("âš ï¸ æ²¡æœ‰æ•°å€¼ç‰¹å¾éœ€è¦å¯è§†åŒ–")
        return
    
    # åˆ›å»ºå­å›¾
    n_features = len(numerical_features)
    n_cols = min(3, n_features)
    n_rows = (n_features + n_cols - 1) // n_cols
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))
    if n_rows == 1 and n_cols == 1:
        axes = [axes]
    elif n_rows == 1:
        axes = axes
    else:
        axes = axes.flatten()
    
    # ä¸ºæ¯ä¸ªæ•°å€¼ç‰¹å¾ç»˜åˆ¶åˆ†å¸ƒå›¾
    for i, feature in enumerate(numerical_features):
        feature_idx = feature_names.index(feature)
        
        ax = axes[i] if len(axes) > 1 else axes[0]
        
        # åŸå§‹æ•°æ®åˆ†å¸ƒ
        ax.hist(X_original[:, feature_idx], bins=30, alpha=0.6, 
                label='Original', color='skyblue', density=True)
        
        # æ ‡å‡†åŒ–åæ•°æ®åˆ†å¸ƒ
        ax.hist(X_scaled[:, feature_idx], bins=30, alpha=0.6, 
                label='Scaled', color='orange', density=True)
        
        ax.set_title(f'{feature}\nOriginal: Î¼={X_original[:, feature_idx].mean():.3f}, Ïƒ={X_original[:, feature_idx].std():.3f}\n'
                    f'Scaled: Î¼={X_scaled[:, feature_idx].mean():.3f}, Ïƒ={X_scaled[:, feature_idx].std():.3f}')
        ax.set_xlabel('Value')
        ax.set_ylabel('Density')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    # éšè—å¤šä½™çš„å­å›¾
    for i in range(len(numerical_features), len(axes)):
        axes[i].set_visible(False)
    
    plt.suptitle(f'{title_prefix} - Feature Distribution Comparison', fontsize=16, y=0.98)
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    save_figure(fig, f'{filename_prefix}_feature_distributions.png')
    plt.close()


def visualize_cross_domain_effect(X_source_original, X_source_scaled, 
                                X_target_original, X_target_scaled,
                                feature_names, categorical_features):
    """å¯è§†åŒ–è·¨åŸŸæ ‡å‡†åŒ–æ•ˆæœ"""
    numerical_features = [f for f in feature_names if f not in categorical_features]
    
    if len(numerical_features) == 0:
        return
    
    # é€‰æ‹©å‰4ä¸ªæ•°å€¼ç‰¹å¾è¿›è¡Œå¯è§†åŒ–
    selected_features = numerical_features[:4]
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    axes = axes.flatten()
    
    for i, feature in enumerate(selected_features):
        if i >= 4:
            break
            
        feature_idx = feature_names.index(feature)
        ax = axes[i]
        
        # æºåŸŸæ•°æ®
        ax.hist(X_source_original[:, feature_idx], bins=20, alpha=0.5, 
                label='Source Original', color='blue', density=True)
        ax.hist(X_source_scaled[:, feature_idx], bins=20, alpha=0.5, 
                label='Source Scaled', color='lightblue', density=True)
        
        # ç›®æ ‡åŸŸæ•°æ®
        ax.hist(X_target_original[:, feature_idx], bins=20, alpha=0.5, 
                label='Target Original', color='red', density=True)
        ax.hist(X_target_scaled[:, feature_idx], bins=20, alpha=0.5, 
                label='Target Scaled', color='pink', density=True)
        
        ax.set_title(f'{feature} - Cross-Domain Scaling')
        ax.set_xlabel('Value')
        ax.set_ylabel('Density')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    plt.suptitle('Cross-Domain Scaling Effect (Source A â†’ Target B)', fontsize=16)
    plt.tight_layout()
    
    save_figure(fig, 'cross_domain_scaling_effect.png')
    plt.close()


def visualize_scaler_comparison(X_original, scalers_results, feature_names, categorical_features):
    """å¯è§†åŒ–ä¸åŒæ ‡å‡†åŒ–å™¨çš„å¯¹æ¯”æ•ˆæœ"""
    numerical_features = [f for f in feature_names if f not in categorical_features]
    
    if len(numerical_features) == 0:
        return
    
    # é€‰æ‹©å‰2ä¸ªæ•°å€¼ç‰¹å¾è¿›è¡Œè¯¦ç»†å¯¹æ¯”
    selected_features = numerical_features[:2]
    
    fig, axes = plt.subplots(len(selected_features), 1, figsize=(12, 6*len(selected_features)))
    if len(selected_features) == 1:
        axes = [axes]
    
    colors = ['blue', 'green', 'red', 'purple']
    
    for i, feature in enumerate(selected_features):
        feature_idx = feature_names.index(feature)
        ax = axes[i]
        
        # åŸå§‹æ•°æ®
        ax.hist(X_original[:, feature_idx], bins=30, alpha=0.4, 
                label='Original', color='gray', density=True)
        
        # ä¸åŒæ ‡å‡†åŒ–å™¨çš„ç»“æœ
        for j, (scaler_name, X_scaled) in enumerate(scalers_results.items()):
            ax.hist(X_scaled[:, feature_idx], bins=30, alpha=0.6, 
                    label=f'{scaler_name.title()}', color=colors[j % len(colors)], 
                    density=True, histtype='step', linewidth=2)
        
        ax.set_title(f'{feature} - Scaler Comparison')
        ax.set_xlabel('Value')
        ax.set_ylabel('Density')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    plt.suptitle('Different Scalers Comparison', fontsize=16)
    plt.tight_layout()
    
    save_figure(fig, 'scalers_comparison.png')
    plt.close()


def visualize_feature_sets_comparison(loader):
    """å¯è§†åŒ–ä¸åŒç‰¹å¾é›†çš„ç»Ÿè®¡ä¿¡æ¯"""
    feature_types = ['best7', 'best8', 'best9', 'best10']
    stats_data = []
    
    for feature_type in feature_types:
        dataset_A = loader.load_dataset('A', feature_type=feature_type)
        categorical_features = loader.get_categorical_features(feature_type)
        
        stats_data.append({
            'Feature Set': feature_type,
            'Total Features': dataset_A['n_features'],
            'Numerical Features': dataset_A['n_features'] - len(categorical_features),
            'Categorical Features': len(categorical_features),
            'Samples': dataset_A['n_samples']
        })
    
    # åˆ›å»ºç»Ÿè®¡å›¾è¡¨
    df_stats = pd.DataFrame(stats_data)
    
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    # ç‰¹å¾æ•°é‡å¯¹æ¯”
    x = range(len(feature_types))
    width = 0.35
    
    axes[0].bar([i - width/2 for i in x], df_stats['Numerical Features'], 
                width, label='Numerical Features', color='skyblue')
    axes[0].bar([i + width/2 for i in x], df_stats['Categorical Features'], 
                width, label='Categorical Features', color='orange')
    
    axes[0].set_xlabel('Feature Sets')
    axes[0].set_ylabel('Number of Features')
    axes[0].set_title('Feature Composition by Feature Set')
    axes[0].set_xticks(x)
    axes[0].set_xticklabels(feature_types)
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # ç‰¹å¾æ¯”ä¾‹é¥¼å›¾
    total_features = df_stats['Total Features'].iloc[-1]  # ä½¿ç”¨best10çš„æ€»æ•°
    numerical_count = df_stats['Numerical Features'].iloc[-1]
    categorical_count = df_stats['Categorical Features'].iloc[-1]
    
    axes[1].pie([numerical_count, categorical_count], 
                labels=['Numerical Features', 'Categorical Features'],
                colors=['skyblue', 'orange'], autopct='%1.1f%%', startangle=90)
    axes[1].set_title('Feature Type Distribution (Best10 Set)')
    
    plt.tight_layout()
    save_figure(fig, 'feature_sets_comparison.png')
    plt.close()
    
    return df_stats


def test_real_data_standard_scaling():
    """æµ‹è¯•çœŸå®åŒ»ç–—æ•°æ®çš„æ ‡å‡†æ ‡å‡†åŒ–"""
    print("ğŸ”¬ å¼€å§‹æµ‹è¯•çœŸå®åŒ»ç–—æ•°æ®æ ‡å‡†åŒ–...")
    
    # åŠ è½½çœŸå®åŒ»ç–—æ•°æ®
    loader = MedicalDataLoader()
    
    # åŠ è½½æ•°æ®Aï¼ˆ295æ¡ï¼‰å’Œæ•°æ®Bï¼ˆ190æ¡ï¼‰
    dataset_A = loader.load_dataset('A', feature_type='best8')
    dataset_B = loader.load_dataset('B', feature_type='best8')
    
    X_A = pd.DataFrame(dataset_A['X'], columns=dataset_A['feature_names'])
    X_B = pd.DataFrame(dataset_B['X'], columns=dataset_B['feature_names'])
    
    # è·å–ç±»åˆ«ç‰¹å¾
    categorical_features = loader.get_categorical_features('best8')
    
    print(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆ:")
    print(f"   - æ•°æ®A: {X_A.shape} (295æ¡è®°å½•)")
    print(f"   - æ•°æ®B: {X_B.shape} (190æ¡è®°å½•)")
    print(f"   - ç‰¹å¾é›†: best8 ({X_A.shape[1]}ä¸ªç‰¹å¾)")
    print(f"   - ç±»åˆ«ç‰¹å¾: {categorical_features}")
    
    # æµ‹è¯•æ ‡å‡†æ ‡å‡†åŒ–
    scaler = MedicalDataScaler(
        scaler_type='standard',
        categorical_features=categorical_features
    )
    
    # åœ¨æ•°æ®Aä¸Šæ‹Ÿåˆ
    scaler.fit(X_A)
    print(f"âœ… æ ‡å‡†åŒ–å™¨åœ¨æ•°æ®Aä¸Šæ‹Ÿåˆå®Œæˆ")
    
    # è·å–ç‰¹å¾ä¿¡æ¯
    info = scaler.get_feature_info()
    print(f"ğŸ“‹ ç‰¹å¾ä¿¡æ¯:")
    print(f"   - æ€»ç‰¹å¾æ•°: {info['total_features']}")
    print(f"   - æ•°å€¼ç‰¹å¾æ•°: {info['numerical_features']}")
    print(f"   - ç±»åˆ«ç‰¹å¾æ•°: {info['categorical_features']}")
    print(f"   - æ•°å€¼ç‰¹å¾å: {info['numerical_feature_names']}")
    print(f"   - ç±»åˆ«ç‰¹å¾å: {info['categorical_feature_names']}")
    
    # åœ¨æ•°æ®Aä¸Šå˜æ¢
    X_A_scaled = scaler.transform(X_A)
    print(f"âœ… æ•°æ®Aæ ‡å‡†åŒ–å®Œæˆ: {X_A_scaled.shape}")
    
    # éªŒè¯æ•°å€¼ç‰¹å¾æ ‡å‡†åŒ–æ•ˆæœ
    numerical_indices = [X_A.columns.get_loc(col) for col in info['numerical_feature_names']]
    X_A_numerical_scaled = X_A_scaled[:, numerical_indices]
    
    mean_after = np.mean(X_A_numerical_scaled)
    std_after = np.std(X_A_numerical_scaled)
    
    print(f"ğŸ“ˆ æ•°æ®Aæ ‡å‡†åŒ–æ•ˆæœ:")
    print(f"   - æ•°å€¼ç‰¹å¾å‡å€¼: {mean_after:.6f} (åº”æ¥è¿‘0)")
    print(f"   - æ•°å€¼ç‰¹å¾æ ‡å‡†å·®: {std_after:.6f} (åº”æ¥è¿‘1)")
    
    # éªŒè¯ç±»åˆ«ç‰¹å¾ä¿æŒä¸å˜
    for cat_feature in categorical_features:
        cat_idx = X_A.columns.get_loc(cat_feature)
        original_values = X_A.iloc[:, cat_idx].values
        scaled_values = X_A_scaled[:, cat_idx]
        assert np.array_equal(original_values, scaled_values), f"ç±»åˆ«ç‰¹å¾ {cat_feature} å‘ç”Ÿäº†å˜åŒ–"
    
    print(f"âœ… ç±»åˆ«ç‰¹å¾ä¿æŒä¸å˜éªŒè¯é€šè¿‡")
    
    # å¯è§†åŒ–æ ‡å‡†åŒ–æ•ˆæœ
    visualize_scaling_effect(
        X_A.values, X_A_scaled, dataset_A['feature_names'], categorical_features,
        'Dataset A Standard Scaling', 'dataset_A_standard_scaling'
    )
    
    return scaler, X_A_scaled, info, X_A.values


def test_cross_domain_scaling():
    """æµ‹è¯•è·¨åŸŸæ ‡å‡†åŒ–ï¼šåœ¨æ•°æ®Aä¸Šæ‹Ÿåˆï¼Œåœ¨æ•°æ®Bä¸Šå˜æ¢"""
    print("\nğŸŒ å¼€å§‹æµ‹è¯•è·¨åŸŸæ ‡å‡†åŒ–...")
    
    # åŠ è½½æ•°æ®
    loader = MedicalDataLoader()
    dataset_A = loader.load_dataset('A', feature_type='best8')
    dataset_B = loader.load_dataset('B', feature_type='best8')
    
    X_A = pd.DataFrame(dataset_A['X'], columns=dataset_A['feature_names'])
    X_B = pd.DataFrame(dataset_B['X'], columns=dataset_B['feature_names'])
    categorical_features = loader.get_categorical_features('best8')
    
    # åˆ›å»ºæ ‡å‡†åŒ–å™¨å¹¶åœ¨æ•°æ®Aä¸Šæ‹Ÿåˆ
    scaler = MedicalDataScaler(
        scaler_type='standard',
        categorical_features=categorical_features
    )
    scaler.fit(X_A)
    
    # åœ¨æ•°æ®Aå’Œæ•°æ®Bä¸Šåº”ç”¨æ ‡å‡†åŒ–
    X_A_scaled = scaler.transform(X_A)
    X_B_scaled = scaler.transform(X_B)
    
    print(f"âœ… è·¨åŸŸæ ‡å‡†åŒ–å®Œæˆ: æ•°æ®A({X_A.shape[0]}) â†’ æ•°æ®B({X_B.shape[0]})")
    
    # éªŒè¯å½¢çŠ¶
    assert X_B_scaled.shape == X_B.shape, "æ ‡å‡†åŒ–åå½¢çŠ¶å‘ç”Ÿå˜åŒ–"
    
    # éªŒè¯ç±»åˆ«ç‰¹å¾ä¿æŒä¸å˜
    for cat_feature in categorical_features:
        cat_idx = X_B.columns.get_loc(cat_feature)
        original_values = X_B.iloc[:, cat_idx].values
        scaled_values = X_B_scaled[:, cat_idx]
        assert np.array_equal(original_values, scaled_values), f"ç±»åˆ«ç‰¹å¾ {cat_feature} å‘ç”Ÿäº†å˜åŒ–"
    
    print(f"âœ… è·¨åŸŸæ ‡å‡†åŒ–éªŒè¯é€šè¿‡")
    
    # åˆ†ææ•°å€¼ç‰¹å¾çš„åˆ†å¸ƒå˜åŒ–
    info = scaler.get_feature_info()
    numerical_indices = [X_B.columns.get_loc(col) for col in info['numerical_feature_names']]
    X_B_numerical_scaled = X_B_scaled[:, numerical_indices]
    
    mean_B = np.mean(X_B_numerical_scaled)
    std_B = np.std(X_B_numerical_scaled)
    
    print(f"ğŸ“ˆ æ•°æ®Bæ ‡å‡†åŒ–åç»Ÿè®¡:")
    print(f"   - æ•°å€¼ç‰¹å¾å‡å€¼: {mean_B:.6f}")
    print(f"   - æ•°å€¼ç‰¹å¾æ ‡å‡†å·®: {std_B:.6f}")
    print(f"   - æ³¨æ„: ç”±äºåŸŸé—´å·®å¼‚ï¼Œå‡å€¼å’Œæ ‡å‡†å·®å¯èƒ½ä¸æ˜¯0å’Œ1")
    
    # å¯è§†åŒ–è·¨åŸŸæ ‡å‡†åŒ–æ•ˆæœ
    visualize_cross_domain_effect(
        X_A.values, X_A_scaled, X_B.values, X_B_scaled,
        dataset_A['feature_names'], categorical_features
    )
    
    return X_B_scaled


def test_robust_scaling():
    """æµ‹è¯•é²æ£’æ ‡å‡†åŒ–"""
    print("\nğŸ›¡ï¸ å¼€å§‹æµ‹è¯•é²æ£’æ ‡å‡†åŒ–...")
    
    # åŠ è½½æ•°æ®
    loader = MedicalDataLoader()
    dataset_A = loader.load_dataset('A', feature_type='best8')
    
    X_A = pd.DataFrame(dataset_A['X'], columns=dataset_A['feature_names'])
    categorical_features = loader.get_categorical_features('best8')
    
    # åˆ›å»ºé²æ£’æ ‡å‡†åŒ–å™¨
    scaler = MedicalDataScaler(
        scaler_type='robust',
        categorical_features=categorical_features
    )
    
    # æ‹Ÿåˆå’Œå˜æ¢
    X_A_scaled = scaler.fit_transform(X_A)
    print(f"âœ… é²æ£’æ ‡å‡†åŒ–å®Œæˆ: {X_A_scaled.shape}")
    
    # éªŒè¯æ•°å€¼ç‰¹å¾çš„ä¸­ä½æ•°æ¥è¿‘0
    info = scaler.get_feature_info()
    numerical_indices = [X_A.columns.get_loc(col) for col in info['numerical_feature_names']]
    X_A_numerical_scaled = X_A_scaled[:, numerical_indices]
    
    median_after = np.median(X_A_numerical_scaled)
    iqr_after = np.percentile(X_A_numerical_scaled, 75) - np.percentile(X_A_numerical_scaled, 25)
    
    print(f"ğŸ“ˆ é²æ£’æ ‡å‡†åŒ–æ•ˆæœ:")
    print(f"   - æ•°å€¼ç‰¹å¾ä¸­ä½æ•°: {median_after:.6f} (åº”æ¥è¿‘0)")
    print(f"   - æ•°å€¼ç‰¹å¾IQR: {iqr_after:.6f}")
    
    # å¯è§†åŒ–é²æ£’æ ‡å‡†åŒ–æ•ˆæœ
    visualize_scaling_effect(
        X_A.values, X_A_scaled, dataset_A['feature_names'], categorical_features,
        'Dataset A Robust Scaling', 'dataset_A_robust_scaling'
    )
    
    return X_A_scaled


def test_no_scaling():
    """æµ‹è¯•ä¸è¿›è¡Œæ ‡å‡†åŒ–"""
    print("\nğŸš« å¼€å§‹æµ‹è¯•ä¸è¿›è¡Œæ ‡å‡†åŒ–...")
    
    # åŠ è½½æ•°æ®
    loader = MedicalDataLoader()
    dataset_A = loader.load_dataset('A', feature_type='best8')
    
    X_A = pd.DataFrame(dataset_A['X'], columns=dataset_A['feature_names'])
    categorical_features = loader.get_categorical_features('best8')
    
    # åˆ›å»ºæ— æ ‡å‡†åŒ–å™¨
    scaler = MedicalDataScaler(
        scaler_type='none',
        categorical_features=categorical_features
    )
    
    # æ‹Ÿåˆå’Œå˜æ¢
    X_A_no_scaled = scaler.fit_transform(X_A)
    print(f"âœ… æ— æ ‡å‡†åŒ–å®Œæˆ: {X_A_no_scaled.shape}")
    
    # éªŒè¯æ•°æ®ä¿æŒä¸å˜
    assert np.array_equal(X_A.values, X_A_no_scaled), "æ— æ ‡å‡†åŒ–æ—¶æ•°æ®åº”ä¿æŒä¸å˜"
    
    # è·å–ç‰¹å¾ä¿¡æ¯
    info = scaler.get_feature_info()
    numerical_indices = [X_A.columns.get_loc(col) for col in info['numerical_feature_names']]
    X_A_numerical = X_A_no_scaled[:, numerical_indices]
    
    mean_original = np.mean(X_A_numerical)
    std_original = np.std(X_A_numerical)
    
    print(f"ğŸ“ˆ æ— æ ‡å‡†åŒ–æ•ˆæœ:")
    print(f"   - æ•°å€¼ç‰¹å¾å‡å€¼: {mean_original:.6f} (ä¿æŒåŸå§‹)")
    print(f"   - æ•°å€¼ç‰¹å¾æ ‡å‡†å·®: {std_original:.6f} (ä¿æŒåŸå§‹)")
    print(f"   - æ•°æ®å®Œå…¨ä¿æŒä¸å˜: âœ…")
    
    # å¯è§†åŒ–æ— æ ‡å‡†åŒ–æ•ˆæœï¼ˆåº”è¯¥æ˜¾ç¤ºåŸå§‹æ•°æ®å’Œ"æ ‡å‡†åŒ–"åæ•°æ®å®Œå…¨ä¸€è‡´ï¼‰
    visualize_scaling_effect(
        X_A.values, X_A_no_scaled, dataset_A['feature_names'], categorical_features,
        'Dataset A No Scaling', 'dataset_A_no_scaling'
    )
    
    return X_A_no_scaled


def test_scaler_comparison():
    """æ¯”è¾ƒä¸åŒæ ‡å‡†åŒ–å™¨çš„æ•ˆæœ"""
    print("\nâš–ï¸ å¼€å§‹æ¯”è¾ƒä¸åŒæ ‡å‡†åŒ–å™¨...")
    
    # åŠ è½½æ•°æ®
    loader = MedicalDataLoader()
    dataset_A = loader.load_dataset('A', feature_type='best8')
    
    X_A = pd.DataFrame(dataset_A['X'], columns=dataset_A['feature_names'])
    categorical_features = loader.get_categorical_features('best8')
    
    # æ¯”è¾ƒæ ‡å‡†åŒ–å™¨
    comparison = compare_scalers(X_A, categorical_features)
    
    print(f"ğŸ“Š æ ‡å‡†åŒ–å™¨æ¯”è¾ƒç»“æœ:")
    for scaler_type, stats in comparison.items():
        print(f"   {scaler_type.upper()}:")
        print(f"     - å‡å€¼: {stats['mean']:.6f}")
        print(f"     - æ ‡å‡†å·®: {stats['std']:.6f}")
        print(f"     - ä¸­ä½æ•°: {stats['median']:.6f}")
        print(f"     - IQR: {stats['iqr']:.6f}")
        print(f"     - èŒƒå›´: [{stats['min']:.3f}, {stats['max']:.3f}]")
    
    # è·å–ä¸åŒæ ‡å‡†åŒ–å™¨çš„ç»“æœç”¨äºå¯è§†åŒ–
    scalers_results = {}
    for scaler_type in ['standard', 'robust', 'none']:
        scaler = MedicalDataScaler(
            scaler_type=scaler_type,
            categorical_features=categorical_features
        )
        X_scaled = scaler.fit_transform(X_A)
        scalers_results[scaler_type] = X_scaled
    
    # å¯è§†åŒ–ä¸åŒæ ‡å‡†åŒ–å™¨çš„å¯¹æ¯”
    visualize_scaler_comparison(
        X_A.values, scalers_results, dataset_A['feature_names'], categorical_features
    )
    
    return comparison


def test_feature_sets():
    """æµ‹è¯•ä¸åŒç‰¹å¾é›†çš„æ ‡å‡†åŒ–"""
    print("\nğŸ¯ å¼€å§‹æµ‹è¯•ä¸åŒç‰¹å¾é›†...")
    
    loader = MedicalDataLoader()
    feature_types = ['best7', 'best8', 'best9', 'best10']
    
    for feature_type in feature_types:
        print(f"\nğŸ“‹ æµ‹è¯•ç‰¹å¾é›†: {feature_type}")
        
        # åŠ è½½æ•°æ®
        dataset_A = loader.load_dataset('A', feature_type=feature_type)
        X_A = pd.DataFrame(dataset_A['X'], columns=dataset_A['feature_names'])
        categorical_features = loader.get_categorical_features(feature_type)
        
        # åˆ›å»ºæ ‡å‡†åŒ–å™¨
        scaler = MedicalDataScaler(
            scaler_type='standard',
            categorical_features=categorical_features
        )
        
        # æ‹Ÿåˆå’Œå˜æ¢
        scaler.fit_transform(X_A)
        
        # è·å–ä¿¡æ¯
        info = scaler.get_feature_info()
        
        print(f"   - æ•°æ®å½¢çŠ¶: {X_A.shape}")
        print(f"   - æ€»ç‰¹å¾: {info['total_features']}")
        print(f"   - æ•°å€¼ç‰¹å¾: {info['numerical_features']}")
        print(f"   - ç±»åˆ«ç‰¹å¾: {info['categorical_features']}")
        print(f"   - ç±»åˆ«ç‰¹å¾å: {info['categorical_feature_names']}")
    
    # å¯è§†åŒ–ç‰¹å¾é›†å¯¹æ¯”
    stats_df = visualize_feature_sets_comparison(loader)
    print(f"\nğŸ“Š ç‰¹å¾é›†ç»Ÿè®¡å¯¹æ¯”:")
    print(stats_df.to_string(index=False))


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹çœŸå®åŒ»ç–—æ•°æ®æ ‡å‡†åŒ–æµ‹è¯•")
    print("=" * 60)
    
    try:
        # æµ‹è¯•1: æ ‡å‡†æ ‡å‡†åŒ–
        test_real_data_standard_scaling()
        
        # æµ‹è¯•2: è·¨åŸŸæ ‡å‡†åŒ–
        test_cross_domain_scaling()
        
        # æµ‹è¯•3: é²æ£’æ ‡å‡†åŒ–
        test_robust_scaling()
        
        # æµ‹è¯•4: æ— æ ‡å‡†åŒ–
        test_no_scaling()
        
        # æµ‹è¯•5: æ ‡å‡†åŒ–å™¨æ¯”è¾ƒ
        test_scaler_comparison()
        
        # æµ‹è¯•5: ä¸åŒç‰¹å¾é›†
        test_feature_sets()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("âœ… æ ‡å‡†åŒ–å™¨å¯ä»¥æ­£ç¡®å¤„ç†çœŸå®åŒ»ç–—æ•°æ®")
        print("âœ… æ”¯æŒè·¨åŸŸæ ‡å‡†åŒ–ï¼ˆAâ†’Bï¼‰")
        print("âœ… ç±»åˆ«ç‰¹å¾ä¿æŒä¸å˜")
        print("âœ… æ•°å€¼ç‰¹å¾æ­£ç¡®æ ‡å‡†åŒ–")
        print(f"ğŸ“Š å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {IMG_DIR}")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 