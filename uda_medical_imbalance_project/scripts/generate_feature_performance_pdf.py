#!/usr/bin/env python3
"""
Feature Number Performance Visualization Script

æ ¹æ®feature_number_comparison.csvç”Ÿæˆé«˜è´¨é‡PDFæ ¼å¼çš„æ€§èƒ½å¯¹æ¯”å›¾è¡¨
ç”¨äºå­¦æœ¯è®ºæ–‡å‘è¡¨ï¼ŒDPIè®¾ç½®ä¸º900-1200

ä¾èµ–åŒ…å®‰è£…:
pip install pandas matplotlib numpy seaborn

ä½œè€…: TabPFN+TCA Medical Research Team
æ—¥æœŸ: 2025-08-22
"""

import sys
from pathlib import Path
import warnings

# æ£€æŸ¥ä¾èµ–åŒ…
required_packages = {
    'pandas': 'pandas',
    'matplotlib.pyplot': 'matplotlib', 
    'numpy': 'numpy',
    'seaborn': 'seaborn'
}

missing_packages = []
for module, package in required_packages.items():
    try:
        __import__(module)
    except ImportError:
        missing_packages.append(package)

if missing_packages:
    print("âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…:")
    for package in missing_packages:
        print(f"  - {package}")
    print("\nğŸ’¡ å®‰è£…å‘½ä»¤:")
    print(f"pip install {' '.join(missing_packages)}")
    print("\næˆ–è€…ä½¿ç”¨conda:")
    print(f"conda install {' '.join(missing_packages)}")
    sys.exit(1)

# å¯¼å…¥æ‰€æœ‰ä¾èµ–åŒ…
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

warnings.filterwarnings('ignore')

# è®¾ç½®NatureæœŸåˆŠçº§åˆ«çš„å›¾å½¢å‚æ•°
plt.rcParams.update({
    'font.family': 'Arial',
    'font.sans-serif': ['Arial'],
    'font.size': 11,
    'axes.titlesize': 12,
    'axes.labelsize': 11,
    'xtick.labelsize': 10,
    'ytick.labelsize': 10,
    'legend.fontsize': 10,
    'figure.titlesize': 14,
    'text.usetex': False,
    'axes.linewidth': 0.8,
    'grid.linewidth': 0.5,
    'lines.linewidth': 1.5,
    'patch.linewidth': 0.8
})

def load_and_analyze_data(csv_path):
    """åŠ è½½å¹¶åˆ†æCSVæ•°æ®"""
    print(f"ğŸ“Š åŠ è½½æ•°æ®æ–‡ä»¶: {csv_path}")
    
    # è¯»å–CSVæ–‡ä»¶
    try:
        df = pd.read_csv(csv_path)
        print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼Œå…± {len(df)} è¡Œè®°å½•")
        
        # æ˜¾ç¤ºæ•°æ®åŸºæœ¬ä¿¡æ¯
        print(f"ğŸ“‹ æ•°æ®åˆ—: {list(df.columns)}")
        print(f"ğŸ“ˆ ç‰¹å¾æ•°é‡èŒƒå›´: {df['n_features'].min()} - {df['n_features'].max()}")
        
        return df
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        raise

def create_performance_comparison_plot(df, output_path, dpi=1200):
    """
    åˆ›å»ºæ€§èƒ½å¯¹æ¯”å›¾è¡¨
    
    å‚æ•°:
    - df: æ•°æ®æ¡†
    - output_path: è¾“å‡ºè·¯å¾„
    - dpi: å›¾ç‰‡åˆ†è¾¨ç‡ (900-1200)
    """
    print(f"ğŸ¨ ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨ (DPI: {dpi})")
    
    # åˆ›å»ºå›¾å½¢å’Œå­å›¾
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    # åˆ é™¤ä¸»æ ‡é¢˜ä»¥ç¬¦åˆæŠ•ç¨¿è¦æ±‚
    # fig.suptitle('Feature Number vs. Classification Performance (TabPFN+TCA Medical Cross-Domain Analysis)', 
    #              fontsize=12, fontweight='bold', y=0.96)
    
    # å®šä¹‰NatureæœŸåˆŠæ ‡å‡†é…è‰² - å››è‰²æ–¹æ¡ˆ
    colors = {
        'accuracy': '#9BDCFC',     # æ–°æµ…è“è‰²
        'auc': '#C9EFBE',          # æ–°æµ…ç»¿è‰²
        'f1': '#CAC8EF',           # æ–°æµ…ç´«è‰²
        'cost_eff': '#F0CFEA',     # æ–°æµ…ç²‰è‰²ï¼ˆCost-Effectivenessï¼‰
        'dual_1': '#9BDCFC',       # åŒè‰²æ–¹æ¡ˆ1ï¼ˆå¤ç”¨ï¼‰
        'dual_2': '#F0CFEA'        # åŒè‰²æ–¹æ¡ˆ2ï¼ˆå¤ç”¨ï¼‰
    }
    
    # å­å›¾1: Accuracy vs Feature Number
    ax1 = axes[0, 0]
    ax1.plot(df['n_features'], df['mean_accuracy'], 'o-', 
             color=colors['accuracy'], linewidth=2, markersize=5, alpha=0.9)
    ax1.fill_between(df['n_features'], 
                     df['mean_accuracy'] - df['std_accuracy'],
                     df['mean_accuracy'] + df['std_accuracy'],
                     alpha=0.25, color=colors['accuracy'])
    ax1.set_title('a', fontweight='bold', fontsize=24, pad=20, loc='left')
    ax1.text(0.02, 0.95, 'Accuracy vs. Number of Features', transform=ax1.transAxes, 
             fontsize=11, fontweight='normal', va='top')
    ax1.set_xlabel('Number of Features')
    ax1.set_ylabel('Mean Accuracy')
    ax1.grid(True, alpha=0.3, linestyle='--')
    ax1.set_ylim([0.60, 0.95])
    
    # æ·»åŠ æœ€ä½³æ€§èƒ½ç‚¹æ ‡æ³¨
    best_acc_idx = df['mean_accuracy'].idxmax()
    best_acc_features = df.iloc[best_acc_idx]['n_features']
    best_acc_value = df.iloc[best_acc_idx]['mean_accuracy']
    ax1.annotate(f'Peak: {best_acc_features} features',
                xy=(best_acc_features, best_acc_value),
                xytext=(best_acc_features + 8, best_acc_value - 0.02),
                arrowprops=dict(arrowstyle='->', color='#333333', alpha=0.8, lw=1),
                fontsize=9, ha='left',
                bbox=dict(boxstyle="round,pad=0.2", facecolor='white', alpha=0.9, edgecolor='gray', linewidth=0.5))
    
    # å­å›¾2: AUC vs Feature Number
    ax2 = axes[0, 1]
    ax2.plot(df['n_features'], df['mean_auc'], 'o-', 
             color=colors['auc'], linewidth=2, markersize=5, alpha=0.9)
    ax2.fill_between(df['n_features'], 
                     df['mean_auc'] - df['std_auc'],
                     df['mean_auc'] + df['std_auc'],
                     alpha=0.25, color=colors['auc'])
    ax2.set_title('b', fontweight='bold', fontsize=24, pad=20, loc='left')
    ax2.text(0.02, 0.95, 'AUC vs. Number of Features', transform=ax2.transAxes, 
             fontsize=11, fontweight='normal', va='top')
    ax2.set_xlabel('Number of Features')
    ax2.set_ylabel('Mean AUC')
    ax2.grid(True, alpha=0.3, linestyle='--')
    ax2.set_ylim([0.60, 0.95])
    
    # æ·»åŠ æœ€ä½³AUCç‚¹æ ‡æ³¨
    best_auc_idx = df['mean_auc'].idxmax()
    best_auc_features = df.iloc[best_auc_idx]['n_features']
    best_auc_value = df.iloc[best_auc_idx]['mean_auc']
    ax2.annotate(f'Peak: {best_auc_features} features',
                xy=(best_auc_features, best_auc_value),
                xytext=(best_auc_features + 8, best_auc_value - 0.02),
                arrowprops=dict(arrowstyle='->', color='#333333', alpha=0.8, lw=1),
                fontsize=9, ha='left',
                bbox=dict(boxstyle="round,pad=0.2", facecolor='white', alpha=0.9, edgecolor='gray', linewidth=0.5))
    
    # å­å›¾3: F1 Score vs Feature Number
    ax3 = axes[1, 0]
    ax3.plot(df['n_features'], df['mean_f1'], 'o-', 
             color=colors['f1'], linewidth=2, markersize=5, alpha=0.9)
    ax3.fill_between(df['n_features'], 
                     df['mean_f1'] - df['std_f1'],
                     df['mean_f1'] + df['std_f1'],
                     alpha=0.25, color=colors['f1'])
    ax3.set_title('c', fontweight='bold', fontsize=24, pad=20, loc='left')
    ax3.text(0.02, 0.95, 'F1-Score vs. Number of Features', transform=ax3.transAxes, 
             fontsize=11, fontweight='normal', va='top')
    ax3.set_xlabel('Number of Features')
    ax3.set_ylabel('Mean F1-Score')
    ax3.grid(True, alpha=0.3, linestyle='--')
    ax3.set_ylim([0.60, 0.95])
    
    # æ·»åŠ æœ€ä½³F1ç‚¹æ ‡æ³¨
    best_f1_idx = df['mean_f1'].idxmax()
    best_f1_features = df.iloc[best_f1_idx]['n_features']
    best_f1_value = df.iloc[best_f1_idx]['mean_f1']
    ax3.annotate(f'Peak: {best_f1_features} features',
                xy=(best_f1_features, best_f1_value),
                xytext=(best_f1_features + 8, best_f1_value - 0.02),
                arrowprops=dict(arrowstyle='->', color='#333333', alpha=0.8, lw=1),
                fontsize=9, ha='left',
                bbox=dict(boxstyle="round,pad=0.2", facecolor='white', alpha=0.9, edgecolor='gray', linewidth=0.5))
    
    # å­å›¾4: ç»¼åˆæ€§ä»·æ¯”æŒ‡æ ‡
    ax4 = axes[1, 1]
    
    # è®¡ç®—ç»¼åˆæ€§ä»·æ¯”æŒ‡æ ‡
    # 1. æ€§èƒ½å¾—åˆ† (0-1, è¶Šé«˜è¶Šå¥½)
    performance_score = (df['mean_auc'] * 0.5 + df['mean_accuracy'] * 0.3 + df['mean_f1'] * 0.2)
    
    # 2. æ•ˆç‡å¾—åˆ† (0-1, è®­ç»ƒæ—¶é—´è¶ŠçŸ­è¶Šå¥½)
    max_time = df['mean_time'].max()
    min_time = df['mean_time'].min()
    efficiency_score = 1 - (df['mean_time'] - min_time) / (max_time - min_time)
    
    # 3. ç¨³å®šæ€§å¾—åˆ† (0-1, æ ‡å‡†å·®è¶Šå°è¶Šå¥½) 
    avg_std = (df['std_auc'] + df['std_accuracy'] + df['std_f1']) / 3
    max_std = avg_std.max()
    min_std = avg_std.min()
    stability_score = 1 - (avg_std - min_std) / (max_std - min_std) if max_std > min_std else 1
    
    # 4. ç®€æ´æ€§å¾—åˆ† (0-1, ç¬¦åˆå¥¥å¡å§†å‰ƒåˆ€åŸåˆ™ï¼Œè¶Šç®€å•è¶Šå¥½)
    # ä½¿ç”¨çº¯æ•°å­¦çš„æŒ‡æ•°è¡°å‡å‡½æ•°ï¼Œä½“ç°"è¶Šç®€å•è¶Šå¥½"çš„å¥¥å¡å§†å‰ƒåˆ€åŸç†
    alpha = 0.015  # å¤æ‚åº¦æƒ©ç½šç³»æ•°
    simplicity_score = np.exp(-alpha * df['n_features'])
    
    # ç»¼åˆè¯„ä»·æŒ‡æ ‡ (ç†è®ºé©±åŠ¨çš„æƒé‡åˆ†é…ï¼Œæ€§èƒ½ä¼˜å…ˆï¼Œç®€æ´åº¦é€‚åº¦å¢å¼º)
    # ä¼˜åŒ–æƒé‡: Performance=0.45, Efficiency=0.15, Stability=0.15, Simplicity=0.25
    cost_effectiveness = (performance_score * 0.45 + 
                         efficiency_score * 0.15 + 
                         stability_score * 0.15 + 
                         simplicity_score * 0.25)
    
    # ç»˜åˆ¶ç»¼åˆæŒ‡æ ‡
    ax4.plot(df['n_features'], cost_effectiveness, 'o-', 
             color=colors['cost_eff'], linewidth=2.5, markersize=6, alpha=0.9)
    ax4.fill_between(df['n_features'], 
                     cost_effectiveness - cost_effectiveness.std()*0.1,
                     cost_effectiveness + cost_effectiveness.std()*0.1,
                     alpha=0.2, color=colors['cost_eff'])
    
    # ä¸ºdå›¾æ·»åŠ 9-13ç‰¹å¾é‡è¦åŒºé—´èƒŒæ™¯
    ax4.axvspan(9, 13, alpha=0.25, color=colors['cost_eff'], 
                label='Key Range (9-13 features)', zorder=0)
    
    ax4.set_title('d', fontweight='bold', fontsize=24, pad=20, loc='left')
    ax4.text(0.98, 0.95, 'Cost-Effectiveness Index', transform=ax4.transAxes, 
             fontsize=11, fontweight='normal', va='top', ha='right')
    ax4.set_xlabel('Number of Features')
    ax4.set_ylabel('Comprehensive Score')
    ax4.grid(True, alpha=0.3, linestyle='--')
    # è°ƒæ•´yè½´èŒƒå›´ä»¥æ›´å¥½åœ°æ˜¾ç¤ºæ ‡å‡†å·®
    y_min = min(cost_effectiveness.min() - cost_effectiveness.std()*0.15, 
                cost_effectiveness.min() - 0.1)
    y_max = min(1.0, cost_effectiveness.max() + cost_effectiveness.std()*0.15)
    ax4.set_ylim([y_min, y_max])
    
    # æ·»åŠ æœ€ä½³æ€§ä»·æ¯”ç‚¹æ ‡æ³¨
    best_ce_idx = cost_effectiveness.idxmax()
    best_ce_features = df.iloc[best_ce_idx]['n_features']
    best_ce_value = cost_effectiveness.iloc[best_ce_idx]
    ax4.annotate(f'Optimal: {best_ce_features} features',
                xy=(best_ce_features, best_ce_value),
                xytext=(best_ce_features + 8, best_ce_value - 0.05),
                arrowprops=dict(arrowstyle='->', color='#333333', alpha=0.8, lw=1),
                fontsize=9, ha='left',
                bbox=dict(boxstyle="round,pad=0.2", facecolor='white', alpha=0.9, 
                         edgecolor='gray', linewidth=0.5))
    
    # æ·»åŠ å›¾ä¾‹è¯´æ˜ç»¼åˆæŒ‡æ ‡çš„æ„æˆ
    legend_text = ('PerformanceÃ—0.45 + SimplicityÃ—0.25\n'
                   '+ EfficiencyÃ—0.15 + StabilityÃ—0.15')
    ax4.text(0.02, 0.02, legend_text, transform=ax4.transAxes, 
             fontsize=8, ha='left', va='bottom',
             bbox=dict(boxstyle="round,pad=0.3", facecolor='lightgray', 
                      alpha=0.8, edgecolor='gray', linewidth=0.5))
    
    # è°ƒæ•´å­å›¾é—´è·
    plt.tight_layout()
    plt.subplots_adjust(top=0.92, hspace=0.3, wspace=0.3)
    
    # ä¿å­˜ä¸ºPDF
    print(f"ğŸ’¾ ä¿å­˜PDFå›¾è¡¨åˆ°: {output_path}")
    plt.savefig(output_path, format='pdf', dpi=dpi, bbox_inches='tight', 
                facecolor='white', edgecolor='none', 
                metadata={'Title': 'Feature Number Performance Analysis',
                         'Author': 'TabPFN+TCA Medical Research Team',
                         'Subject': 'Cross-Domain Medical Classification',
                         'Creator': 'Python matplotlib'})
    
    # åŒæ—¶ä¿å­˜é«˜åˆ†è¾¨ç‡PNGç”¨äºé¢„è§ˆ
    png_path = output_path.with_suffix('.png')
    print(f"ğŸ’¾ ä¿å­˜PNGé¢„è§ˆå›¾åˆ°: {png_path}")
    plt.savefig(png_path, format='png', dpi=dpi, bbox_inches='tight',
                facecolor='white', edgecolor='none')
    
    plt.show()
    
    # è¿”å›æœ€ä½³æ€§èƒ½ç»Ÿè®¡
    best_performance = {
        'best_accuracy': {'features': best_acc_features, 'value': best_acc_value},
        'best_auc': {'features': best_auc_features, 'value': best_auc_value},
        'best_f1': {'features': best_f1_features, 'value': best_f1_value}
    }
    
    return best_performance

def create_comprehensive_analysis_plot(df, output_path, dpi=1200):
    """
    åˆ›å»ºç»¼åˆåˆ†æå›¾è¡¨ï¼ŒåŒ…å«æ›´å¤šç»†èŠ‚åˆ†æ
    """
    print(f"ğŸ¨ ç”Ÿæˆç»¼åˆåˆ†æå›¾è¡¨ (DPI: {dpi})")
    
    # åˆ›å»ºæ›´å¤§çš„å›¾å½¢ç”¨äºç»¼åˆåˆ†æ - è°ƒæ•´ä¸ºæ›´é«˜çš„å›¾å½¢ä»¥é€‚åº”æ–°å¸ƒå±€
    fig = plt.figure(figsize=(16, 20))
    
    # ä½¿ç”¨GridSpecè¿›è¡Œå¤æ‚å¸ƒå±€ - ä¿®æ”¹ä¸º5è¡Œ2åˆ—çš„å¸ƒå±€
    from matplotlib.gridspec import GridSpec
    gs = GridSpec(5, 2, figure=fig, height_ratios=[2, 1, 1, 1, 1], width_ratios=[1, 1])
    
    # å®šä¹‰NatureæœŸåˆŠæ ‡å‡†é…è‰² - å››è‰²æ–¹æ¡ˆ
    colors = {
        'accuracy': '#9BDCFC',     # æ–°æµ…è“è‰²
        'auc': '#C9EFBE',          # æ–°æµ…ç»¿è‰²
        'f1': '#CAC8EF',           # æ–°æµ…ç´«è‰²
        'cost_eff': '#F0CFEA',     # æ–°æµ…ç²‰è‰²ï¼ˆCost-Effectivenessï¼‰
        'dual_1': '#9BDCFC',       # åŒè‰²æ–¹æ¡ˆ1ï¼ˆå¤ç”¨ï¼‰
        'dual_2': '#F0CFEA'        # åŒè‰²æ–¹æ¡ˆ2ï¼ˆå¤ç”¨ï¼‰
    }
    
    # åˆ é™¤ä¸»æ ‡é¢˜ä»¥ç¬¦åˆæŠ•ç¨¿è¦æ±‚
    # fig.suptitle('Comprehensive Feature Number Analysis for Medical Cross-Domain Classification\n(TabPFN+TCA Framework)', 
    #              fontsize=18, fontweight='bold', y=0.95)
    
    # ä¸»è¦æ€§èƒ½æŒ‡æ ‡è¶‹åŠ¿å›¾ (å æ®ç¬¬ä¸€è¡Œçš„æ•´ä¸ªå®½åº¦)
    ax_main = fig.add_subplot(gs[0, :])
    
    # ç»˜åˆ¶å¤šæ¡æ€§èƒ½æ›²çº¿
    metrics = ['mean_accuracy', 'mean_auc', 'mean_f1']
    metric_labels = ['Accuracy', 'AUC', 'F1-Score']
    metric_colors = [colors['accuracy'], colors['auc'], colors['f1']]
    
    for i, (metric, label, color) in enumerate(zip(metrics, metric_labels, metric_colors)):
        ax_main.plot(df['n_features'], df[metric], 'o-', 
                     color=color, linewidth=2.5, markersize=7, 
                     label=label, alpha=0.9)
        
        # æ·»åŠ è¯¯å·®å¸¦
        std_metric = f'std_{metric.split("_")[1]}'
        ax_main.fill_between(df['n_features'], 
                            df[metric] - df[std_metric],
                            df[metric] + df[std_metric],
                            alpha=0.15, color=color)
    
    ax_main.set_title('a', fontweight='bold', fontsize=24, pad=20, loc='left')
    ax_main.text(0.02, 0.95, 'Performance Metrics vs. Number of Features', transform=ax_main.transAxes, 
                 fontsize=11, fontweight='normal', va='top')
    ax_main.set_xlabel('Number of Features', fontsize=12)
    ax_main.set_ylabel('Performance Score', fontsize=12)
    ax_main.grid(True, alpha=0.3, linestyle='--')
    ax_main.legend(loc='lower right', fontsize=11)
    ax_main.set_ylim([0.60, 0.95])
    
    # æ·»åŠ 9-13ç‰¹å¾é‡è¦åŒºé—´çš„èƒŒæ™¯è‰²æ ‡è¯†
    ax_main.axvspan(9, 13, alpha=0.25, color=colors['cost_eff'], 
                    label='Key Range (9-13 features)', zorder=0)
    
    # æ·»åŠ å³°å€¼ç‚¹æ ‡æ³¨
    # æ‰¾åˆ°æ¯ä¸ªæŒ‡æ ‡çš„å³°å€¼
    best_acc_idx = df['mean_accuracy'].idxmax()
    best_auc_idx = df['mean_auc'].idxmax()  
    best_f1_idx = df['mean_f1'].idxmax()
    
    best_acc_features = df.iloc[best_acc_idx]['n_features']
    best_auc_features = df.iloc[best_auc_idx]['n_features']
    best_f1_features = df.iloc[best_f1_idx]['n_features']
    
    best_acc_value = df.iloc[best_acc_idx]['mean_accuracy']
    best_auc_value = df.iloc[best_auc_idx]['mean_auc']
    best_f1_value = df.iloc[best_f1_idx]['mean_f1']
    
    # æ ‡æ³¨å³°å€¼ç‚¹ - é‡æ–°è®¾è®¡é¿å…é‡å 
    # Acc Peak: 13 - ä»å³ä¾§æŒ‡å‘å³°å€¼
    ax_main.annotate(f'Acc Peak: {best_acc_features}',
                    xy=(best_acc_features, best_acc_value),
                    xytext=(best_acc_features + 10, best_acc_value),
                    arrowprops=dict(arrowstyle='->', color=colors['accuracy'], alpha=0.8, lw=1.5),
                    fontsize=8, ha='left', va='center',
                    bbox=dict(boxstyle="round,pad=0.2", facecolor='white', alpha=0.9, 
                             edgecolor=colors['accuracy'], linewidth=0.5))
    
    # AUC Peak: 15 - ä»å³ä¾§æŒ‡å‘å³°å€¼
    ax_main.annotate(f'AUC Peak: {best_auc_features}',
                    xy=(best_auc_features, best_auc_value),
                    xytext=(best_auc_features + 8, best_auc_value),
                    arrowprops=dict(arrowstyle='->', color=colors['auc'], alpha=0.8, lw=1.5),
                    fontsize=8, ha='left', va='center',
                    bbox=dict(boxstyle="round,pad=0.2", facecolor='white', alpha=0.9, 
                             edgecolor=colors['auc'], linewidth=0.5))
    
    # F1 Peak: 13 - ä»å³ä¾§æŒ‡å‘å³°å€¼ï¼Œé¿å¼€Accæ ‡æ³¨
    ax_main.annotate(f'F1 Peak: {best_f1_features}',
                    xy=(best_f1_features, best_f1_value),
                    xytext=(best_f1_features + 12, best_f1_value),
                    arrowprops=dict(arrowstyle='->', color=colors['f1'], alpha=0.8, lw=1.5),
                    fontsize=8, ha='left', va='center',
                    bbox=dict(boxstyle="round,pad=0.2", facecolor='white', alpha=0.9, 
                             edgecolor=colors['f1'], linewidth=0.5))
    
    # æ›´æ–°å›¾ä¾‹åŒ…å«é‡è¦åŒºé—´
    ax_main.legend(loc='lower right', fontsize=10)
    
    # ç±»åˆ«ç‰¹å¼‚æ€§æ€§èƒ½ (ç¬¬äºŒè¡Œå·¦ä¾§)
    ax_class = fig.add_subplot(gs[1, 0])
    ax_class.plot(df['n_features'], df['mean_acc_0'], 'o-', 
                  color=colors['dual_1'], linewidth=2, markersize=5, 
                  label='Class 0 (Benign)', alpha=0.8)
    ax_class.plot(df['n_features'], df['mean_acc_1'], 'o-', 
                  color=colors['dual_2'], linewidth=2, markersize=5, 
                  label='Class 1 (Malignant)', alpha=0.8)
    ax_class.set_title('b', fontweight='bold', fontsize=24, pad=20, loc='left')
    ax_class.text(0.98, 0.02, 'Class-Specific Accuracy', transform=ax_class.transAxes, 
                  fontsize=11, fontweight='normal', va='bottom', ha='right')
    ax_class.set_xlabel('Features')
    ax_class.set_ylabel('Accuracy')
    ax_class.grid(True, alpha=0.3)
    ax_class.legend(fontsize=9)
    
    # ä¸ºcomprehensiveç‰ˆbå›¾æ·»åŠ 9-13ç‰¹å¾é‡è¦åŒºé—´èƒŒæ™¯
    ax_class.axvspan(9, 13, alpha=0.25, color=colors['cost_eff'], 
                    label='Key Range (9-13 features)', zorder=0)
    # æ›´æ–°å›¾ä¾‹åŒ…å«é‡è¦åŒºé—´
    ax_class.legend(fontsize=9)
    
    # è®­ç»ƒæ—¶é—´åˆ†æ (ç¬¬äºŒè¡Œå³ä¾§)
    ax_time = fig.add_subplot(gs[1, 1])
    ax_time.plot(df['n_features'], df['mean_time'], 'o-', 
                 color='#666666', linewidth=2, markersize=5, alpha=0.8)
    ax_time.fill_between(df['n_features'], 
                        df['mean_time'] - df['std_time'],
                        df['mean_time'] + df['std_time'],
                        alpha=0.2, color='#666666')
    ax_time.set_title('c', fontweight='bold', fontsize=24, pad=20, loc='left')
    ax_time.text(0.02, 0.95, 'Training Time Complexity', transform=ax_time.transAxes, 
                 fontsize=11, fontweight='normal', va='top')
    ax_time.set_xlabel('Features')
    ax_time.set_ylabel('Time (s)')
    ax_time.grid(True, alpha=0.3)
    
    # æ€§èƒ½ç¨³å®šæ€§åˆ†æ (ç¬¬ä¸‰è¡Œæ•´è¡Œ)
    ax_stability = fig.add_subplot(gs[2, :])
    
    # è®¡ç®—å˜å¼‚ç³»æ•° (CV = std/mean)
    cv_accuracy = df['std_accuracy'] / df['mean_accuracy']
    cv_auc = df['std_auc'] / df['mean_auc']
    cv_f1 = df['std_f1'] / df['mean_f1']
    
    ax_stability.plot(df['n_features'], cv_accuracy, 'o-', 
                     color=colors['accuracy'], linewidth=2, markersize=5, 
                     label='Accuracy CV', alpha=0.8)
    ax_stability.plot(df['n_features'], cv_auc, 'o-', 
                     color=colors['auc'], linewidth=2, markersize=5, 
                     label='AUC CV', alpha=0.8)
    ax_stability.plot(df['n_features'], cv_f1, 'o-', 
                     color=colors['f1'], linewidth=2, markersize=5, 
                     label='F1 CV', alpha=0.8)
    
    ax_stability.set_title('d', fontweight='bold', fontsize=24, pad=20, loc='left')
    ax_stability.text(0.98, 0.02, 'Performance Stability (Coefficient of Variation)', transform=ax_stability.transAxes, 
                      fontsize=11, fontweight='normal', va='bottom', ha='right')
    ax_stability.set_xlabel('Number of Features')
    ax_stability.set_ylabel('CV (std/mean)')
    ax_stability.grid(True, alpha=0.3)
    ax_stability.legend(fontsize=10)
    
    # ä¸ºcomprehensiveç‰ˆdå›¾æ·»åŠ 9-13ç‰¹å¾é‡è¦åŒºé—´èƒŒæ™¯
    ax_stability.axvspan(9, 13, alpha=0.25, color=colors['cost_eff'], 
                        label='Key Range (9-13 features)', zorder=0)
    # æ›´æ–°å›¾ä¾‹åŒ…å«é‡è¦åŒºé—´
    ax_stability.legend(fontsize=10)
    
    # Cost-Effectiveness Index åˆ†æ (ç¬¬å››è¡Œæ•´è¡Œ)
    ax_optimal = fig.add_subplot(gs[3, :])
    
    # è®¡ç®—Cost-Effectiveness Index (ä¸æ ‡å‡†ç‰ˆæœ¬ç›¸åŒçš„ç®—æ³•)
    # 1. æ€§èƒ½å¾—åˆ† (0-1, è¶Šé«˜è¶Šå¥½)
    performance_score = (df['mean_auc'] * 0.5 + df['mean_accuracy'] * 0.3 + df['mean_f1'] * 0.2)
    
    # 2. æ•ˆç‡å¾—åˆ† (0-1, è®­ç»ƒæ—¶é—´è¶ŠçŸ­è¶Šå¥½)
    max_time = df['mean_time'].max()
    min_time = df['mean_time'].min()
    efficiency_score = 1 - (df['mean_time'] - min_time) / (max_time - min_time)
    
    # 3. ç¨³å®šæ€§å¾—åˆ† (0-1, æ ‡å‡†å·®è¶Šå°è¶Šå¥½) 
    avg_std = (df['std_auc'] + df['std_accuracy'] + df['std_f1']) / 3
    max_std = avg_std.max()
    min_std = avg_std.min()
    stability_score = 1 - (avg_std - min_std) / (max_std - min_std) if max_std > min_std else 1
    
    # 4. ç®€æ´æ€§å¾—åˆ† (0-1, ç¬¦åˆå¥¥å¡å§†å‰ƒåˆ€åŸåˆ™ï¼Œè¶Šç®€å•è¶Šå¥½)
    # ä½¿ç”¨çº¯æ•°å­¦çš„æŒ‡æ•°è¡°å‡å‡½æ•°ï¼Œä½“ç°"è¶Šç®€å•è¶Šå¥½"çš„å¥¥å¡å§†å‰ƒåˆ€åŸç†
    alpha = 0.015  # å¤æ‚åº¦æƒ©ç½šç³»æ•°
    simplicity_score = np.exp(-alpha * df['n_features'])
    
    # ç»¼åˆè¯„ä»·æŒ‡æ ‡ (ç†è®ºé©±åŠ¨çš„æƒé‡åˆ†é…ï¼Œæ€§èƒ½ä¼˜å…ˆï¼Œç®€æ´åº¦é€‚åº¦å¢å¼º)
    # ä¼˜åŒ–æƒé‡: Performance=0.45, Efficiency=0.15, Stability=0.15, Simplicity=0.25
    cost_effectiveness = (performance_score * 0.45 + 
                         efficiency_score * 0.15 + 
                         stability_score * 0.15 + 
                         simplicity_score * 0.25)
    
    # ç»˜åˆ¶ç»¼åˆæŒ‡æ ‡
    ax_optimal.plot(df['n_features'], cost_effectiveness, 'o-', 
                   color='#F5A889', linewidth=2.5, markersize=6, alpha=0.9)
    ax_optimal.fill_between(df['n_features'], 
                           cost_effectiveness - cost_effectiveness.std()*0.1,
                           cost_effectiveness + cost_effectiveness.std()*0.1,
                           alpha=0.2, color='#F5A889')
    
    ax_optimal.set_title('e', fontweight='bold', fontsize=24, pad=20, loc='left')
    ax_optimal.text(0.98, 0.95, 'Cost-Effectiveness Index', transform=ax_optimal.transAxes, 
                    fontsize=11, fontweight='normal', va='top', ha='right')
    ax_optimal.set_xlabel('Number of Features')
    ax_optimal.set_ylabel('Comprehensive Score')
    ax_optimal.grid(True, alpha=0.3, linestyle='--')
    ax_optimal.set_ylim([cost_effectiveness.min() - 0.05, 
                        min(1.0, cost_effectiveness.max() + 0.05)])
    
    # æ·»åŠ æœ€ä½³æ€§ä»·æ¯”ç‚¹æ ‡æ³¨
    best_ce_idx = cost_effectiveness.idxmax()
    best_ce_features = df.iloc[best_ce_idx]['n_features']
    best_ce_value = cost_effectiveness.iloc[best_ce_idx]
    ax_optimal.annotate(f'Optimal: {best_ce_features} features',
                       xy=(best_ce_features, best_ce_value),
                       xytext=(best_ce_features + 8, best_ce_value - 0.05),
                       arrowprops=dict(arrowstyle='->', color='#333333', alpha=0.8, lw=1),
                       fontsize=9, ha='left',
                       bbox=dict(boxstyle="round,pad=0.2", facecolor='white', alpha=0.9, 
                                edgecolor='gray', linewidth=0.5))
    
    # æ·»åŠ ç»¼åˆæŒ‡æ ‡æ„æˆè¯´æ˜
    formula_text = ('PerformanceÃ—0.45 + SimplicityÃ—0.25\n'
                   '+ EfficiencyÃ—0.15 + StabilityÃ—0.15')
    ax_optimal.text(0.02, 0.02, formula_text, transform=ax_optimal.transAxes, 
                    fontsize=8, ha='left', va='bottom',
                    bbox=dict(boxstyle="round,pad=0.3", facecolor='lightgray', 
                             alpha=0.8, edgecolor='gray', linewidth=0.5))
    
    # è°ƒæ•´å¸ƒå±€ - ä¸ºæ–°çš„5è¡Œå¸ƒå±€å¢åŠ å‚ç›´é—´è·
    plt.tight_layout()
    plt.subplots_adjust(top=0.96, hspace=0.3, wspace=0.2)
    
    # ä¿å­˜ç»¼åˆåˆ†æå›¾
    comprehensive_path = output_path.parent / f"{output_path.stem}_comprehensive.pdf"
    print(f"ğŸ’¾ ä¿å­˜ç»¼åˆåˆ†æPDFåˆ°: {comprehensive_path}")
    plt.savefig(comprehensive_path, format='pdf', dpi=dpi, bbox_inches='tight', 
                facecolor='white', edgecolor='none')
    
    # ä¿å­˜PNGé¢„è§ˆ
    png_path = comprehensive_path.with_suffix('.png')
    plt.savefig(png_path, format='png', dpi=dpi, bbox_inches='tight',
                facecolor='white', edgecolor='none')
    
    plt.show()
    
    return {
        'best_cost_effectiveness': {'features': best_ce_features, 'value': best_ce_value}
    }

def print_summary_statistics(df, best_performance):
    """æ‰“å°æ€»ç»“ç»Ÿè®¡ä¿¡æ¯"""
    print(f"\nğŸ“Š ç‰¹å¾æ•°é‡æ€§èƒ½åˆ†ææ€»ç»“")
    print("=" * 50)
    
    print(f"ğŸ“ˆ æœ€ä½³æ€§èƒ½æŒ‡æ ‡:")
    print(f"  æœ€ä½³å‡†ç¡®ç‡: {best_performance['best_accuracy']['value']:.3f} (ç‰¹å¾æ•°: {best_performance['best_accuracy']['features']})")
    print(f"  æœ€ä½³AUC: {best_performance['best_auc']['value']:.3f} (ç‰¹å¾æ•°: {best_performance['best_auc']['features']})")
    print(f"  æœ€ä½³F1åˆ†æ•°: {best_performance['best_f1']['value']:.3f} (ç‰¹å¾æ•°: {best_performance['best_f1']['features']})")
    
    print(f"\nâš¡ æ•ˆç‡åˆ†æ:")
    min_time_idx = df['mean_time'].idxmin()
    min_time_features = df.iloc[min_time_idx]['n_features']
    min_time_value = df.iloc[min_time_idx]['mean_time']
    print(f"  æœ€å¿«è®­ç»ƒæ—¶é—´: {min_time_value:.2f}s (ç‰¹å¾æ•°: {min_time_features})")
    
    max_time_idx = df['mean_time'].idxmax()
    max_time_features = df.iloc[max_time_idx]['n_features']
    max_time_value = df.iloc[max_time_idx]['mean_time']
    print(f"  æœ€æ…¢è®­ç»ƒæ—¶é—´: {max_time_value:.2f}s (ç‰¹å¾æ•°: {max_time_features})")
    
    print(f"\nğŸ¯ æ¨èé…ç½®:")
    # æ‰¾åˆ°å¹³è¡¡ç‚¹ï¼šæ€§èƒ½å¥½ä¸”æ•ˆç‡é«˜
    df['efficiency_score'] = (df['mean_auc'] * 0.6 + df['mean_f1'] * 0.4) / (df['mean_time'] / df['mean_time'].min())
    best_efficiency_idx = df['efficiency_score'].idxmax()
    best_efficiency_features = df.iloc[best_efficiency_idx]['n_features']
    best_efficiency_auc = df.iloc[best_efficiency_idx]['mean_auc']
    best_efficiency_time = df.iloc[best_efficiency_idx]['mean_time']
    
    print(f"  æ¨èç‰¹å¾æ•°: {best_efficiency_features} (å¹³è¡¡æ€§èƒ½ä¸æ•ˆç‡)")
    print(f"  å¯¹åº”AUC: {best_efficiency_auc:.3f}")
    print(f"  å¯¹åº”è®­ç»ƒæ—¶é—´: {best_efficiency_time:.2f}s")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ ç‰¹å¾æ•°é‡æ€§èƒ½åˆ†æ - å­¦æœ¯è®ºæ–‡çº§PDFç”Ÿæˆå™¨")
    print("=" * 60)
    
    # æ–‡ä»¶è·¯å¾„é…ç½®
    csv_path = Path("/Users/lqy/work/TabPFN/uda_medical_imbalance_project/results/feature_number_evaluation/feature_number_comparison.csv")
    output_path = Path("/Users/lqy/work/TabPFN/uda_medical_imbalance_project/results/feature_number_evaluation/performance_comparison.pdf")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not csv_path.exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    try:
        # 1. åŠ è½½æ•°æ®
        df = load_and_analyze_data(csv_path)
        
        # 2. ç”Ÿæˆæ ‡å‡†æ€§èƒ½å¯¹æ¯”å›¾ (DPI: 1200)
        print(f"\nğŸ¨ ç”Ÿæˆæ ‡å‡†æ€§èƒ½å¯¹æ¯”å›¾...")
        best_performance = create_performance_comparison_plot(df, output_path, dpi=1200)
        
        # 3. ç”Ÿæˆç»¼åˆåˆ†æå›¾ (DPI: 900, æ›´å¤æ‚çš„å›¾è¡¨ä½¿ç”¨ç¨ä½DPIä»¥å¹³è¡¡æ–‡ä»¶å¤§å°)
        print(f"\nğŸ¨ ç”Ÿæˆç»¼åˆåˆ†æå›¾...")
        analysis_results = create_comprehensive_analysis_plot(df, output_path, dpi=900)
        
        # 4. æ‰“å°æ€»ç»“ç»Ÿè®¡
        print_summary_statistics(df, best_performance)
        
        print(f"\nâœ… PDFå›¾è¡¨ç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"  æ ‡å‡†ç‰ˆ: {output_path}")
        print(f"  ç»¼åˆç‰ˆ: {output_path.parent / f'{output_path.stem}_comprehensive.pdf'}")
        print(f"  PNGé¢„è§ˆ: {output_path.with_suffix('.png')}")
        
        print(f"\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
        print(f"  - æ ‡å‡†ç‰ˆé€‚åˆè®ºæ–‡æ­£æ–‡æ’å…¥")
        print(f"  - ç»¼åˆç‰ˆé€‚åˆè¡¥å……ææ–™æˆ–è¯¦ç»†åˆ†æ")
        print(f"  - æ‰€æœ‰å›¾è¡¨DPIâ‰¥900ï¼Œç¬¦åˆå­¦æœ¯æœŸåˆŠè¦æ±‚")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()