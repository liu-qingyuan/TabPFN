#!/usr/bin/env python3
"""
ä½¿ç”¨çœŸå®åŒ»ç–—æ•°æ®é›†Aå’ŒBçš„UDAå¯è§†åŒ–ç¤ºä¾‹

è¿™ä¸ªè„šæœ¬ä½¿ç”¨çœŸå®çš„åŒ»ç–—æ•°æ®é›†è¿›è¡Œå®Œæ•´çš„UDAå¯è§†åŒ–åˆ†æï¼š
- æ•°æ®é›†A (AI4health) ä½œä¸ºæºåŸŸ
- æ•°æ®é›†B (HenanCancerHospital) ä½œä¸ºç›®æ ‡åŸŸ
- ä½¿ç”¨best8ç‰¹å¾è¿›è¡ŒåŸŸé€‚åº”
- ç”Ÿæˆå®Œæ•´çš„å¯è§†åŒ–åˆ†ææŠ¥å‘Š

è¿è¡Œç¤ºä¾‹: python examples/real_data_visualization.py
"""

import sys
import os
from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
from datetime import datetime
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def load_real_medical_data():
    """åŠ è½½çœŸå®åŒ»ç–—æ•°æ®é›†Aå’ŒB"""
    try:
        from data.loader import MedicalDataLoader
        
        # ä½¿ç”¨MedicalDataLoaderåŠ è½½çœŸå®æ•°æ®
        loader = MedicalDataLoader()
        
        # åŠ è½½æ•°æ®é›†Aå’ŒBï¼Œä½¿ç”¨best8ç‰¹å¾
        print("ğŸ“Š åŠ è½½çœŸå®åŒ»ç–—æ•°æ®...")
        data_A = loader.load_dataset('A', feature_type='best8')
        data_B = loader.load_dataset('B', feature_type='best8')
        
        # æå–ç‰¹å¾å’Œæ ‡ç­¾
        X_A = pd.DataFrame(data_A['X'], columns=data_A['feature_names'])
        y_A = pd.Series(data_A['y'], name='label')
        X_B = pd.DataFrame(data_B['X'], columns=data_B['feature_names'])
        y_B = pd.Series(data_B['y'], name='label')
        
        # ç¡®ä¿Aå’ŒBæ•°æ®é›†ä½¿ç”¨ç›¸åŒçš„ç‰¹å¾åˆ—ï¼ˆç‰¹å¾å¯¹é½ï¼‰
        common_features = list(set(X_A.columns) & set(X_B.columns))
        if len(common_features) != len(X_A.columns) or len(common_features) != len(X_B.columns):
            print(f"âš  è­¦å‘Š: Aå’ŒBæ•°æ®é›†ç‰¹å¾ä¸å®Œå…¨ä¸€è‡´")
            print(f"  Aç‰¹å¾: {list(X_A.columns)}")
            print(f"  Bç‰¹å¾: {list(X_B.columns)}")
            print(f"  å…±åŒç‰¹å¾: {common_features}")
            # ä½¿ç”¨å…±åŒç‰¹å¾
            X_A = X_A[common_features]
            X_B = X_B[common_features]
        
        print(f"âœ… æˆåŠŸåŠ è½½çœŸå®åŒ»ç–—æ•°æ®:")
        print(f"  æ•°æ®é›†A (AI4health): {X_A.shape}")
        print(f"  æ•°æ®é›†B (HenanCancerHospital): {X_B.shape}")
        print(f"  ç‰¹å¾åˆ—è¡¨: {list(X_A.columns)}")
        print(f"  Aç±»åˆ«åˆ†å¸ƒ: {dict(y_A.value_counts().sort_index())}")
        print(f"  Bç±»åˆ«åˆ†å¸ƒ: {dict(y_B.value_counts().sort_index())}")
        
        return X_A.values, y_A.values, X_B.values, y_B.values, list(X_A.columns)
        
    except Exception as e:
        print(f"âŒ åŠ è½½çœŸå®æ•°æ®å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨ä¸”data.loaderæ¨¡å—å¯ç”¨")
        raise


def analyze_data_distribution(X_A, y_A, X_B, y_B, feature_names):
    """åˆ†ææ•°æ®åˆ†å¸ƒç‰¹å¾"""
    print(f"\nğŸ“ˆ æ•°æ®åˆ†å¸ƒåˆ†æ:")
    
    # åŸºæœ¬ç»Ÿè®¡
    print(f"æºåŸŸ (A) ç»Ÿè®¡:")
    print(f"  æ ·æœ¬æ•°: {len(X_A)}")
    print(f"  æ­£ç±»æ¯”ä¾‹: {np.mean(y_A):.3f}")
    print(f"  ç‰¹å¾å‡å€¼: {np.mean(X_A, axis=0)[:3]} ...")
    print(f"  ç‰¹å¾æ ‡å‡†å·®: {np.std(X_A, axis=0)[:3]} ...")
    
    print(f"ç›®æ ‡åŸŸ (B) ç»Ÿè®¡:")
    print(f"  æ ·æœ¬æ•°: {len(X_B)}")
    print(f"  æ­£ç±»æ¯”ä¾‹: {np.mean(y_B):.3f}")
    print(f"  ç‰¹å¾å‡å€¼: {np.mean(X_B, axis=0)[:3]} ...")
    print(f"  ç‰¹å¾æ ‡å‡†å·®: {np.std(X_B, axis=0)[:3]} ...")
    
    # è®¡ç®—åŸŸé—´å·®å¼‚
    mean_diff = np.mean(np.abs(np.mean(X_A, axis=0) - np.mean(X_B, axis=0)))
    std_diff = np.mean(np.abs(np.std(X_A, axis=0) - np.std(X_B, axis=0)))
    
    print(f"åŸŸé—´å·®å¼‚:")
    print(f"  å¹³å‡ç‰¹å¾å‡å€¼å·®å¼‚: {mean_diff:.4f}")
    print(f"  å¹³å‡ç‰¹å¾æ ‡å‡†å·®å·®å¼‚: {std_diff:.4f}")
    
    return {
        'mean_difference': mean_diff,
        'std_difference': std_diff,
        'source_positive_rate': np.mean(y_A),
        'target_positive_rate': np.mean(y_B)
    }


def run_uda_with_visualization(X_source, y_source, X_target, y_target, 
                              feature_names, method_name='TCA'):
    """è¿è¡ŒUDAæ–¹æ³•å¹¶ç”Ÿæˆå¯è§†åŒ–"""
    
    from preprocessing.uda_processor import create_uda_processor
    from preprocessing.uda_visualizer import create_uda_visualizer
    
    # å¯¼å…¥TabPFN
    try:
        from tabpfn import TabPFNClassifier
        base_estimator = TabPFNClassifier(n_estimators=32)
        print("âœ… ä½¿ç”¨TabPFNä½œä¸ºåŸºç¡€ä¼°è®¡å™¨")
    except ImportError:
        from sklearn.linear_model import LogisticRegression
        base_estimator = LogisticRegression(penalty=None, random_state=42, max_iter=1000)
        print("âš  TabPFNä¸å¯ç”¨ï¼Œä½¿ç”¨LogisticRegressionä½œä¸ºfallback")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = f"results/real_data_uda_{method_name}_{timestamp}"
    
    print(f"\nğŸ”¬ è¿è¡ŒUDAæ–¹æ³•: {method_name}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # åˆ›å»ºUDAå¤„ç†å™¨ï¼Œé’ˆå¯¹åŒ»ç–—æ•°æ®ä¼˜åŒ–å‚æ•°
    processor = create_uda_processor(
        method_name=method_name,
        base_estimator=base_estimator,
        save_results=True,
        output_dir=output_dir
    )
    
    # é’ˆå¯¹ä¸åŒæ–¹æ³•ä¼˜åŒ–å‚æ•°
    if method_name == 'TCA':
        # TCAå‚æ•°ä¼˜åŒ–ï¼šé’ˆå¯¹åŒ»ç–—æ•°æ®çš„å°æ ·æœ¬ã€é«˜ç»´ç‰¹å¾
        processor.config.method_params.update({
            'n_components': None,  # è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç»„ä»¶æ•°
            'mu': 0.1,  # è¾ƒå°çš„muå€¼ï¼Œå‡å°‘æ­£åˆ™åŒ–ï¼Œé€‚åˆå°æ ·æœ¬
            'kernel': 'linear'  # çº¿æ€§æ ¸ï¼Œé€‚åˆåŒ»ç–—ç‰¹å¾
        })
        print(f"  TCAå‚æ•°ä¼˜åŒ–: n_components={min(6, len(feature_names)-1)}, mu=0.1, kernel=linear")
    elif method_name == 'SA':
        # SAå‚æ•°ä¼˜åŒ–
        processor.config.method_params.update({
            'n_components': None  # è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç»„ä»¶æ•°
        })
        print(f"  SAå‚æ•°ä¼˜åŒ–: n_components=auto")
    
    # æ‹ŸåˆUDAæ–¹æ³•
    print("ğŸ”§ æ‹ŸåˆUDAæ–¹æ³•...")
    uda_method, uda_results = processor.fit_transform(
        X_source, y_source, X_target, y_target
    )
    
    print(f"âœ… UDAæ–¹æ³•æ‹Ÿåˆå®Œæˆ")
    print(f"æ€§èƒ½æŒ‡æ ‡:")
    for metric in ['accuracy', 'auc', 'f1', 'precision', 'recall']:
        if metric in uda_results:
            print(f"  {metric.upper()}: {uda_results[metric]:.4f}")
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = create_uda_visualizer(
        figsize=(16, 12),
        save_plots=True,
        output_dir=output_dir
    )
    
    # å®Œæ•´å¯è§†åŒ–åˆ†æ
    print(f"\nğŸ¨ ç”Ÿæˆå®Œæ•´å¯è§†åŒ–åˆ†æ...")
    viz_results = visualizer.visualize_domain_adaptation_complete(
        X_source, y_source, X_target, y_target,
        uda_method=uda_method,
        method_name=f"{method_name}_RealData"
    )
    
    return uda_results, viz_results, output_dir


def compare_multiple_uda_methods(X_source, y_source, X_target, y_target, feature_names):
    """å¯¹æ¯”å¤šç§UDAæ–¹æ³•åœ¨çœŸå®æ•°æ®ä¸Šçš„è¡¨ç°"""
    
    print(f"\nğŸ” å¤šç§UDAæ–¹æ³•å¯¹æ¯”åˆ†æ")
    print("=" * 50)
    
    methods_to_test = ['TCA', 'SA', 'CORAL']  # TCAä¼˜å…ˆï¼Œå› ä¸ºåœ¨åŒ»ç–—æ•°æ®ä¸Šè¡¨ç°æœ€ä½³
    results_summary = {}
    
    for method_name in methods_to_test:
        print(f"\n--- æµ‹è¯•æ–¹æ³•: {method_name} ---")
        
        try:
            uda_results, viz_results, output_dir = run_uda_with_visualization(
                X_source, y_source, X_target, y_target, 
                feature_names, method_name
            )
            
            # æå–å…³é”®æŒ‡æ ‡
            summary = {
                'method': method_name,
                'accuracy': uda_results.get('accuracy', 0),
                'auc': uda_results.get('auc', 0),
                'f1': uda_results.get('f1', 0),
                'output_dir': output_dir
            }
            
            # æ·»åŠ åŸŸè·ç¦»æ”¹è¿›ï¼ˆä¼˜å…ˆä½¿ç”¨ADAPTæŒ‡æ ‡ï¼‰
            if 'domain_distances' in viz_results:
                distances = viz_results['domain_distances']
                
                # ä½¿ç”¨æ ‡å‡†åŒ–æŒ‡æ ‡ä½œä¸ºä¸»è¦æ”¹è¿›åº¦é‡
                summary['cov_improvement'] = distances.get('cov_distance_improvement', 0)
                summary['norm_linear_improvement'] = distances.get('normalized_linear_discrepancy_improvement', 0)
                summary['norm_frechet_improvement'] = distances.get('normalized_frechet_distance_improvement', 0)
                
                # æ ‡å‡†åŒ–å¤‡ç”¨æŒ‡æ ‡ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
                summary['norm_kl_improvement'] = distances.get('normalized_kl_divergence_improvement', 0)
                summary['norm_wasserstein_improvement'] = distances.get('normalized_wasserstein_improvement', 0)
                
                # åŸå§‹å¤‡ç”¨æŒ‡æ ‡
                summary['kl_improvement'] = distances.get('kl_divergence_improvement', 0)
                summary['wasserstein_improvement'] = distances.get('wasserstein_improvement', 0)
                summary['mmd_improvement'] = distances.get('mmd_improvement', 0)
            
            results_summary[method_name] = summary
            
            print(f"âœ… {method_name} å®Œæˆ:")
            print(f"   AUC: {summary['auc']:.4f}")
            print(f"   Accuracy: {summary['accuracy']:.4f}")
            print(f"   F1: {summary['f1']:.4f}")
            
        except Exception as e:
            print(f"âŒ {method_name} å¤±è´¥: {e}")
            results_summary[method_name] = {'method': method_name, 'error': str(e)}
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    generate_comparison_report(results_summary)
    
    return results_summary


def generate_comparison_report(results_summary):
    """ç”Ÿæˆæ–¹æ³•å¯¹æ¯”æŠ¥å‘Š"""
    
    print(f"\nğŸ“Š UDAæ–¹æ³•å¯¹æ¯”æŠ¥å‘Š")
    print("=" * 60)
    
    # è¿‡æ»¤æˆåŠŸçš„æ–¹æ³•
    successful_methods = {k: v for k, v in results_summary.items() if 'error' not in v}
    
    if not successful_methods:
        print("âŒ æ²¡æœ‰æˆåŠŸçš„æ–¹æ³•å¯ä¾›å¯¹æ¯”")
        return
    
    # æ€§èƒ½å¯¹æ¯”è¡¨æ ¼
    print(f"{'æ–¹æ³•':<8} {'AUC':<8} {'Accuracy':<10} {'F1':<8} {'åæ–¹å·®æ”¹è¿›':<10} {'çº¿æ€§å·®å¼‚æ”¹è¿›':<12} {'Frechetæ”¹è¿›':<12}")
    print("-" * 78)
    
    best_auc = 0
    best_method = ""
    
    for method, results in successful_methods.items():
        auc = results.get('auc', 0)
        acc = results.get('accuracy', 0)
        f1 = results.get('f1', 0)
        
        # ä¼˜å…ˆä½¿ç”¨ADAPTæŒ‡æ ‡
        cov_imp = results.get('cov_improvement', 0)
        norm_linear_imp = results.get('norm_linear_improvement', 0)
        norm_frechet_imp = results.get('norm_frechet_improvement', 0)
        
        # å¦‚æœADAPTæŒ‡æ ‡ä¸å¯ç”¨ï¼Œä½¿ç”¨æ ‡å‡†åŒ–å¤‡ç”¨æŒ‡æ ‡
        if cov_imp == 0 and norm_linear_imp == 0 and norm_frechet_imp == 0:
            # ä¼˜å…ˆä½¿ç”¨æ ‡å‡†åŒ–ç‰ˆæœ¬
            norm_kl_imp = results.get('norm_kl_improvement', 0)
            norm_ws_imp = results.get('norm_wasserstein_improvement', 0)
            
            if norm_kl_imp != 0 or norm_ws_imp != 0:
                # ä½¿ç”¨æ ‡å‡†åŒ–å¤‡ç”¨æŒ‡æ ‡
                mmd_imp = results.get('mmd_improvement', 0)
                print(f"{method:<8} {auc:<8.4f} {acc:<10.4f} {f1:<8.4f} {norm_kl_imp:<10.4f} {norm_ws_imp:<12.4f} {mmd_imp:<12.4f}")
            else:
                # ä½¿ç”¨åŸå§‹å¤‡ç”¨æŒ‡æ ‡
                kl_imp = results.get('kl_improvement', 0)
                ws_imp = results.get('wasserstein_improvement', 0)
                mmd_imp = results.get('mmd_improvement', 0)
                print(f"{method:<8} {auc:<8.4f} {acc:<10.4f} {f1:<8.4f} {kl_imp:<10.4f} {ws_imp:<12.4f} {mmd_imp:<12.4f}")
        else:
            print(f"{method:<8} {auc:<8.4f} {acc:<10.4f} {f1:<8.4f} {cov_imp:<10.4f} {norm_linear_imp:<12.4f} {norm_frechet_imp:<12.4f}")
        
        if auc > best_auc:
            best_auc = auc
            best_method = method
    
    print("\nğŸ† æœ€ä½³æ–¹æ³•:")
    print(f"   {best_method} (AUC: {best_auc:.4f})")
    
    # ä¿å­˜å¯¹æ¯”ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    comparison_file = f"results/uda_methods_comparison_{timestamp}.json"
    
    import json
    os.makedirs("results", exist_ok=True)
    with open(comparison_file, 'w', encoding='utf-8') as f:
        json.dump(results_summary, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"ğŸ“ å¯¹æ¯”ç»“æœå·²ä¿å­˜: {comparison_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¥ çœŸå®åŒ»ç–—æ•°æ®UDAå¯è§†åŒ–åˆ†æ")
    print("=" * 50)
    
    try:
        # æ£€æŸ¥ç¯å¢ƒ
        from uda.adapt_methods import is_adapt_available
        
        if not is_adapt_available():
            print("âŒ Adaptåº“ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install adapt-python")
            return
        
        print("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡")
        
        # 1. åŠ è½½çœŸå®åŒ»ç–—æ•°æ®
        X_source, y_source, X_target, y_target, feature_names = load_real_medical_data()
        
        # 2. åˆ†ææ•°æ®åˆ†å¸ƒ
        data_stats = analyze_data_distribution(X_source, y_source, X_target, y_target, feature_names)
        
        # 3. è¿è¡Œå•ä¸ªæœ€ä½³æ–¹æ³•çš„å®Œæ•´åˆ†æ
        print(f"\nğŸ¯ ä½¿ç”¨æœ€ä½³æ–¹æ³• (TCA) è¿›è¡Œè¯¦ç»†åˆ†æ")
        uda_results, viz_results, output_dir = run_uda_with_visualization(
            X_source, y_source, X_target, y_target, 
            feature_names, method_name='TCA'
        )
        
        # è¾“å‡ºè¯¦ç»†ç»“æœ
        if 'domain_distances' in viz_results:
            distances = viz_results['domain_distances']
            print(f"\nğŸ“Š åŸŸé€‚åº”æ•ˆæœåˆ†æ:")
            
            # æ£€æŸ¥å¯ç”¨çš„æ”¹è¿›æŒ‡æ ‡
            improvement_metrics = []
            
            # ä¼˜å…ˆä½¿ç”¨ADAPTåº“çš„æŒ‡æ ‡
            if 'cov_distance_improvement' in distances:
                print(f"  åæ–¹å·®è·ç¦»æ”¹è¿›: {distances['cov_distance_improvement']:.4f}")
                improvement_metrics.append(distances['cov_distance_improvement'])
            
            if 'normalized_linear_discrepancy_improvement' in distances:
                print(f"  æ ‡å‡†åŒ–çº¿æ€§å·®å¼‚æ”¹è¿›: {distances['normalized_linear_discrepancy_improvement']:.4f}")
                improvement_metrics.append(distances['normalized_linear_discrepancy_improvement'])
            
            if 'normalized_frechet_distance_improvement' in distances:
                print(f"  æ ‡å‡†åŒ–Frechetè·ç¦»æ”¹è¿›: {distances['normalized_frechet_distance_improvement']:.4f}")
                improvement_metrics.append(distances['normalized_frechet_distance_improvement'])
            
            # æ ‡å‡†åŒ–å¤‡ç”¨æŒ‡æ ‡ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
            if 'normalized_kl_divergence_improvement' in distances:
                print(f"  æ ‡å‡†åŒ–KLæ•£åº¦æ”¹è¿›: {distances['normalized_kl_divergence_improvement']:.4f}")
                improvement_metrics.append(distances['normalized_kl_divergence_improvement'])
            
            if 'normalized_wasserstein_improvement' in distances:
                print(f"  æ ‡å‡†åŒ–Wassersteinè·ç¦»æ”¹è¿›: {distances['normalized_wasserstein_improvement']:.4f}")
                improvement_metrics.append(distances['normalized_wasserstein_improvement'])
            
            # åŸå§‹å¤‡ç”¨æŒ‡æ ‡ï¼ˆå¦‚æœæ ‡å‡†åŒ–ç‰ˆæœ¬ä¸å¯ç”¨ï¼‰
            if 'kl_divergence_improvement' in distances:
                print(f"  KLæ•£åº¦æ”¹è¿›: {distances['kl_divergence_improvement']:.4f}")
                improvement_metrics.append(distances['kl_divergence_improvement'])
            
            if 'wasserstein_improvement' in distances:
                print(f"  Wassersteinè·ç¦»æ”¹è¿›: {distances['wasserstein_improvement']:.4f}")
                improvement_metrics.append(distances['wasserstein_improvement'])
            
            if 'mmd_improvement' in distances:
                print(f"  MMDæ”¹è¿›: {distances['mmd_improvement']:.4f}")
                improvement_metrics.append(distances['mmd_improvement'])
            
            # è¯„ä¼°æ”¹è¿›æ•ˆæœ
            if improvement_metrics:
                # è¿‡æ»¤æ‰NaNå€¼
                valid_improvements = [imp for imp in improvement_metrics if not np.isnan(imp)]
                if valid_improvements:
                    avg_improvement = np.mean(valid_improvements)
                    
                    if avg_improvement > 0:
                        print(f"  âœ… åŸŸé€‚åº”æ•ˆæœ: è‰¯å¥½ (å¹³å‡æ”¹è¿›: {avg_improvement:.4f})")
                    else:
                        print(f"  âš  åŸŸé€‚åº”æ•ˆæœ: æœ‰é™ (å¹³å‡æ”¹è¿›: {avg_improvement:.4f})")
                else:
                    print(f"  âš  åŸŸé€‚åº”æ•ˆæœ: æ— æ³•è¯„ä¼° (æ‰€æœ‰æ”¹è¿›æŒ‡æ ‡ä¸ºNaN)")
            else:
                print(f"  âš  åŸŸé€‚åº”æ•ˆæœ: æ— å¯ç”¨çš„æ”¹è¿›æŒ‡æ ‡")
        
        print(f"\nğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        
        # 4. å¤šæ–¹æ³•å¯¹æ¯”ï¼ˆè‡ªåŠ¨è¿è¡Œï¼‰
        print(f"\nğŸ” è‡ªåŠ¨è¿è¡Œå¤šæ–¹æ³•å¯¹æ¯”åˆ†æ...")
        comparison_results = compare_multiple_uda_methods(
            X_source, y_source, X_target, y_target, feature_names
        )
        
        print(f"\nâœ… çœŸå®åŒ»ç–—æ•°æ®UDAå¯è§†åŒ–åˆ†æå®Œæˆï¼")
        print(f"ğŸ“ æŸ¥çœ‹ results/ ç›®å½•ä¸‹çš„æ‰€æœ‰å¯è§†åŒ–ç»“æœ")
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 